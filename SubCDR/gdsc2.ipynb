{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4370fc1-8231-4984-b07d-02e4fab19211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch_geometric/typing.py:54: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /gpfs/gsfs12/users/inouey2/conda/envs/genex/lib/python3.10/site-packages/libpyg.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch_geometric/typing.py:72: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /gpfs/gsfs12/users/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch_scatter/_scatter_cuda.so: undefined symbol: _ZN2at23SavedTensorDefaultHooks11set_tracingEb\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch_geometric/typing.py:99: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /gpfs/gsfs12/users/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch_spline_conv/_basis_cuda.so: undefined symbol: _ZN2at23SavedTensorDefaultHooks11set_tracingEb\n",
      "  warnings.warn(\n",
      "/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /gpfs/gsfs12/users/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch_sparse/_spmm_cuda.so: undefined symbol: _ZN2at23SavedTensorDefaultHooks11set_tracingEb\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from molFrags import *\n",
    "from sklearn.model_selection import KFold\n",
    "from torch_dataset import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ac870f-3e1b-4cb4-925d-479b2e3d088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_process import data_process\n",
    "from load_data import load_data\n",
    "from main_classify import *\n",
    "from MF import *\n",
    "from models_classify import *\n",
    "from sampler import Sampler\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a74c714-b933-47b1-84aa-324775cfc237",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = \"gdsc2\"\n",
    "\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.lr = 0.0001  # 学習率\n",
    "        self.bs = 5000  # バッチサイズ\n",
    "        self.ep = 100  # エポック数\n",
    "        self.o = f\"./{tmp}_output_dir/\"  # 出力ディレクトリ\n",
    "        self.data = tmp\n",
    "\n",
    "\n",
    "# argsオブジェクトを作成\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f6a906-9ddc-48b5-8358-adbf65d5bf7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files...\n",
      "Processing drug data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [00:04, 58.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug processing complete.\n",
      "Processing cell line data...\n",
      "Cell line processing complete.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(args.o, exist_ok=True)\n",
    "# ---data process\n",
    "start_time = time.time()\n",
    "seed = 42\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "drug_subfeat, cline_subfeat, drug_dim, drug_compo_elem, cline_compos_elem = (\n",
    "    data_process(args)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "548fc90d-74be-4963-8128-3b718f1c50a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_matrix_factorization(train_set):\n",
    "    \"\"\"Matrix factorization preparation and execution\"\"\"\n",
    "    # print(\"Building known matrix...\")\n",
    "    CDR_known = train_set.set_index([\"Cline\", \"Drug\"]).unstack(\"Cline\")\n",
    "    CDR_known.columns = CDR_known.columns.droplevel()\n",
    "\n",
    "    CDR_matrix = np.array(CDR_known)\n",
    "    CDR_mask = 1 - np.float32(np.isnan(CDR_matrix))\n",
    "    CDR_matrix[np.isnan(CDR_matrix)] = 0\n",
    "\n",
    "    # print(\"Performing matrix factorization...\")\n",
    "    drug_glofeat, cline_glofeat = svt_solve(A=CDR_matrix, mask=CDR_mask)\n",
    "    drug_glofeat = pd.DataFrame(drug_glofeat, index=list(CDR_known.index))\n",
    "    cline_glofeat = pd.DataFrame(cline_glofeat, index=list(CDR_known.columns))\n",
    "\n",
    "    return drug_glofeat, cline_glofeat\n",
    "\n",
    "\n",
    "def prepare_data_loaders(\n",
    "    train_set, validation_set, drug_glofeat, cline_glofeat, batch_sizes\n",
    "):\n",
    "    \"\"\"Prepare train and validation data loaders\"\"\"\n",
    "    # print(\"Preparing data loaders...\")\n",
    "    # Shuffle data\n",
    "    train_set = train_set.sample(frac=1, random_state=seed)\n",
    "    validation_set = validation_set.sample(frac=1, random_state=seed)\n",
    "\n",
    "    # Create train loaders\n",
    "    # print(\"Preparing train data loaders...\")\n",
    "    drug_loader_train, cline_loader_train, glo_loader_train, _, _, label_train = (\n",
    "        BatchGenerate(\n",
    "            train_set,\n",
    "            drug_subfeat,\n",
    "            cline_subfeat,\n",
    "            drug_glofeat,\n",
    "            cline_glofeat,\n",
    "            drug_compo_elem,\n",
    "            cline_compos_elem,\n",
    "            bs=batch_sizes,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create validation loaders\n",
    "    # print(\"Preparing test data loaders...\")\n",
    "    (\n",
    "        drug_loader_valid,\n",
    "        cline_loader_valid,\n",
    "        glo_loader_valid,\n",
    "        dc_valid,\n",
    "        cc_valid,\n",
    "        label_valid,\n",
    "    ) = BatchGenerate(\n",
    "        validation_set,\n",
    "        drug_subfeat,\n",
    "        cline_subfeat,\n",
    "        drug_glofeat,\n",
    "        cline_glofeat,\n",
    "        drug_compo_elem,\n",
    "        cline_compos_elem,\n",
    "        bs=batch_sizes,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        drug_loader_train,\n",
    "        cline_loader_train,\n",
    "        glo_loader_train,\n",
    "        label_train,\n",
    "        drug_loader_valid,\n",
    "        cline_loader_valid,\n",
    "        glo_loader_valid,\n",
    "        label_valid,\n",
    "        dc_valid,\n",
    "        cc_valid,\n",
    "    )\n",
    "\n",
    "\n",
    "def setup_model(drug_dim, glo_dim, device, args):\n",
    "    \"\"\"Initialize model and optimizer\"\"\"\n",
    "    # print(\"Initializing model and optimizer...\")\n",
    "    if args.data == \"ctrp\":\n",
    "        out = 80\n",
    "    else:\n",
    "        out = 82\n",
    "    model = SubCDR(\n",
    "        SubEncoder(in_drug=drug_dim, in_cline=8, out=out),\n",
    "        GraphEncoder(in_channels=32, out_channels=16),\n",
    "        GloEncoder(in_channels=glo_dim, out_channels=128),\n",
    "        Decoder(in_channels=160),\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
    "    myloss = torch.nn.BCELoss()\n",
    "\n",
    "    return model, optimizer, myloss\n",
    "\n",
    "\n",
    "def train_epoch(model, loaders, optimizer, myloss):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    drug_loader_train, cline_loader_train, glo_loader_train, label_train = loaders\n",
    "    train(\n",
    "        model,\n",
    "        optimizer,\n",
    "        myloss,\n",
    "        drug_loader_train,\n",
    "        cline_loader_train,\n",
    "        glo_loader_train,\n",
    "        label_train,\n",
    "    )\n",
    "\n",
    "\n",
    "def validate(model, loaders, myloss):\n",
    "    \"\"\"Perform validation\"\"\"\n",
    "    drug_loader_valid, cline_loader_valid, glo_loader_valid, label_valid = loaders\n",
    "    auc, aupr, y_true, y_pred = test(\n",
    "        model,\n",
    "        myloss,\n",
    "        drug_loader_valid,\n",
    "        cline_loader_valid,\n",
    "        glo_loader_valid,\n",
    "        label_valid,\n",
    "    )\n",
    "    return auc, aupr, y_true, y_pred\n",
    "\n",
    "\n",
    "def train_and_validate_fold(train_set, validation_set, args):\n",
    "    \"\"\"Main training and validation function for one fold\"\"\"\n",
    "    print(\n",
    "        f\"Train set size: {len(train_set)}, Validation set size: {len(validation_set)}\"\n",
    "    )\n",
    "\n",
    "    # Matrix factorization\n",
    "    drug_glofeat, cline_glofeat = prepare_matrix_factorization(train_set)\n",
    "    glo_dim = 2 * drug_glofeat.shape[1]\n",
    "\n",
    "    # Prepare data\n",
    "    batch_sizes = args.bs\n",
    "    loaders = prepare_data_loaders(\n",
    "        train_set, validation_set, drug_glofeat, cline_glofeat, batch_sizes\n",
    "    )\n",
    "    train_loaders = loaders[:4]\n",
    "    valid_loaders = loaders[4:8]\n",
    "\n",
    "    # Setup model\n",
    "    model, optimizer, myloss = setup_model(drug_dim, glo_dim, device, args)\n",
    "\n",
    "    # Training loop\n",
    "    # print(\"\\nStarting training...\")\n",
    "    start = time.time()\n",
    "    best_auc = 0\n",
    "    best_aupr = 0\n",
    "\n",
    "    for epoch in range(args.ep):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{args.ep}\")\n",
    "\n",
    "        # Train\n",
    "        # print(\"Training...\")\n",
    "        train_epoch(model, train_loaders, optimizer, myloss)\n",
    "\n",
    "        # Validate\n",
    "        # print(\"Validating...\")\n",
    "        auc, aupr, y_true, y_pred = validate(model, valid_loaders, myloss)\n",
    "        print(f\"Test AUC: {auc:.4f}, Test AUPR: {aupr:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if auc > best_auc:\n",
    "            # print(\"New best model found! Saving...\")\n",
    "            best_auc = auc\n",
    "            best_aupr = aupr\n",
    "            best_pred = y_pred\n",
    "            torch.save(model.state_dict(), f\"{args.o}classification_model.pkl\")\n",
    "\n",
    "    training_time = time.time() - start\n",
    "    print(f\"Best AUC: {best_auc:.4f}, Best AUPR: {best_aupr:.4f}\")\n",
    "    return best_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c680a58-efc5-4337-aa85-9564ad60eba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_cross_validation(args):\n",
    "    \"\"\"Run k-fold cross validation\"\"\"\n",
    "    print(\"\\nStarting 5-fold cross validation...\")\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    best_preds = []\n",
    "    y_trues = []\n",
    "\n",
    "    for train_index, test_index in kfold.split(np.arange(pos_num)):\n",
    "\n",
    "        sampler = Sampler(res, train_index, test_index, null_mask)\n",
    "\n",
    "        train_data = pd.DataFrame(\n",
    "            sampler.train_data, index=res.index, columns=res.columns\n",
    "        )\n",
    "        test_data = pd.DataFrame(\n",
    "            sampler.test_data, index=res.index, columns=res.columns\n",
    "        )\n",
    "\n",
    "        train_mask = pd.DataFrame(\n",
    "            sampler.train_mask, index=res.index, columns=res.columns\n",
    "        )\n",
    "        test_mask = pd.DataFrame(\n",
    "            sampler.test_mask, index=res.index, columns=res.columns\n",
    "        )\n",
    "\n",
    "        train = pd.DataFrame(train_mask.values.nonzero()).T\n",
    "        train[2] = train_data.values[train_mask.values.nonzero()].astype(int)\n",
    "\n",
    "        test = pd.DataFrame(test_mask.values.nonzero()).T\n",
    "        test[2] = test_data.values[test_mask.values.nonzero()].astype(int)\n",
    "\n",
    "        train[0] = [cells[i] for i in train[0]]\n",
    "        train[1] = [drugs[i] for i in train[1]]\n",
    "\n",
    "        test[0] = [cells[i] for i in test[0]]\n",
    "        test[1] = [drugs[i] for i in test[1]]\n",
    "\n",
    "        cols = [\"Cline\", \"Drug\", \"Values\"]\n",
    "\n",
    "        train.columns = cols\n",
    "        test.columns = cols\n",
    "\n",
    "        train_set = train\n",
    "        validation_set = test\n",
    "        best_pred, y_true = train_and_validate_fold(train_set, validation_set, args)\n",
    "        best_preds.append(best_pred)\n",
    "        y_trues.append(y_true)\n",
    "\n",
    "    pd.DataFrame(best_preds).to_csv(f\"pred_{tmp}.csv\")\n",
    "    pd.DataFrame(y_trues).to_csv(f\"true_{tmp}.csv\")\n",
    "\n",
    "    return pd.DataFrame(best_preds), pd.DataFrame(y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70098482-6e1c-4e61-bcfe-b1c76ad95f76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load gdsc2\n",
      "\n",
      "Starting 5-fold cross validation...\n",
      "Train set size: 178648, Validation set size: 11466\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m drugs \u001b[38;5;241m=\u001b[39m {i: j \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(res\u001b[38;5;241m.\u001b[39mcolumns)}\n\u001b[1;32m      4\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 5\u001b[0m best, true \u001b[38;5;241m=\u001b[39m \u001b[43mrun_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 45\u001b[0m, in \u001b[0;36mrun_cross_validation\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     43\u001b[0m train_set \u001b[38;5;241m=\u001b[39m train\n\u001b[1;32m     44\u001b[0m validation_set \u001b[38;5;241m=\u001b[39m test\n\u001b[0;32m---> 45\u001b[0m best_pred, y_true \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_validate_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m best_preds\u001b[38;5;241m.\u001b[39mappend(best_pred)\n\u001b[1;32m     47\u001b[0m y_trues\u001b[38;5;241m.\u001b[39mappend(y_true)\n",
      "Cell \u001b[0;32mIn[5], line 158\u001b[0m, in \u001b[0;36mtrain_and_validate_fold\u001b[0;34m(train_set, validation_set, args)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# print(\"Training...\")\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmyloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# print(\"Validating...\")\u001b[39;00m\n\u001b[1;32m    162\u001b[0m auc, aupr, y_true, y_pred \u001b[38;5;241m=\u001b[39m validate(model, valid_loaders, myloss)\n",
      "Cell \u001b[0;32mIn[5], line 101\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loaders, optimizer, myloss)\u001b[0m\n\u001b[1;32m     99\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    100\u001b[0m drug_loader_train, cline_loader_train, glo_loader_train, label_train \u001b[38;5;241m=\u001b[39m loaders\n\u001b[0;32m--> 101\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmyloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrug_loader_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcline_loader_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglo_loader_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/spin1/home/linux/inouey2/DRBenchmark/SubCDR/main_classify.py:107\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, myloss, drug_loader_train, cline_loader_train, glo_loader_train, label_train)\u001b[0m\n\u001b[1;32m    105\u001b[0m loss_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    106\u001b[0m Y_true, Y_pred \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (drug, cline, glo_feat, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mzip\u001b[39m(drug_loader_train, cline_loader_train, glo_loader_train, label_train)\n\u001b[1;32m    109\u001b[0m ):\n\u001b[1;32m    110\u001b[0m     label \u001b[38;5;241m=\u001b[39m getBinary(label[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    111\u001b[0m     pred, _ \u001b[38;5;241m=\u001b[39m model(drug\u001b[38;5;241m.\u001b[39mto(device), cline\u001b[38;5;241m.\u001b[39mto(device), glo_feat\u001b[38;5;241m.\u001b[39mto(device))\n",
      "File \u001b[0;32m/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/spin1/home/linux/inouey2/DRBenchmark/SubCDR/torch_dataset.py:21\u001b[0m, in \u001b[0;36mPairsData.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):  \u001b[38;5;66;03m# 返回的是tensor\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     s1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     s2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md2[index])\n\u001b[1;32m     23\u001b[0m     data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((s1, s2), \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res, exprs, null_mask, pos_num = load_data(args)\n",
    "cells = {i: j for i, j in enumerate(res.index)}\n",
    "drugs = {i: j for i, j in enumerate(res.columns)}\n",
    "k = 5\n",
    "best, true = run_cross_validation(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97506070-e7c1-4c45-97ee-882145c9358f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a7c5c-9fe1-425b-81c7-39ca738d2f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b277777-1da9-417f-aba0-ab87f8fcbdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d515c-c1cf-448f-9f0b-188235acbac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2983b61-dccf-431f-ae3a-b602818cbeab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72396eac-9482-4c08-b5fd-1561c09df274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32aba7d-63bb-4fb7-82c1-cc6117926664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf813734-2057-4efa-a4c9-9bd253cc93fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be883e4a-dc79-432f-a1f3-e39caf48bd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genex",
   "language": "python",
   "name": "genex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
