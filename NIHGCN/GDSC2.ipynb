{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20439e7-025d-4489-8a64-3dd3cba26832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd02a138-b06d-4cff-93b8-8fd9c0f73c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from load_data import load_data\n",
    "from model import Optimizer, nihgcn\n",
    "from myutils import *\n",
    "from sampler import RandomSampler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "914e98a0-69fc-4c61-97d3-e5ee0a37cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.device = \"cuda:0\"  # cuda:number or cpu\n",
    "        self.data = \"gdsc2\"  # Dataset{gdsc or ccle}\n",
    "        self.lr = 0.001  # the learning rate\n",
    "        self.wd = 1e-5  # the weight decay for l2 normalizaton\n",
    "        self.layer_size = [1024, 1024]  # Output sizes of every layer\n",
    "        self.alpha = 0.25  # the scale for balance gcn and ni\n",
    "        self.gamma = 8  # the scale for sigmod\n",
    "        self.epochs = 1000  # the epochs for model\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3810b16a-58a3-4de8-a739-478968f466af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load gdsc2\n"
     ]
    }
   ],
   "source": [
    "res, drug_finger, exprs, null_mask, pos_num = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "838ba91c-69e3-494d-9f89-47d69e76642e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss:0.705132 auc:0.4852\n",
      "epoch:  20 loss:0.138467 auc:0.9684\n",
      "epoch:  40 loss:0.123824 auc:0.9741\n",
      "epoch:  60 loss:0.111770 auc:0.9783\n",
      "epoch:  80 loss:0.103934 auc:0.9807\n",
      "epoch: 100 loss:0.098278 auc:0.9819\n",
      "epoch: 120 loss:0.092646 auc:0.9830\n",
      "epoch: 140 loss:0.087156 auc:0.9837\n",
      "epoch: 160 loss:0.082540 auc:0.9839\n",
      "epoch: 180 loss:0.080363 auc:0.9832\n",
      "epoch: 200 loss:0.076553 auc:0.9840\n",
      "epoch: 220 loss:0.074182 auc:0.9839\n",
      "epoch: 240 loss:0.072330 auc:0.9840\n",
      "epoch: 260 loss:0.072442 auc:0.9835\n",
      "epoch: 280 loss:0.070156 auc:0.9841\n",
      "epoch: 300 loss:0.069760 auc:0.9836\n",
      "epoch: 320 loss:0.068500 auc:0.9842\n",
      "epoch: 340 loss:0.067958 auc:0.9842\n",
      "epoch: 360 loss:0.068261 auc:0.9842\n",
      "epoch: 380 loss:0.067340 auc:0.9840\n",
      "epoch: 400 loss:0.068031 auc:0.9841\n",
      "epoch: 420 loss:0.066811 auc:0.9838\n",
      "epoch: 440 loss:0.066503 auc:0.9840\n",
      "epoch: 460 loss:0.066475 auc:0.9839\n",
      "epoch: 480 loss:0.066303 auc:0.9841\n",
      "epoch: 500 loss:0.067673 auc:0.9826\n",
      "epoch: 520 loss:0.065775 auc:0.9839\n",
      "epoch: 540 loss:0.066122 auc:0.9837\n",
      "epoch: 560 loss:0.065752 auc:0.9840\n",
      "epoch: 580 loss:0.065611 auc:0.9837\n",
      "epoch: 600 loss:0.065547 auc:0.9836\n",
      "epoch: 620 loss:0.066574 auc:0.9827\n",
      "epoch: 640 loss:0.065279 auc:0.9837\n",
      "epoch: 660 loss:0.065208 auc:0.9838\n",
      "epoch: 680 loss:0.067092 auc:0.9833\n",
      "epoch: 700 loss:0.065314 auc:0.9838\n",
      "epoch: 720 loss:0.065034 auc:0.9838\n",
      "epoch: 740 loss:0.064943 auc:0.9838\n",
      "epoch: 760 loss:0.066034 auc:0.9838\n",
      "epoch: 780 loss:0.064967 auc:0.9837\n",
      "epoch: 800 loss:0.065140 auc:0.9838\n",
      "epoch: 820 loss:0.066450 auc:0.9834\n",
      "epoch: 840 loss:0.064948 auc:0.9837\n",
      "epoch: 860 loss:0.064762 auc:0.9838\n",
      "epoch: 880 loss:0.065705 auc:0.9835\n",
      "epoch: 900 loss:0.064817 auc:0.9837\n",
      "epoch: 920 loss:0.065049 auc:0.9832\n",
      "epoch: 940 loss:0.064913 auc:0.9835\n",
      "epoch: 960 loss:0.065483 auc:0.9837\n",
      "epoch: 980 loss:0.065590 auc:0.9838\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.699503 auc:0.4952\n",
      "epoch:  20 loss:0.138971 auc:0.9679\n",
      "epoch:  40 loss:0.123463 auc:0.9743\n",
      "epoch:  60 loss:0.111053 auc:0.9779\n",
      "epoch:  80 loss:0.103008 auc:0.9801\n",
      "epoch: 100 loss:0.097007 auc:0.9810\n",
      "epoch: 120 loss:0.091373 auc:0.9817\n",
      "epoch: 140 loss:0.086388 auc:0.9824\n",
      "epoch: 160 loss:0.082109 auc:0.9828\n",
      "epoch: 180 loss:0.080015 auc:0.9828\n",
      "epoch: 200 loss:0.076391 auc:0.9830\n",
      "epoch: 220 loss:0.074184 auc:0.9832\n",
      "epoch: 240 loss:0.072402 auc:0.9834\n",
      "epoch: 260 loss:0.073002 auc:0.9823\n",
      "epoch: 280 loss:0.070219 auc:0.9835\n",
      "epoch: 300 loss:0.069923 auc:0.9832\n",
      "epoch: 320 loss:0.068662 auc:0.9834\n",
      "epoch: 340 loss:0.068138 auc:0.9834\n",
      "epoch: 360 loss:0.068631 auc:0.9835\n",
      "epoch: 380 loss:0.067513 auc:0.9834\n",
      "epoch: 400 loss:0.067037 auc:0.9835\n",
      "epoch: 420 loss:0.067423 auc:0.9831\n",
      "epoch: 440 loss:0.066859 auc:0.9835\n",
      "epoch: 460 loss:0.066376 auc:0.9834\n",
      "epoch: 480 loss:0.068275 auc:0.9823\n",
      "epoch: 500 loss:0.066361 auc:0.9836\n",
      "epoch: 520 loss:0.065989 auc:0.9834\n",
      "epoch: 540 loss:0.066390 auc:0.9831\n",
      "epoch: 560 loss:0.065976 auc:0.9835\n",
      "epoch: 580 loss:0.065793 auc:0.9834\n",
      "epoch: 600 loss:0.067507 auc:0.9823\n",
      "epoch: 620 loss:0.065752 auc:0.9833\n",
      "epoch: 640 loss:0.065625 auc:0.9833\n",
      "epoch: 660 loss:0.067484 auc:0.9834\n",
      "epoch: 680 loss:0.065525 auc:0.9833\n",
      "epoch: 700 loss:0.065299 auc:0.9833\n",
      "epoch: 720 loss:0.065851 auc:0.9829\n",
      "epoch: 740 loss:0.065454 auc:0.9831\n",
      "epoch: 760 loss:0.065222 auc:0.9833\n",
      "epoch: 780 loss:0.066117 auc:0.9832\n",
      "epoch: 800 loss:0.065203 auc:0.9832\n",
      "epoch: 820 loss:0.065056 auc:0.9832\n",
      "epoch: 840 loss:0.069664 auc:0.9825\n",
      "epoch: 860 loss:0.065654 auc:0.9831\n",
      "epoch: 880 loss:0.065104 auc:0.9832\n",
      "epoch: 900 loss:0.065264 auc:0.9833\n",
      "epoch: 920 loss:0.065140 auc:0.9830\n",
      "epoch: 940 loss:0.065235 auc:0.9831\n",
      "epoch: 960 loss:0.066017 auc:0.9827\n",
      "epoch: 980 loss:0.064930 auc:0.9832\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.693982 auc:0.5238\n",
      "epoch:  20 loss:0.139700 auc:0.9679\n",
      "epoch:  40 loss:0.124386 auc:0.9735\n",
      "epoch:  60 loss:0.111372 auc:0.9778\n",
      "epoch:  80 loss:0.103526 auc:0.9797\n",
      "epoch: 100 loss:0.097782 auc:0.9806\n",
      "epoch: 120 loss:0.092262 auc:0.9814\n",
      "epoch: 140 loss:0.087076 auc:0.9821\n",
      "epoch: 160 loss:0.082683 auc:0.9827\n",
      "epoch: 180 loss:0.079400 auc:0.9830\n",
      "epoch: 200 loss:0.076382 auc:0.9833\n",
      "epoch: 220 loss:0.075676 auc:0.9831\n",
      "epoch: 240 loss:0.072496 auc:0.9835\n",
      "epoch: 260 loss:0.072988 auc:0.9832\n",
      "epoch: 280 loss:0.070270 auc:0.9836\n",
      "epoch: 300 loss:0.072333 auc:0.9822\n",
      "epoch: 320 loss:0.069191 auc:0.9837\n",
      "epoch: 340 loss:0.068277 auc:0.9837\n",
      "epoch: 360 loss:0.069907 auc:0.9829\n",
      "epoch: 380 loss:0.067597 auc:0.9838\n",
      "epoch: 400 loss:0.067100 auc:0.9837\n",
      "epoch: 420 loss:0.068602 auc:0.9835\n",
      "epoch: 440 loss:0.066887 auc:0.9837\n",
      "epoch: 460 loss:0.066473 auc:0.9837\n",
      "epoch: 480 loss:0.067021 auc:0.9832\n",
      "epoch: 500 loss:0.066205 auc:0.9836\n",
      "epoch: 520 loss:0.066108 auc:0.9835\n",
      "epoch: 540 loss:0.066372 auc:0.9835\n",
      "epoch: 560 loss:0.066217 auc:0.9834\n",
      "epoch: 580 loss:0.065825 auc:0.9835\n",
      "epoch: 600 loss:0.066566 auc:0.9836\n",
      "epoch: 620 loss:0.065746 auc:0.9836\n",
      "epoch: 640 loss:0.065548 auc:0.9834\n",
      "epoch: 660 loss:0.066541 auc:0.9832\n",
      "epoch: 680 loss:0.066624 auc:0.9833\n",
      "epoch: 700 loss:0.065561 auc:0.9834\n",
      "epoch: 720 loss:0.065372 auc:0.9834\n",
      "epoch: 740 loss:0.067641 auc:0.9829\n",
      "epoch: 760 loss:0.065626 auc:0.9835\n",
      "epoch: 780 loss:0.065345 auc:0.9835\n",
      "epoch: 800 loss:0.065469 auc:0.9835\n",
      "epoch: 820 loss:0.065948 auc:0.9829\n",
      "epoch: 840 loss:0.065235 auc:0.9833\n",
      "epoch: 860 loss:0.066341 auc:0.9832\n",
      "epoch: 880 loss:0.065235 auc:0.9833\n",
      "epoch: 900 loss:0.065717 auc:0.9829\n",
      "epoch: 920 loss:0.065494 auc:0.9834\n",
      "epoch: 940 loss:0.065093 auc:0.9834\n",
      "epoch: 960 loss:0.067026 auc:0.9821\n",
      "epoch: 980 loss:0.065180 auc:0.9833\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.697343 auc:0.4843\n",
      "epoch:  20 loss:0.138765 auc:0.9682\n",
      "epoch:  40 loss:0.124319 auc:0.9740\n",
      "epoch:  60 loss:0.112280 auc:0.9779\n",
      "epoch:  80 loss:0.104482 auc:0.9802\n",
      "epoch: 100 loss:0.098669 auc:0.9817\n",
      "epoch: 120 loss:0.093055 auc:0.9828\n",
      "epoch: 140 loss:0.087739 auc:0.9835\n",
      "epoch: 160 loss:0.085282 auc:0.9837\n",
      "epoch: 180 loss:0.079596 auc:0.9841\n",
      "epoch: 200 loss:0.076419 auc:0.9842\n",
      "epoch: 220 loss:0.074624 auc:0.9842\n",
      "epoch: 240 loss:0.073071 auc:0.9840\n",
      "epoch: 260 loss:0.071291 auc:0.9842\n",
      "epoch: 280 loss:0.072928 auc:0.9830\n",
      "epoch: 300 loss:0.069591 auc:0.9843\n",
      "epoch: 320 loss:0.068918 auc:0.9842\n",
      "epoch: 340 loss:0.068245 auc:0.9843\n",
      "epoch: 360 loss:0.068635 auc:0.9842\n",
      "epoch: 380 loss:0.067466 auc:0.9842\n",
      "epoch: 400 loss:0.067089 auc:0.9843\n",
      "epoch: 420 loss:0.067539 auc:0.9836\n",
      "epoch: 440 loss:0.067491 auc:0.9837\n",
      "epoch: 460 loss:0.066436 auc:0.9842\n",
      "epoch: 480 loss:0.067387 auc:0.9839\n",
      "epoch: 500 loss:0.066523 auc:0.9841\n",
      "epoch: 520 loss:0.065979 auc:0.9841\n",
      "epoch: 540 loss:0.066690 auc:0.9838\n",
      "epoch: 560 loss:0.065832 auc:0.9840\n",
      "epoch: 580 loss:0.068965 auc:0.9830\n",
      "epoch: 600 loss:0.065861 auc:0.9839\n",
      "epoch: 620 loss:0.065565 auc:0.9839\n",
      "epoch: 640 loss:0.066027 auc:0.9836\n",
      "epoch: 660 loss:0.065433 auc:0.9839\n",
      "epoch: 680 loss:0.067512 auc:0.9831\n",
      "epoch: 700 loss:0.065483 auc:0.9840\n",
      "epoch: 720 loss:0.065714 auc:0.9840\n",
      "epoch: 740 loss:0.065620 auc:0.9835\n",
      "epoch: 760 loss:0.065206 auc:0.9838\n",
      "epoch: 780 loss:0.067624 auc:0.9830\n",
      "epoch: 800 loss:0.065411 auc:0.9839\n",
      "epoch: 820 loss:0.065120 auc:0.9838\n",
      "epoch: 840 loss:0.065132 auc:0.9838\n",
      "epoch: 860 loss:0.065244 auc:0.9837\n",
      "epoch: 880 loss:0.065236 auc:0.9839\n",
      "epoch: 900 loss:0.065108 auc:0.9838\n",
      "epoch: 920 loss:0.066300 auc:0.9830\n",
      "epoch: 940 loss:0.065585 auc:0.9838\n",
      "epoch: 960 loss:0.064990 auc:0.9838\n",
      "epoch: 980 loss:0.065189 auc:0.9837\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.705088 auc:0.5057\n",
      "epoch:  20 loss:0.138828 auc:0.9660\n",
      "epoch:  40 loss:0.123757 auc:0.9717\n",
      "epoch:  60 loss:0.111479 auc:0.9756\n",
      "epoch:  80 loss:0.103743 auc:0.9778\n",
      "epoch: 100 loss:0.097871 auc:0.9794\n",
      "epoch: 120 loss:0.092436 auc:0.9802\n",
      "epoch: 140 loss:0.087227 auc:0.9809\n",
      "epoch: 160 loss:0.082429 auc:0.9817\n",
      "epoch: 180 loss:0.078867 auc:0.9821\n",
      "epoch: 200 loss:0.076119 auc:0.9823\n",
      "epoch: 220 loss:0.074006 auc:0.9823\n",
      "epoch: 240 loss:0.072985 auc:0.9821\n",
      "epoch: 260 loss:0.071330 auc:0.9823\n",
      "epoch: 280 loss:0.071005 auc:0.9822\n",
      "epoch: 300 loss:0.069374 auc:0.9824\n",
      "epoch: 320 loss:0.069726 auc:0.9819\n",
      "epoch: 340 loss:0.068170 auc:0.9824\n",
      "epoch: 360 loss:0.068747 auc:0.9819\n",
      "epoch: 380 loss:0.067399 auc:0.9823\n",
      "epoch: 400 loss:0.067509 auc:0.9823\n",
      "epoch: 420 loss:0.066697 auc:0.9824\n",
      "epoch: 440 loss:0.066789 auc:0.9821\n",
      "epoch: 460 loss:0.066452 auc:0.9823\n",
      "epoch: 480 loss:0.066219 auc:0.9823\n",
      "epoch: 500 loss:0.067345 auc:0.9818\n",
      "epoch: 520 loss:0.066000 auc:0.9822\n",
      "epoch: 540 loss:0.068260 auc:0.9818\n",
      "epoch: 560 loss:0.065919 auc:0.9821\n",
      "epoch: 580 loss:0.065506 auc:0.9822\n",
      "epoch: 600 loss:0.067332 auc:0.9819\n",
      "epoch: 620 loss:0.066155 auc:0.9822\n",
      "epoch: 640 loss:0.065406 auc:0.9822\n",
      "epoch: 660 loss:0.065237 auc:0.9822\n",
      "epoch: 680 loss:0.065566 auc:0.9821\n",
      "epoch: 700 loss:0.065249 auc:0.9822\n",
      "epoch: 720 loss:0.065218 auc:0.9821\n",
      "epoch: 740 loss:0.065188 auc:0.9821\n",
      "epoch: 760 loss:0.066450 auc:0.9818\n",
      "epoch: 780 loss:0.065220 auc:0.9822\n",
      "epoch: 800 loss:0.067086 auc:0.9817\n",
      "epoch: 820 loss:0.065234 auc:0.9821\n",
      "epoch: 840 loss:0.065044 auc:0.9820\n",
      "epoch: 860 loss:0.065788 auc:0.9815\n",
      "epoch: 880 loss:0.065212 auc:0.9822\n",
      "epoch: 900 loss:0.064827 auc:0.9821\n",
      "epoch: 920 loss:0.066733 auc:0.9816\n",
      "epoch: 940 loss:0.064906 auc:0.9821\n",
      "epoch: 960 loss:0.067177 auc:0.9813\n",
      "epoch: 980 loss:0.065123 auc:0.9817\n",
      "Fit finished.\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "true_datas = pd.DataFrame()\n",
    "predict_datas = pd.DataFrame()\n",
    "\n",
    "for train_index, test_index in kfold.split(np.arange(pos_num)):\n",
    "    sampler = RandomSampler(res, train_index, test_index, null_mask)\n",
    "    model = nihgcn(\n",
    "        adj_mat=sampler.train_data,\n",
    "        cell_exprs=exprs,\n",
    "        drug_finger=drug_finger,\n",
    "        layer_size=args.layer_size,\n",
    "        alpha=args.alpha,\n",
    "        gamma=args.gamma,\n",
    "        device=args.device,\n",
    "    ).to(args.device)\n",
    "    opt = Optimizer(\n",
    "        model,\n",
    "        sampler.train_data,\n",
    "        sampler.test_data,\n",
    "        sampler.test_mask,\n",
    "        sampler.train_mask,\n",
    "        roc_auc,\n",
    "        lr=args.lr,\n",
    "        wd=args.wd,\n",
    "        epochs=args.epochs,\n",
    "        device=args.device,\n",
    "    ).to(args.device)\n",
    "    true_data, predict_data = opt()\n",
    "    true_datas = pd.concat([true_datas, translate_result(true_data)], ignore_index=True)\n",
    "    predict_datas = pd.concat(\n",
    "        [predict_datas, translate_result(predict_data)], ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a87fb88-253c-46b5-a367-df7ea05cbf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_datas.to_csv(\"true_gdsc2.csv\")\n",
    "predict_datas.to_csv(\"pred_gdsc2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7184ada-620d-4f1e-ab5c-60c8ce997a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genex",
   "language": "python",
   "name": "genex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
