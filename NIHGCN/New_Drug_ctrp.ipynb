{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20439e7-025d-4489-8a64-3dd3cba26832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd02a138-b06d-4cff-93b8-8fd9c0f73c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from load_data import load_data\n",
    "from model import Optimizer, nihgcn\n",
    "from myutils import *\n",
    "from sampler import NewSampler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "914e98a0-69fc-4c61-97d3-e5ee0a37cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )  # cuda:number or cpu\n",
    "        self.data = \"ctrp\"  # Dataset{gdsc or ccle}\n",
    "        self.lr = 0.001  # the learning rate\n",
    "        self.wd = 1e-5  # the weight decay for l2 normalizaton\n",
    "        self.layer_size = [1024, 1024]  # Output sizes of every layer\n",
    "        self.alpha = 0.25  # the scale for balance gcn and ni\n",
    "        self.gamma = 8  # the scale for sigmod\n",
    "        self.epochs = 1000  # the epochs for model\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3810b16a-58a3-4de8-a739-478968f466af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res, drug_finger, exprs, null_mask, pos_num = load_data(args)\n",
    "cell_sum = np.sum(res, axis=1)\n",
    "drug_sum = np.sum(res, axis=0)\n",
    "\n",
    "target_dim = [\n",
    "    # 0,  # Cell\n",
    "    1  # Drug\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03e6709-b358-4c5b-91bf-082f827a81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nihgcn_new(\n",
    "    cell_exprs,\n",
    "    drug_finger,\n",
    "    res_mat,\n",
    "    null_mask,\n",
    "    target_dim,\n",
    "    target_index,\n",
    "    evaluate_fun,\n",
    "    args,\n",
    "    seed,\n",
    "):\n",
    "\n",
    "    sampler = NewSampler(res_mat, null_mask, target_dim, target_index, seed)\n",
    "\n",
    "    val_labels = sampler.test_data[sampler.test_mask]\n",
    "\n",
    "    if len(np.unique(val_labels)) < 2:\n",
    "        print(f\"Target {target_index} skipped: Validation set has only one class.\")\n",
    "        return None, None\n",
    "\n",
    "    model = nihgcn(\n",
    "        sampler.train_data,\n",
    "        cell_exprs=cell_exprs,\n",
    "        drug_finger=drug_finger,\n",
    "        layer_size=args.layer_size,\n",
    "        alpha=args.alpha,\n",
    "        gamma=args.gamma,\n",
    "        device=args.device,\n",
    "    )\n",
    "    opt = Optimizer(\n",
    "        model,\n",
    "        sampler.train_data,\n",
    "        sampler.test_data,\n",
    "        sampler.test_mask,\n",
    "        sampler.train_mask,\n",
    "        evaluate_fun,\n",
    "        lr=args.lr,\n",
    "        wd=args.wd,\n",
    "        epochs=args.epochs,\n",
    "        device=args.device,\n",
    "    )\n",
    "    true_data, predict_data = opt()\n",
    "    return true_data, predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4138fc51-acbb-46b5-960d-9c9aa20c2cde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dim 1:   0%|                                                         | 0/460 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss:0.700125 auc:0.6650\n",
      "epoch:   0 loss:0.701826 auc:0.5306\n",
      "epoch:   0 loss:0.698057 auc:0.5485\n",
      "epoch:   0 loss:0.699401 auc:0.5259\n",
      "epoch:   0 loss:0.699864 auc:0.4961\n",
      "epoch:  20 loss:0.352026 auc:0.5825\n",
      "epoch:  20 loss:0.353488 auc:0.6670\n",
      "epoch:  20 loss:0.354796 auc:0.6603\n",
      "epoch:  20 loss:0.353556 auc:0.7383\n",
      "epoch:  20 loss:0.352843 auc:0.7519\n",
      "epoch:  40 loss:0.330609 auc:0.7109\n",
      "epoch:  40 loss:0.328146 auc:0.5850\n",
      "epoch:  40 loss:0.329086 auc:0.8906\n",
      "epoch:  40 loss:0.327884 auc:0.6685\n",
      "epoch:  40 loss:0.327367 auc:0.7348\n",
      "epoch:  60 loss:0.307274 auc:0.5750\n",
      "epoch:  60 loss:0.310535 auc:0.9570\n",
      "epoch:  60 loss:0.304176 auc:0.6364\n",
      "epoch:  60 loss:0.304537 auc:0.7469\n",
      "epoch:  60 loss:0.311164 auc:0.7107\n",
      "epoch:  80 loss:0.282168 auc:0.9492\n",
      "epoch:  80 loss:0.282012 auc:0.6325\n",
      "epoch:  80 loss:0.279761 auc:0.7534\n",
      "epoch:  80 loss:0.281367 auc:0.6582\n",
      "epoch: 100 loss:0.262552 auc:0.9258\n",
      "epoch:  80 loss:0.286870 auc:0.7139\n",
      "epoch: 100 loss:0.261070 auc:0.7711\n",
      "epoch: 100 loss:0.262578 auc:0.6025\n",
      "epoch: 100 loss:0.261425 auc:0.6547\n",
      "epoch: 120 loss:0.251437 auc:0.8984\n",
      "epoch: 100 loss:0.276265 auc:0.7267\n",
      "epoch: 120 loss:0.248904 auc:0.7773\n",
      "epoch: 120 loss:0.257777 auc:0.6543\n",
      "epoch: 120 loss:0.250481 auc:0.5875\n",
      "epoch: 140 loss:0.242453 auc:0.8828\n",
      "epoch: 140 loss:0.241528 auc:0.7765\n",
      "epoch: 120 loss:0.253820 auc:0.7507\n",
      "epoch: 140 loss:0.242303 auc:0.5870\n",
      "epoch: 140 loss:0.252037 auc:0.6825\n",
      "epoch: 160 loss:0.236548 auc:0.8594\n",
      "epoch: 160 loss:0.235794 auc:0.7714\n",
      "epoch: 140 loss:0.243969 auc:0.7629\n",
      "epoch: 160 loss:0.239404 auc:0.5940\n",
      "epoch: 160 loss:0.237041 auc:0.6175\n",
      "epoch: 180 loss:0.233219 auc:0.8359\n",
      "epoch: 180 loss:0.232350 auc:0.7693\n",
      "epoch: 180 loss:0.232217 auc:0.5690\n",
      "epoch: 160 loss:0.237668 auc:0.7466\n",
      "epoch: 200 loss:0.229694 auc:0.8555\n",
      "epoch: 180 loss:0.233420 auc:0.6350\n",
      "epoch: 200 loss:0.236155 auc:0.7554\n",
      "epoch: 220 loss:0.227715 auc:0.8281\n",
      "epoch: 180 loss:0.234269 auc:0.7487\n",
      "epoch: 200 loss:0.231125 auc:0.5733\n",
      "epoch: 200 loss:0.229698 auc:0.6425\n",
      "epoch: 220 loss:0.227250 auc:0.7733\n",
      "epoch: 240 loss:0.228177 auc:0.8203\n",
      "epoch: 220 loss:0.227623 auc:0.5879\n",
      "epoch: 200 loss:0.230711 auc:0.7534\n",
      "epoch: 220 loss:0.227680 auc:0.6425\n",
      "epoch: 240 loss:0.227095 auc:0.7713\n",
      "epoch: 260 loss:0.224703 auc:0.8125\n",
      "epoch: 220 loss:0.232872 auc:0.7412\n",
      "epoch: 240 loss:0.226136 auc:0.5762\n",
      "epoch: 240 loss:0.226421 auc:0.6550\n",
      "epoch: 260 loss:0.223531 auc:0.7752\n",
      "epoch: 280 loss:0.229946 auc:0.8906\n",
      "epoch: 240 loss:0.225740 auc:0.7164\n",
      "epoch: 260 loss:0.225841 auc:0.5332\n",
      "epoch: 260 loss:0.224595 auc:0.6600\n",
      "epoch: 300 loss:0.222447 auc:0.8203\n",
      "epoch: 280 loss:0.227751 auc:0.7808\n",
      "epoch: 260 loss:0.225252 auc:0.6906\n",
      "epoch: 280 loss:0.222964 auc:0.5273\n",
      "epoch: 280 loss:0.224978 auc:0.6700\n",
      "epoch: 300 loss:0.221642 auc:0.7732\n",
      "epoch: 320 loss:0.222842 auc:0.8438\n",
      "epoch: 280 loss:0.223074 auc:0.7032\n",
      "epoch: 300 loss:0.223436 auc:0.5142\n",
      "epoch: 300 loss:0.223125 auc:0.6850\n",
      "epoch: 320 loss:0.220220 auc:0.7765\n",
      "epoch: 340 loss:0.219977 auc:0.8359\n",
      "epoch: 300 loss:0.222115 auc:0.7085\n",
      "epoch: 320 loss:0.220733 auc:0.5260\n",
      "epoch: 320 loss:0.221065 auc:0.6775\n",
      "epoch: 340 loss:0.224469 auc:0.7615\n",
      "epoch: 360 loss:0.222105 auc:0.8398\n",
      "epoch: 320 loss:0.231566 auc:0.6755\n",
      "epoch: 340 loss:0.224539 auc:0.5509\n",
      "epoch: 360 loss:0.219362 auc:0.7805\n",
      "epoch: 340 loss:0.221033 auc:0.6700\n",
      "epoch: 380 loss:0.218684 auc:0.8516\n",
      "epoch: 380 loss:0.218088 auc:0.7780\n",
      "epoch: 360 loss:0.219642 auc:0.5227\n",
      "epoch: 340 loss:0.220788 auc:0.7270\n",
      "epoch: 360 loss:0.219648 auc:0.6650\n",
      "epoch: 400 loss:0.220253 auc:0.8516\n",
      "epoch: 400 loss:0.221582 auc:0.7854\n",
      "epoch: 380 loss:0.222905 auc:0.7100\n",
      "epoch: 380 loss:0.219317 auc:0.5058\n",
      "epoch: 360 loss:0.218867 auc:0.7157\n",
      "epoch: 420 loss:0.217884 auc:0.8477\n",
      "epoch: 400 loss:0.218663 auc:0.5236\n",
      "epoch: 420 loss:0.217815 auc:0.7794\n",
      "epoch: 400 loss:0.218409 auc:0.6825\n",
      "epoch: 380 loss:0.220635 auc:0.7078\n",
      "epoch: 440 loss:0.216889 auc:0.8398\n",
      "epoch: 420 loss:0.217372 auc:0.5200\n",
      "epoch: 440 loss:0.216738 auc:0.7754\n",
      "epoch: 420 loss:0.219324 auc:0.6700\n",
      "epoch: 400 loss:0.217896 auc:0.7154\n",
      "epoch: 460 loss:0.217471 auc:0.8359\n",
      "epoch: 440 loss:0.217753 auc:0.5348\n",
      "epoch: 460 loss:0.218865 auc:0.7796\n",
      "epoch: 440 loss:0.217441 auc:0.6625\n",
      "epoch: 420 loss:0.217646 auc:0.7082\n",
      "epoch: 480 loss:0.216169 auc:0.8281\n",
      "epoch: 460 loss:0.216672 auc:0.5228\n",
      "epoch: 460 loss:0.219245 auc:0.6750\n",
      "epoch: 480 loss:0.216630 auc:0.7750\n",
      "epoch: 500 loss:0.216678 auc:0.8008\n",
      "epoch: 440 loss:0.216479 auc:0.6980\n",
      "epoch: 480 loss:0.216867 auc:0.5335\n",
      "epoch: 480 loss:0.217098 auc:0.6850\n",
      "epoch: 500 loss:0.215568 auc:0.7716\n",
      "epoch: 520 loss:0.215355 auc:0.8320\n",
      "epoch: 500 loss:0.217650 auc:0.5232\n",
      "epoch: 500 loss:0.215819 auc:0.6775\n",
      "epoch: 460 loss:0.220464 auc:0.7045\n",
      "epoch: 520 loss:0.217200 auc:0.7752\n",
      "epoch: 520 loss:0.216119 auc:0.5175\n",
      "epoch: 540 loss:0.216811 auc:0.8359\n",
      "epoch: 520 loss:0.217809 auc:0.6825\n",
      "epoch: 480 loss:0.216251 auc:0.6939\n",
      "epoch: 540 loss:0.215114 auc:0.7679\n",
      "epoch: 540 loss:0.216675 auc:0.5625\n",
      "epoch: 560 loss:0.214976 auc:0.8281\n",
      "epoch: 560 loss:0.219204 auc:0.7678\n",
      "epoch: 540 loss:0.215386 auc:0.6850\n",
      "epoch: 500 loss:0.215635 auc:0.6941\n",
      "epoch: 560 loss:0.215260 auc:0.5313\n",
      "epoch: 580 loss:0.227844 auc:0.7734\n",
      "epoch: 560 loss:0.223774 auc:0.6825\n",
      "epoch: 520 loss:0.216165 auc:0.7198\n",
      "epoch: 580 loss:0.215622 auc:0.7701\n",
      "epoch: 580 loss:0.216319 auc:0.5425\n",
      "epoch: 600 loss:0.216098 auc:0.8125\n",
      "epoch: 540 loss:0.214822 auc:0.7095\n",
      "epoch: 580 loss:0.216122 auc:0.6700\n",
      "epoch: 600 loss:0.214464 auc:0.7688\n",
      "epoch: 600 loss:0.214399 auc:0.5229\n",
      "epoch: 620 loss:0.218141 auc:0.7578\n",
      "epoch: 560 loss:0.223763 auc:0.7131\n",
      "epoch: 600 loss:0.214638 auc:0.6725\n",
      "epoch: 620 loss:0.215585 auc:0.7706\n",
      "epoch: 620 loss:0.215454 auc:0.5209\n",
      "epoch: 580 loss:0.215439 auc:0.7120\n",
      "epoch: 620 loss:0.215470 auc:0.6675\n",
      "epoch: 640 loss:0.214304 auc:0.8086\n",
      "epoch: 640 loss:0.214575 auc:0.7684\n",
      "epoch: 640 loss:0.213977 auc:0.5296\n",
      "epoch: 640 loss:0.214410 auc:0.6750\n",
      "epoch: 600 loss:0.214296 auc:0.6991\n",
      "epoch: 660 loss:0.216118 auc:0.8164\n",
      "epoch: 660 loss:0.214137 auc:0.7585\n",
      "epoch: 660 loss:0.214324 auc:0.6625\n",
      "epoch: 660 loss:0.219516 auc:0.5959\n",
      "epoch: 620 loss:0.216559 auc:0.7166\n",
      "epoch: 680 loss:0.214073 auc:0.8047\n",
      "epoch: 680 loss:0.215413 auc:0.7717\n",
      "epoch: 680 loss:0.214211 auc:0.5430\n",
      "epoch: 640 loss:0.214424 auc:0.7144\n",
      "epoch: 680 loss:0.215178 auc:0.6750\n",
      "epoch: 700 loss:0.217646 auc:0.8477\n",
      "epoch: 700 loss:0.214208 auc:0.7612\n",
      "epoch: 660 loss:0.213763 auc:0.7091\n",
      "epoch: 700 loss:0.213434 auc:0.5404\n",
      "epoch: 700 loss:0.214414 auc:0.6750\n",
      "epoch: 720 loss:0.214191 auc:0.8086\n",
      "epoch: 720 loss:0.216286 auc:0.7605\n",
      "epoch: 680 loss:0.214187 auc:0.7041\n",
      "epoch: 720 loss:0.216227 auc:0.5076\n",
      "epoch: 740 loss:0.214423 auc:0.8047\n",
      "epoch: 740 loss:0.214133 auc:0.7595\n",
      "epoch: 720 loss:0.213705 auc:0.6675\n",
      "epoch: 700 loss:0.213840 auc:0.7023\n",
      "epoch: 740 loss:0.213549 auc:0.5328\n",
      "epoch: 740 loss:0.222242 auc:0.6750\n",
      "epoch: 760 loss:0.216583 auc:0.8320\n",
      "epoch: 760 loss:0.213491 auc:0.7591\n",
      "epoch: 720 loss:0.214121 auc:0.6873\n",
      "epoch: 780 loss:0.213499 auc:0.8242\n",
      "epoch: 760 loss:0.213164 auc:0.5399\n",
      "epoch: 760 loss:0.214722 auc:0.6725\n",
      "epoch: 780 loss:0.216550 auc:0.7594\n",
      "epoch: 740 loss:0.213806 auc:0.6966\n",
      "epoch: 780 loss:0.213547 auc:0.6775\n",
      "epoch: 780 loss:0.214884 auc:0.5319\n",
      "epoch: 800 loss:0.216296 auc:0.7734\n",
      "epoch: 800 loss:0.213479 auc:0.7573\n",
      "epoch: 760 loss:0.215698 auc:0.6668\n",
      "epoch: 800 loss:0.220966 auc:0.6900\n",
      "epoch: 820 loss:0.213646 auc:0.8086\n",
      "epoch: 820 loss:0.213685 auc:0.7578\n",
      "epoch: 800 loss:0.213041 auc:0.5404\n",
      "epoch: 780 loss:0.213241 auc:0.6956\n",
      "epoch: 820 loss:0.214415 auc:0.6750\n",
      "epoch: 840 loss:0.212976 auc:0.8086\n",
      "epoch: 820 loss:0.212939 auc:0.5351\n",
      "epoch: 840 loss:0.215048 auc:0.7549\n",
      "epoch: 800 loss:0.224822 auc:0.6432\n",
      "epoch: 840 loss:0.213215 auc:0.6700\n",
      "epoch: 840 loss:0.213833 auc:0.5414\n",
      "epoch: 860 loss:0.218577 auc:0.7773\n",
      "epoch: 860 loss:0.213146 auc:0.7534\n",
      "epoch: 820 loss:0.214508 auc:0.7196\n",
      "epoch: 860 loss:0.213094 auc:0.6725\n",
      "epoch: 880 loss:0.213424 auc:0.7969\n",
      "epoch: 860 loss:0.212704 auc:0.5390\n",
      "epoch: 880 loss:0.214744 auc:0.7595\n",
      "epoch: 880 loss:0.212995 auc:0.6675\n",
      "epoch: 840 loss:0.212994 auc:0.7041\n",
      "epoch: 900 loss:0.216482 auc:0.7773\n",
      "epoch: 880 loss:0.215690 auc:0.5576\n",
      "epoch: 900 loss:0.213281 auc:0.7549\n",
      "epoch: 900 loss:0.212816 auc:0.5634\n",
      "epoch: 860 loss:0.212739 auc:0.6987\n",
      "epoch: 900 loss:0.221187 auc:0.5675\n",
      "epoch: 920 loss:0.213283 auc:0.7930\n",
      "epoch: 920 loss:0.212904 auc:0.7524\n",
      "epoch: 920 loss:0.212496 auc:0.5608\n",
      "epoch: 920 loss:0.213839 auc:0.6650\n",
      "epoch: 880 loss:0.212872 auc:0.6918\n",
      "epoch: 940 loss:0.212653 auc:0.7969\n",
      "epoch: 940 loss:0.219092 auc:0.7596\n",
      "epoch: 940 loss:0.213557 auc:0.5791\n",
      "epoch: 940 loss:0.212886 auc:0.6600\n",
      "epoch: 900 loss:0.212981 auc:0.6978\n",
      "epoch: 960 loss:0.213564 auc:0.7812\n",
      "epoch: 960 loss:0.213975 auc:0.7527\n",
      "epoch: 960 loss:0.212386 auc:0.5595\n",
      "epoch: 960 loss:0.214255 auc:0.6625\n",
      "epoch: 920 loss:0.212836 auc:0.6833\n",
      "epoch: 980 loss:0.212864 auc:0.7773\n",
      "epoch: 980 loss:0.212741 auc:0.7526\n",
      "epoch: 980 loss:0.215070 auc:0.5714\n",
      "epoch: 980 loss:0.212998 auc:0.6675\n",
      "epoch: 940 loss:0.213649 auc:0.6966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dim 1:   2%|▉                                           | 10/460 [28:40<21:30:20, 172.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit finished.\n",
      "epoch:   0 loss:0.698007 auc:0.5826\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.700253 auc:0.5228\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.702347 auc:0.5690\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.700224 auc:0.5402\n",
      "epoch: 960 loss:0.212442 auc:0.6907\n",
      "epoch:  20 loss:0.351194 auc:0.5969\n",
      "epoch:  20 loss:0.352918 auc:0.5063\n",
      "epoch:  20 loss:0.355307 auc:0.4215\n",
      "epoch:  20 loss:0.355148 auc:0.7016\n",
      "epoch: 980 loss:0.214205 auc:0.6942\n",
      "epoch:  40 loss:0.325584 auc:0.4019\n",
      "epoch:  40 loss:0.328320 auc:0.5427\n",
      "epoch:  40 loss:0.332843 auc:0.4469\n",
      "epoch:  40 loss:0.330807 auc:0.7850\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.698598 auc:0.4822\n",
      "epoch:  60 loss:0.301058 auc:0.3793\n",
      "epoch:  60 loss:0.305320 auc:0.5914\n",
      "epoch:  60 loss:0.310816 auc:0.4791\n",
      "epoch:  60 loss:0.309043 auc:0.7315\n",
      "epoch:  20 loss:0.352489 auc:0.5557\n",
      "epoch:  80 loss:0.283209 auc:0.6356\n",
      "epoch:  80 loss:0.281258 auc:0.4126\n",
      "epoch:  80 loss:0.289426 auc:0.5588\n",
      "epoch:  80 loss:0.285413 auc:0.7228\n",
      "epoch:  40 loss:0.331582 auc:0.5412\n",
      "epoch: 100 loss:0.260632 auc:0.3936\n",
      "epoch: 100 loss:0.262753 auc:0.6274\n",
      "epoch: 100 loss:0.266819 auc:0.5796\n",
      "epoch: 100 loss:0.266969 auc:0.7131\n",
      "epoch:  60 loss:0.307369 auc:0.5117\n",
      "epoch: 120 loss:0.248282 auc:0.3710\n",
      "epoch: 120 loss:0.253542 auc:0.5640\n",
      "epoch: 120 loss:0.250675 auc:0.6419\n",
      "epoch: 120 loss:0.252917 auc:0.7125\n",
      "epoch:  80 loss:0.283364 auc:0.5415\n",
      "epoch: 140 loss:0.241934 auc:0.6224\n",
      "epoch: 140 loss:0.247541 auc:0.3627\n",
      "epoch: 140 loss:0.243841 auc:0.5721\n",
      "epoch: 140 loss:0.243397 auc:0.7340\n",
      "epoch: 100 loss:0.265052 auc:0.5503\n",
      "epoch: 160 loss:0.236818 auc:0.6274\n",
      "epoch: 160 loss:0.236028 auc:0.3805\n",
      "epoch: 160 loss:0.243036 auc:0.5643\n",
      "epoch: 120 loss:0.250761 auc:0.5441\n",
      "epoch: 160 loss:0.238159 auc:0.7398\n",
      "epoch: 180 loss:0.231564 auc:0.3532\n",
      "epoch: 180 loss:0.232184 auc:0.6196\n",
      "epoch: 180 loss:0.234120 auc:0.5591\n",
      "epoch: 140 loss:0.246178 auc:0.5424\n",
      "epoch: 180 loss:0.233169 auc:0.7369\n",
      "epoch: 200 loss:0.230295 auc:0.6241\n",
      "epoch: 200 loss:0.233330 auc:0.3650\n",
      "epoch: 200 loss:0.230217 auc:0.5643\n",
      "epoch: 160 loss:0.236701 auc:0.5615\n",
      "epoch: 200 loss:0.231959 auc:0.7303\n",
      "epoch: 220 loss:0.227591 auc:0.6234\n",
      "epoch: 220 loss:0.227261 auc:0.3579\n",
      "epoch: 220 loss:0.228438 auc:0.5699\n",
      "epoch: 220 loss:0.228008 auc:0.7309\n",
      "epoch: 180 loss:0.233702 auc:0.5699\n",
      "epoch: 240 loss:0.224947 auc:0.6233\n",
      "epoch: 240 loss:0.225238 auc:0.3746\n",
      "epoch: 240 loss:0.226579 auc:0.5846\n",
      "epoch: 240 loss:0.227985 auc:0.7402\n",
      "epoch: 200 loss:0.229044 auc:0.5720\n",
      "epoch: 260 loss:0.224998 auc:0.6233\n",
      "epoch: 260 loss:0.224486 auc:0.3555\n",
      "epoch: 260 loss:0.225884 auc:0.5763\n",
      "epoch: 260 loss:0.224452 auc:0.7337\n",
      "epoch: 220 loss:0.227387 auc:0.5779\n",
      "epoch: 280 loss:0.224303 auc:0.6186\n",
      "epoch: 280 loss:0.222728 auc:0.3615\n",
      "epoch: 280 loss:0.223559 auc:0.5657\n",
      "epoch: 280 loss:0.228267 auc:0.7385\n",
      "epoch: 240 loss:0.225978 auc:0.5783\n",
      "epoch: 300 loss:0.221612 auc:0.6212\n",
      "epoch: 300 loss:0.222131 auc:0.3424\n",
      "epoch: 300 loss:0.227990 auc:0.5654\n",
      "epoch: 300 loss:0.222369 auc:0.7167\n",
      "epoch: 260 loss:0.223348 auc:0.5922\n",
      "epoch: 320 loss:0.220896 auc:0.6159\n",
      "epoch: 320 loss:0.221042 auc:0.3508\n",
      "epoch: 320 loss:0.221344 auc:0.5605\n",
      "epoch: 320 loss:0.222110 auc:0.7240\n",
      "epoch: 280 loss:0.223465 auc:0.5920\n",
      "epoch: 340 loss:0.220031 auc:0.6078\n",
      "epoch: 340 loss:0.221326 auc:0.3448\n",
      "epoch: 340 loss:0.220479 auc:0.5621\n",
      "epoch: 360 loss:0.220360 auc:0.6033\n",
      "epoch: 300 loss:0.221900 auc:0.5822\n",
      "epoch: 340 loss:0.220174 auc:0.7177\n",
      "epoch: 360 loss:0.219022 auc:0.3317\n",
      "epoch: 360 loss:0.224150 auc:0.5683\n",
      "epoch: 320 loss:0.221023 auc:0.5973\n",
      "epoch: 380 loss:0.219305 auc:0.6065\n",
      "epoch: 360 loss:0.220472 auc:0.6931\n",
      "epoch: 380 loss:0.224047 auc:0.3436\n",
      "epoch: 380 loss:0.219269 auc:0.5662\n",
      "epoch: 340 loss:0.221823 auc:0.6068\n",
      "epoch: 400 loss:0.217360 auc:0.6000\n",
      "epoch: 380 loss:0.218657 auc:0.7057\n",
      "epoch: 400 loss:0.218537 auc:0.3127\n",
      "epoch: 400 loss:0.217975 auc:0.5614\n",
      "epoch: 360 loss:0.218693 auc:0.5969\n",
      "epoch: 420 loss:0.221105 auc:0.5895\n",
      "epoch: 420 loss:0.217188 auc:0.3175\n",
      "epoch: 400 loss:0.219537 auc:0.6865\n",
      "epoch: 420 loss:0.222548 auc:0.5564\n",
      "epoch: 380 loss:0.220661 auc:0.6091\n",
      "epoch: 440 loss:0.217066 auc:0.5911\n",
      "epoch: 440 loss:0.222114 auc:0.3092\n",
      "epoch: 420 loss:0.217469 auc:0.6890\n",
      "epoch: 400 loss:0.218521 auc:0.6208\n",
      "epoch: 440 loss:0.217698 auc:0.5643\n",
      "epoch: 460 loss:0.215819 auc:0.5921\n",
      "epoch: 460 loss:0.216661 auc:0.3294\n",
      "epoch: 440 loss:0.220671 auc:0.6412\n",
      "epoch: 420 loss:0.217031 auc:0.6047\n",
      "epoch: 460 loss:0.216553 auc:0.5652\n",
      "epoch: 480 loss:0.219188 auc:0.3163\n",
      "epoch: 480 loss:0.222452 auc:0.5911\n",
      "epoch: 440 loss:0.219901 auc:0.6007\n",
      "epoch: 460 loss:0.216548 auc:0.6784\n",
      "epoch: 480 loss:0.218434 auc:0.5548\n",
      "epoch: 500 loss:0.215906 auc:0.3115\n",
      "epoch: 500 loss:0.215702 auc:0.5900\n",
      "epoch: 460 loss:0.216137 auc:0.6099\n",
      "epoch: 480 loss:0.221766 auc:0.6884\n",
      "epoch: 500 loss:0.216020 auc:0.5688\n",
      "epoch: 520 loss:0.220601 auc:0.2878\n",
      "epoch: 500 loss:0.216186 auc:0.6873\n",
      "epoch: 520 loss:0.214717 auc:0.5889\n",
      "epoch: 480 loss:0.362625 auc:0.5525\n",
      "epoch: 520 loss:0.218982 auc:0.5775\n",
      "epoch: 540 loss:0.215799 auc:0.3306\n",
      "epoch: 520 loss:0.218847 auc:0.6858\n",
      "epoch: 540 loss:0.217706 auc:0.6097\n",
      "epoch: 540 loss:0.215448 auc:0.5832\n",
      "epoch: 500 loss:0.326523 auc:0.5866\n",
      "epoch: 560 loss:0.215173 auc:0.3199\n",
      "epoch: 540 loss:0.216016 auc:0.6911\n",
      "epoch: 520 loss:0.300418 auc:0.5949\n",
      "epoch: 560 loss:0.214475 auc:0.5878\n",
      "epoch: 560 loss:0.215701 auc:0.5612\n",
      "epoch: 580 loss:0.217223 auc:0.3234\n",
      "epoch: 540 loss:0.276546 auc:0.5838\n",
      "epoch: 560 loss:0.214783 auc:0.6797\n",
      "epoch: 580 loss:0.215546 auc:0.5943\n",
      "epoch: 580 loss:0.213891 auc:0.5872\n",
      "epoch: 600 loss:0.214645 auc:0.3056\n",
      "epoch: 600 loss:0.214434 auc:0.5898\n",
      "epoch: 560 loss:0.258591 auc:0.5822\n",
      "epoch: 580 loss:0.215546 auc:0.6900\n",
      "epoch: 600 loss:0.215194 auc:0.5832\n",
      "epoch: 620 loss:0.216072 auc:0.3234\n",
      "epoch: 620 loss:0.219611 auc:0.5844\n",
      "epoch: 580 loss:0.246745 auc:0.5830\n",
      "epoch: 620 loss:0.213656 auc:0.5882\n",
      "epoch: 600 loss:0.214310 auc:0.6761\n",
      "epoch: 640 loss:0.214328 auc:0.3306\n",
      "epoch: 640 loss:0.214860 auc:0.5968\n",
      "epoch: 600 loss:0.240087 auc:0.5932\n",
      "epoch: 620 loss:0.215062 auc:0.6424\n",
      "epoch: 640 loss:0.214742 auc:0.5841\n",
      "epoch: 620 loss:0.234299 auc:0.5796\n",
      "epoch: 660 loss:0.213433 auc:0.5899\n",
      "epoch: 660 loss:0.215467 auc:0.3317\n",
      "epoch: 640 loss:0.214510 auc:0.6681\n",
      "epoch: 660 loss:0.213957 auc:0.5875\n",
      "epoch: 680 loss:0.214005 auc:0.5749\n",
      "epoch: 680 loss:0.216936 auc:0.3139\n",
      "epoch: 660 loss:0.214361 auc:0.6636\n",
      "epoch: 640 loss:0.232042 auc:0.5644\n",
      "epoch: 680 loss:0.215684 auc:0.5905\n",
      "epoch: 700 loss:0.214204 auc:0.5842\n",
      "epoch: 680 loss:0.215228 auc:0.6543\n",
      "epoch: 700 loss:0.214067 auc:0.3222\n",
      "epoch: 660 loss:0.227600 auc:0.5747\n",
      "epoch: 700 loss:0.213844 auc:0.5754\n",
      "epoch: 720 loss:0.212947 auc:0.5856\n",
      "epoch: 700 loss:0.213806 auc:0.6678\n",
      "epoch: 720 loss:0.213837 auc:0.3389\n",
      "epoch: 680 loss:0.227815 auc:0.6084\n",
      "epoch: 720 loss:0.215395 auc:0.5785\n",
      "epoch: 740 loss:0.216666 auc:0.6010\n",
      "epoch: 720 loss:0.216626 auc:0.6393\n",
      "epoch: 740 loss:0.213509 auc:0.5740\n",
      "epoch: 740 loss:0.386503 auc:0.5803\n",
      "epoch: 700 loss:0.223856 auc:0.5877\n",
      "epoch: 760 loss:0.213335 auc:0.5920\n",
      "epoch: 740 loss:0.213620 auc:0.6720\n",
      "epoch: 760 loss:0.214683 auc:0.5688\n",
      "epoch: 760 loss:0.345974 auc:0.5065\n",
      "epoch: 720 loss:0.228445 auc:0.5803\n",
      "epoch: 780 loss:0.212707 auc:0.5822\n",
      "epoch: 760 loss:0.213293 auc:0.6514\n",
      "epoch: 780 loss:0.329554 auc:0.4828\n",
      "epoch: 740 loss:0.221448 auc:0.6023\n",
      "epoch: 780 loss:0.213275 auc:0.5886\n",
      "epoch: 800 loss:0.214335 auc:0.5946\n",
      "epoch: 780 loss:0.215371 auc:0.6192\n",
      "epoch: 760 loss:0.222152 auc:0.6124\n",
      "epoch: 800 loss:0.315365 auc:0.4637\n",
      "epoch: 800 loss:0.214814 auc:0.5683\n",
      "epoch: 800 loss:0.213199 auc:0.6465\n",
      "epoch: 820 loss:0.213101 auc:0.5848\n",
      "epoch: 780 loss:0.219426 auc:0.6015\n",
      "epoch: 820 loss:0.213142 auc:0.5792\n",
      "epoch: 820 loss:0.300877 auc:0.4554\n",
      "epoch: 840 loss:0.212545 auc:0.5775\n",
      "epoch: 820 loss:0.218387 auc:0.6497\n",
      "epoch: 800 loss:0.219742 auc:0.5970\n",
      "epoch: 840 loss:0.215497 auc:0.5889\n",
      "epoch: 840 loss:0.286850 auc:0.4209\n",
      "epoch: 860 loss:0.220820 auc:0.5963\n",
      "epoch: 840 loss:0.213375 auc:0.6400\n",
      "epoch: 820 loss:0.219677 auc:0.6107\n",
      "epoch: 860 loss:0.274614 auc:0.3888\n",
      "epoch: 860 loss:0.213742 auc:0.5714\n",
      "epoch: 880 loss:0.213045 auc:0.5813\n",
      "epoch: 860 loss:0.212733 auc:0.6392\n",
      "epoch: 880 loss:0.264467 auc:0.4138\n",
      "epoch: 840 loss:0.219381 auc:0.6219\n",
      "epoch: 880 loss:0.212896 auc:0.5782\n",
      "epoch: 900 loss:0.212178 auc:0.5854\n",
      "epoch: 880 loss:0.213997 auc:0.6486\n",
      "epoch: 900 loss:0.256189 auc:0.4423\n",
      "epoch: 900 loss:0.214822 auc:0.5730\n",
      "epoch: 860 loss:0.217359 auc:0.6151\n",
      "epoch: 920 loss:0.212086 auc:0.5798\n",
      "epoch: 900 loss:0.212841 auc:0.6549\n",
      "epoch: 920 loss:0.212876 auc:0.5702\n",
      "epoch: 920 loss:0.256755 auc:0.4721\n",
      "epoch: 880 loss:0.217558 auc:0.6067\n",
      "epoch: 940 loss:0.214466 auc:0.5906\n",
      "epoch: 920 loss:0.213405 auc:0.6344\n",
      "epoch: 940 loss:0.215530 auc:0.5676\n",
      "epoch: 940 loss:0.244663 auc:0.4649\n",
      "epoch: 900 loss:0.218270 auc:0.6128\n",
      "epoch: 960 loss:0.212218 auc:0.5852\n",
      "epoch: 940 loss:0.213049 auc:0.6597\n",
      "epoch: 960 loss:0.242374 auc:0.3912\n",
      "epoch: 960 loss:0.212904 auc:0.5690\n",
      "epoch: 920 loss:0.216884 auc:0.6191\n",
      "epoch: 980 loss:0.211852 auc:0.5888\n",
      "epoch: 960 loss:0.213614 auc:0.6349\n",
      "epoch: 980 loss:0.213986 auc:0.5662\n",
      "epoch: 940 loss:0.216565 auc:0.6261\n",
      "epoch: 980 loss:0.236329 auc:0.4233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dim 1:   3%|█▍                                          | 15/460 [57:53<30:28:03, 246.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit finished.\n",
      "epoch:   0 loss:0.701839 auc:0.5317\n",
      "epoch: 980 loss:0.212978 auc:0.6428\n",
      "epoch: 960 loss:0.216967 auc:0.6126\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.700716 auc:0.4205\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.698572 auc:0.5032\n",
      "epoch:  20 loss:0.352854 auc:0.6151\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.705282 auc:0.5144\n",
      "epoch: 980 loss:0.215792 auc:0.6138\n",
      "epoch:  20 loss:0.351720 auc:0.4863\n",
      "epoch:  20 loss:0.349718 auc:0.5793\n",
      "epoch:  40 loss:0.327901 auc:0.6156\n",
      "Fit finished.\n",
      "epoch:  20 loss:0.353210 auc:0.6417\n",
      "epoch:   0 loss:0.702539 auc:0.4390\n",
      "epoch:  40 loss:0.327999 auc:0.5841\n",
      "epoch:  40 loss:0.324548 auc:0.6338\n",
      "epoch:  60 loss:0.304902 auc:0.6407\n",
      "epoch:  60 loss:0.302851 auc:0.5607\n",
      "epoch:  20 loss:0.352641 auc:0.4498\n",
      "epoch:  40 loss:0.328681 auc:0.6446\n",
      "epoch:  60 loss:0.300610 auc:0.6768\n",
      "epoch:  80 loss:0.280829 auc:0.6157\n",
      "epoch:  40 loss:0.328887 auc:0.5545\n",
      "epoch:  60 loss:0.306758 auc:0.6493\n",
      "epoch:  80 loss:0.276883 auc:0.6705\n",
      "epoch:  80 loss:0.280914 auc:0.5101\n",
      "epoch: 100 loss:0.263732 auc:0.6188\n",
      "epoch:  60 loss:0.305475 auc:0.6101\n",
      "epoch: 100 loss:0.260012 auc:0.5269\n",
      "epoch:  80 loss:0.283252 auc:0.6739\n",
      "epoch: 100 loss:0.258199 auc:0.6757\n",
      "epoch: 120 loss:0.249586 auc:0.6418\n",
      "epoch:  80 loss:0.282187 auc:0.6371\n",
      "epoch: 120 loss:0.249007 auc:0.5481\n",
      "epoch: 100 loss:0.264381 auc:0.6826\n",
      "epoch: 140 loss:0.243482 auc:0.6526\n",
      "epoch: 120 loss:0.247165 auc:0.6769\n",
      "epoch: 120 loss:0.251549 auc:0.6774\n",
      "epoch: 140 loss:0.243097 auc:0.6582\n",
      "epoch: 140 loss:0.241046 auc:0.5653\n",
      "epoch: 160 loss:0.235958 auc:0.6668\n",
      "epoch: 100 loss:0.262516 auc:0.6195\n",
      "epoch: 140 loss:0.241805 auc:0.6706\n",
      "epoch: 160 loss:0.235847 auc:0.6760\n",
      "epoch: 180 loss:0.232532 auc:0.6705\n",
      "epoch: 160 loss:0.235810 auc:0.5663\n",
      "epoch: 120 loss:0.250151 auc:0.6050\n",
      "epoch: 180 loss:0.231643 auc:0.6566\n",
      "epoch: 160 loss:0.238088 auc:0.6711\n",
      "epoch: 200 loss:0.231665 auc:0.6782\n",
      "epoch: 180 loss:0.232028 auc:0.5696\n",
      "epoch: 140 loss:0.241667 auc:0.6168\n",
      "epoch: 200 loss:0.229315 auc:0.6556\n",
      "epoch: 180 loss:0.232287 auc:0.6744\n",
      "epoch: 200 loss:0.228567 auc:0.5597\n",
      "epoch: 220 loss:0.226635 auc:0.6461\n",
      "epoch: 160 loss:0.238266 auc:0.6089\n",
      "epoch: 220 loss:0.227524 auc:0.6989\n",
      "epoch: 200 loss:0.229295 auc:0.6735\n",
      "epoch: 240 loss:0.227396 auc:0.6183\n",
      "epoch: 180 loss:0.233079 auc:0.6022\n",
      "epoch: 220 loss:0.227695 auc:0.5408\n",
      "epoch: 240 loss:0.227117 auc:0.7064\n",
      "epoch: 220 loss:0.228936 auc:0.6668\n",
      "epoch: 200 loss:0.229267 auc:0.6014\n",
      "epoch: 260 loss:0.223238 auc:0.6305\n",
      "epoch: 240 loss:0.224591 auc:0.5349\n",
      "epoch: 260 loss:0.223935 auc:0.7086\n",
      "epoch: 240 loss:0.225411 auc:0.6648\n",
      "epoch: 220 loss:0.227544 auc:0.5986\n",
      "epoch: 280 loss:0.223111 auc:0.6412\n",
      "epoch: 260 loss:0.227207 auc:0.5276\n",
      "epoch: 280 loss:0.225452 auc:0.7053\n",
      "epoch: 260 loss:0.225176 auc:0.6719\n",
      "epoch: 240 loss:0.226276 auc:0.5865\n",
      "epoch: 300 loss:0.220855 auc:0.6314\n",
      "epoch: 280 loss:0.222426 auc:0.5273\n",
      "epoch: 280 loss:0.222464 auc:0.6681\n",
      "epoch: 260 loss:0.223680 auc:0.5823\n",
      "epoch: 300 loss:0.221434 auc:0.7103\n",
      "epoch: 320 loss:0.221677 auc:0.6244\n",
      "epoch: 300 loss:0.222580 auc:0.5183\n",
      "epoch: 300 loss:0.221880 auc:0.6798\n",
      "epoch: 280 loss:0.223445 auc:0.5849\n",
      "epoch: 320 loss:0.220039 auc:0.7096\n",
      "epoch: 320 loss:0.220787 auc:0.5319\n",
      "epoch: 340 loss:0.219250 auc:0.6303\n",
      "epoch: 320 loss:0.222981 auc:0.6591\n",
      "epoch: 300 loss:0.221474 auc:0.5773\n",
      "epoch: 340 loss:0.219112 auc:0.5332\n",
      "epoch: 360 loss:0.220328 auc:0.6297\n",
      "epoch: 340 loss:0.224891 auc:0.6855\n",
      "epoch: 340 loss:0.219854 auc:0.6682\n",
      "epoch: 320 loss:0.221371 auc:0.5725\n",
      "epoch: 360 loss:0.220048 auc:0.5197\n",
      "epoch: 360 loss:0.219027 auc:0.7142\n",
      "epoch: 380 loss:0.217847 auc:0.6280\n",
      "epoch: 380 loss:0.217938 auc:0.5306\n",
      "epoch: 340 loss:0.219564 auc:0.5858\n",
      "epoch: 360 loss:0.220743 auc:0.6547\n",
      "epoch: 400 loss:0.219808 auc:0.6378\n",
      "epoch: 400 loss:0.221570 auc:0.5263\n",
      "epoch: 380 loss:0.219631 auc:0.7108\n",
      "epoch: 360 loss:0.221401 auc:0.5741\n",
      "epoch: 380 loss:0.218337 auc:0.6748\n",
      "epoch: 420 loss:0.217782 auc:0.5461\n",
      "epoch: 400 loss:0.217965 auc:0.7053\n",
      "epoch: 380 loss:0.218341 auc:0.5782\n",
      "epoch: 420 loss:0.217098 auc:0.6270\n",
      "epoch: 440 loss:0.216326 auc:0.5260\n",
      "epoch: 400 loss:0.219454 auc:0.5927\n",
      "epoch: 400 loss:0.220455 auc:0.6698\n",
      "epoch: 420 loss:0.219261 auc:0.6946\n",
      "epoch: 440 loss:0.216988 auc:0.6241\n",
      "epoch: 460 loss:0.218129 auc:0.5170\n",
      "epoch: 420 loss:0.217599 auc:0.6713\n",
      "epoch: 420 loss:0.217057 auc:0.5774\n",
      "epoch: 460 loss:0.216591 auc:0.6320\n",
      "epoch: 440 loss:0.216959 auc:0.6948\n",
      "epoch: 480 loss:0.215718 auc:0.5157\n",
      "epoch: 440 loss:0.222155 auc:0.6603\n",
      "epoch: 440 loss:0.217472 auc:0.5757\n",
      "epoch: 480 loss:0.217372 auc:0.6333\n",
      "epoch: 460 loss:0.216884 auc:0.6740\n",
      "epoch: 460 loss:0.217380 auc:0.6889\n",
      "epoch: 500 loss:0.216674 auc:0.5064\n",
      "epoch: 500 loss:0.215577 auc:0.6253\n",
      "epoch: 460 loss:0.216100 auc:0.5807\n",
      "epoch: 480 loss:0.215525 auc:0.6858\n",
      "epoch: 480 loss:0.227346 auc:0.6764\n",
      "epoch: 520 loss:0.215016 auc:0.5104\n",
      "epoch: 500 loss:0.219276 auc:0.6658\n",
      "epoch: 520 loss:0.216239 auc:0.6275\n",
      "epoch: 480 loss:0.216953 auc:0.5887\n",
      "epoch: 500 loss:0.216167 auc:0.6619\n",
      "epoch: 540 loss:0.217849 auc:0.5200\n",
      "epoch: 540 loss:0.214512 auc:0.6304\n",
      "epoch: 520 loss:0.215293 auc:0.6768\n",
      "epoch: 500 loss:0.215444 auc:0.5967\n",
      "epoch: 520 loss:0.214937 auc:0.6737\n",
      "epoch: 560 loss:0.215233 auc:0.5256\n",
      "epoch: 560 loss:0.214966 auc:0.6305\n",
      "epoch: 540 loss:0.214649 auc:0.6755\n",
      "epoch: 520 loss:0.215643 auc:0.5951\n",
      "epoch: 540 loss:0.217247 auc:0.6865\n",
      "epoch: 580 loss:0.214199 auc:0.5098\n",
      "epoch: 580 loss:0.216060 auc:0.6386\n",
      "epoch: 560 loss:0.217664 auc:0.6521\n",
      "epoch: 540 loss:0.214789 auc:0.5994\n",
      "epoch: 560 loss:0.214596 auc:0.6773\n",
      "epoch: 600 loss:0.214011 auc:0.6211\n",
      "epoch: 600 loss:0.219606 auc:0.5127\n",
      "epoch: 580 loss:0.214453 auc:0.6622\n",
      "epoch: 560 loss:0.215850 auc:0.5975\n",
      "epoch: 580 loss:0.214456 auc:0.6727\n",
      "epoch: 620 loss:0.214610 auc:0.5236\n",
      "epoch: 620 loss:0.216305 auc:0.6469\n",
      "epoch: 600 loss:0.213849 auc:0.6584\n",
      "epoch: 580 loss:0.214349 auc:0.5993\n",
      "epoch: 600 loss:0.214666 auc:0.6801\n",
      "epoch: 640 loss:0.213737 auc:0.5157\n",
      "epoch: 640 loss:0.213705 auc:0.6227\n",
      "epoch: 620 loss:0.220075 auc:0.6474\n",
      "epoch: 600 loss:0.220399 auc:0.5946\n",
      "epoch: 620 loss:0.213972 auc:0.6799\n",
      "epoch: 660 loss:0.213907 auc:0.5174\n",
      "epoch: 640 loss:0.214048 auc:0.6578\n",
      "epoch: 660 loss:0.213304 auc:0.6253\n",
      "epoch: 620 loss:0.214758 auc:0.6086\n",
      "epoch: 640 loss:0.214335 auc:0.6846\n",
      "epoch: 680 loss:0.213566 auc:0.5157\n",
      "epoch: 680 loss:0.215341 auc:0.6234\n",
      "epoch: 660 loss:0.213378 auc:0.6530\n",
      "epoch: 640 loss:0.213729 auc:0.6092\n",
      "epoch: 660 loss:0.213389 auc:0.6762\n",
      "epoch: 700 loss:0.214357 auc:0.5028\n",
      "epoch: 700 loss:0.213148 auc:0.6331\n",
      "epoch: 680 loss:0.215361 auc:0.6521\n",
      "epoch: 660 loss:0.216226 auc:0.6064\n",
      "epoch: 680 loss:0.218008 auc:0.6691\n",
      "epoch: 720 loss:0.213362 auc:0.5134\n",
      "epoch: 720 loss:0.212782 auc:0.6257\n",
      "epoch: 700 loss:0.213369 auc:0.6551\n",
      "epoch: 680 loss:0.213754 auc:0.6087\n",
      "epoch: 740 loss:0.217352 auc:0.5058\n",
      "epoch: 700 loss:0.213603 auc:0.6757\n",
      "epoch: 740 loss:0.223085 auc:0.6471\n",
      "epoch: 720 loss:0.213460 auc:0.6487\n",
      "epoch: 760 loss:0.213548 auc:0.5144\n",
      "epoch: 700 loss:0.213949 auc:0.6096\n",
      "epoch: 720 loss:0.212916 auc:0.6786\n",
      "epoch: 760 loss:0.214492 auc:0.6327\n",
      "epoch: 740 loss:0.214695 auc:0.6269\n",
      "epoch: 780 loss:0.213960 auc:0.5164\n",
      "epoch: 720 loss:0.213318 auc:0.6068\n",
      "epoch: 740 loss:0.434089 auc:0.5438\n",
      "epoch: 780 loss:0.212934 auc:0.6368\n",
      "epoch: 760 loss:0.212968 auc:0.6392\n",
      "epoch: 800 loss:0.213221 auc:0.5144\n",
      "epoch: 740 loss:0.213717 auc:0.6093\n",
      "epoch: 760 loss:0.361452 auc:0.6375\n",
      "epoch: 800 loss:0.212526 auc:0.6395\n",
      "epoch: 780 loss:0.214829 auc:0.6476\n",
      "epoch: 760 loss:0.213436 auc:0.6235\n",
      "epoch: 820 loss:0.212341 auc:0.6381\n",
      "epoch: 780 loss:0.349065 auc:0.6461\n",
      "epoch: 820 loss:0.216754 auc:0.5236\n",
      "epoch: 800 loss:0.214547 auc:0.6377\n",
      "epoch: 780 loss:0.214377 auc:0.6264\n",
      "epoch: 800 loss:0.341903 auc:0.6582\n",
      "epoch: 840 loss:0.213156 auc:0.5260\n",
      "epoch: 840 loss:0.218286 auc:0.6050\n",
      "epoch: 800 loss:0.212983 auc:0.6201\n",
      "epoch: 820 loss:0.212798 auc:0.6442\n",
      "epoch: 820 loss:0.334397 auc:0.6661\n",
      "epoch: 860 loss:0.213156 auc:0.6348\n",
      "epoch: 860 loss:0.213222 auc:0.5217\n",
      "epoch: 820 loss:0.533326 auc:0.4370\n",
      "epoch: 840 loss:0.212492 auc:0.6399\n",
      "epoch: 880 loss:0.214732 auc:0.5164\n",
      "epoch: 880 loss:0.212241 auc:0.6352\n",
      "epoch: 840 loss:0.325019 auc:0.6673\n",
      "epoch: 860 loss:0.216616 auc:0.6269\n",
      "epoch: 840 loss:0.373668 auc:0.4419\n",
      "epoch: 900 loss:0.212733 auc:0.5379\n",
      "epoch: 860 loss:0.313966 auc:0.6632\n",
      "epoch: 900 loss:0.212653 auc:0.6435\n",
      "epoch: 880 loss:0.212739 auc:0.6353\n",
      "epoch: 880 loss:0.302045 auc:0.6562\n",
      "epoch: 860 loss:0.360078 auc:0.4517\n",
      "epoch: 920 loss:0.212685 auc:0.6248\n",
      "epoch: 920 loss:0.212416 auc:0.5322\n",
      "epoch: 900 loss:0.212322 auc:0.6377\n",
      "epoch: 900 loss:0.293040 auc:0.6571\n",
      "epoch: 880 loss:0.354113 auc:0.4617\n",
      "epoch: 940 loss:0.211982 auc:0.6306\n",
      "epoch: 940 loss:0.216814 auc:0.5319\n",
      "epoch: 920 loss:0.219391 auc:0.6384\n",
      "epoch: 920 loss:0.280441 auc:0.6612\n",
      "epoch: 960 loss:0.216594 auc:0.6142\n",
      "epoch: 900 loss:0.349728 auc:0.4712\n",
      "epoch: 960 loss:0.212818 auc:0.5425\n",
      "epoch: 940 loss:0.213326 auc:0.6237\n",
      "epoch: 940 loss:0.270049 auc:0.6628\n",
      "epoch: 980 loss:0.212259 auc:0.6240\n",
      "epoch: 920 loss:0.345575 auc:0.4798\n",
      "epoch: 980 loss:0.219242 auc:0.5448\n",
      "epoch: 960 loss:0.212362 auc:0.6231\n",
      "epoch: 940 loss:0.341067 auc:0.4899\n",
      "epoch: 960 loss:0.261772 auc:0.6672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dim 1:   4%|█▋                                      | 20/460 [5:49:24<178:25:04, 1459.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit finished.\n",
      "epoch:   0 loss:0.702162 auc:0.6678\n",
      "Fit finished.\n",
      "epoch: 980 loss:0.215886 auc:0.6056\n",
      "epoch:   0 loss:0.699643 auc:0.5261\n",
      "epoch: 980 loss:0.254496 auc:0.6583\n",
      "epoch: 960 loss:0.335440 auc:0.5085\n",
      "epoch:  20 loss:0.350058 auc:0.3499\n",
      "epoch:  20 loss:0.351832 auc:0.4400\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.700535 auc:0.4838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dim 1:   5%|██▏                                      | 25/460 [5:50:20<115:31:32, 956.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit finished.\n",
      "epoch:   0 loss:0.703238 auc:0.6118\n",
      "epoch: 980 loss:0.329262 auc:0.5508\n",
      "epoch:  40 loss:0.324255 auc:0.4537\n",
      "epoch:  40 loss:0.327756 auc:0.5599\n",
      "epoch:  20 loss:0.351004 auc:0.4766\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.698233 auc:0.4682\n",
      "epoch:  20 loss:0.354858 auc:0.5110\n",
      "epoch:  60 loss:0.299142 auc:0.4856\n",
      "epoch:  60 loss:0.305137 auc:0.6670\n",
      "epoch:  40 loss:0.325496 auc:0.4974\n",
      "epoch:  20 loss:0.353770 auc:0.5990\n",
      "epoch:  80 loss:0.274814 auc:0.4371\n",
      "epoch:  40 loss:0.328880 auc:0.5281\n",
      "epoch:  80 loss:0.280385 auc:0.7678\n",
      "epoch:  40 loss:0.329153 auc:0.6493\n",
      "epoch:  60 loss:0.302042 auc:0.5266\n",
      "epoch:  60 loss:0.305867 auc:0.5495\n",
      "epoch: 100 loss:0.258006 auc:0.4712\n",
      "epoch: 100 loss:0.262496 auc:0.7950\n",
      "epoch:  60 loss:0.306526 auc:0.6610\n",
      "epoch:  80 loss:0.277599 auc:0.5328\n",
      "epoch: 120 loss:0.246315 auc:0.4687\n",
      "epoch:  80 loss:0.282268 auc:0.6613\n",
      "epoch:  80 loss:0.281955 auc:0.5379\n",
      "epoch: 120 loss:0.249647 auc:0.8307\n",
      "epoch: 100 loss:0.260391 auc:0.5359\n",
      "epoch: 100 loss:0.263630 auc:0.6635\n",
      "epoch: 140 loss:0.242074 auc:0.4940\n",
      "epoch: 140 loss:0.241217 auc:0.8510\n",
      "epoch: 120 loss:0.247171 auc:0.5393\n",
      "epoch: 100 loss:0.267218 auc:0.6011\n",
      "epoch: 120 loss:0.250333 auc:0.6892\n",
      "epoch: 160 loss:0.237118 auc:0.8562\n",
      "epoch: 140 loss:0.240279 auc:0.5472\n",
      "epoch: 160 loss:0.234879 auc:0.4669\n",
      "epoch: 120 loss:0.250294 auc:0.6279\n",
      "epoch: 140 loss:0.241666 auc:0.7011\n",
      "epoch: 180 loss:0.233330 auc:0.8496\n",
      "epoch: 180 loss:0.231013 auc:0.4613\n",
      "epoch: 160 loss:0.236118 auc:0.5562\n",
      "epoch: 160 loss:0.236746 auc:0.6999\n",
      "epoch: 140 loss:0.245746 auc:0.6763\n",
      "epoch: 200 loss:0.233263 auc:0.8483\n",
      "epoch: 180 loss:0.232185 auc:0.5511\n",
      "epoch: 180 loss:0.232167 auc:0.7106\n",
      "epoch: 160 loss:0.236869 auc:0.6591\n",
      "epoch: 200 loss:0.228354 auc:0.4439\n",
      "epoch: 220 loss:0.227277 auc:0.8512\n",
      "epoch: 200 loss:0.230786 auc:0.7048\n",
      "epoch: 220 loss:0.228960 auc:0.4402\n",
      "epoch: 200 loss:0.228094 auc:0.5501\n",
      "epoch: 240 loss:0.225932 auc:0.8551\n",
      "epoch: 180 loss:0.232736 auc:0.6490\n",
      "epoch: 220 loss:0.227137 auc:0.7127\n",
      "epoch: 240 loss:0.224720 auc:0.4252\n",
      "epoch: 220 loss:0.229059 auc:0.5427\n",
      "epoch: 260 loss:0.226070 auc:0.8359\n",
      "epoch: 200 loss:0.232892 auc:0.6609\n",
      "epoch: 240 loss:0.227633 auc:0.7042\n",
      "epoch: 240 loss:0.224727 auc:0.5473\n",
      "epoch: 280 loss:0.223756 auc:0.8307\n",
      "epoch: 260 loss:0.225898 auc:0.4377\n",
      "epoch: 220 loss:0.227401 auc:0.6253\n",
      "epoch: 260 loss:0.223781 auc:0.5486\n",
      "epoch: 260 loss:0.224055 auc:0.7060\n",
      "epoch: 300 loss:0.221591 auc:0.8390\n",
      "epoch: 280 loss:0.222253 auc:0.4066\n",
      "epoch: 240 loss:0.227171 auc:0.6082\n",
      "epoch: 280 loss:0.223580 auc:0.5553\n",
      "epoch: 280 loss:0.223755 auc:0.7032\n",
      "epoch: 300 loss:0.223765 auc:0.3890\n",
      "epoch: 320 loss:0.222551 auc:0.8351\n",
      "epoch: 260 loss:0.224140 auc:0.6049\n",
      "epoch: 300 loss:0.234179 auc:0.6927\n",
      "epoch: 300 loss:0.220972 auc:0.5488\n",
      "epoch: 320 loss:0.220943 auc:0.4050\n",
      "epoch: 340 loss:0.220096 auc:0.8337\n",
      "epoch: 320 loss:0.221783 auc:0.7023\n",
      "epoch: 280 loss:0.223666 auc:0.5918\n",
      "epoch: 340 loss:0.219358 auc:0.3986\n",
      "epoch: 320 loss:0.220439 auc:0.5428\n",
      "epoch: 340 loss:0.219793 auc:0.6999\n",
      "epoch: 360 loss:0.221522 auc:0.8335\n",
      "epoch: 300 loss:0.221932 auc:0.5766\n",
      "epoch: 340 loss:0.219523 auc:0.5450\n",
      "epoch: 360 loss:0.221389 auc:0.4144\n",
      "epoch: 360 loss:0.221380 auc:0.6955\n",
      "epoch: 380 loss:0.221745 auc:0.8199\n",
      "epoch: 320 loss:0.221838 auc:0.5743\n",
      "epoch: 360 loss:0.220963 auc:0.5479\n",
      "epoch: 380 loss:0.218650 auc:0.6959\n",
      "epoch: 380 loss:0.218324 auc:0.3991\n",
      "epoch: 400 loss:0.218165 auc:0.8208\n",
      "epoch: 340 loss:0.220060 auc:0.5791\n",
      "epoch: 380 loss:0.218023 auc:0.5457\n",
      "epoch: 400 loss:0.219683 auc:0.4090\n",
      "epoch: 420 loss:0.218501 auc:0.8187\n",
      "epoch: 400 loss:0.218034 auc:0.6915\n",
      "epoch: 400 loss:0.217500 auc:0.5401\n",
      "epoch: 360 loss:0.221229 auc:0.5468\n",
      "epoch: 420 loss:0.217202 auc:0.3991\n",
      "epoch: 440 loss:0.219115 auc:0.8111\n",
      "epoch: 380 loss:0.218821 auc:0.5658\n",
      "epoch: 420 loss:0.217403 auc:0.5441\n",
      "epoch: 420 loss:0.217112 auc:0.6898\n",
      "epoch: 440 loss:0.217314 auc:0.4020\n",
      "epoch: 460 loss:0.217255 auc:0.8164\n",
      "epoch: 440 loss:0.216124 auc:0.5402\n",
      "epoch: 400 loss:0.224361 auc:0.5414\n",
      "epoch: 460 loss:0.219240 auc:0.4441\n",
      "epoch: 440 loss:0.217712 auc:0.6975\n",
      "epoch: 460 loss:0.217171 auc:0.5391\n",
      "epoch: 420 loss:0.218080 auc:0.5749\n",
      "epoch: 480 loss:0.217041 auc:0.8171\n",
      "epoch: 480 loss:0.215927 auc:0.4032\n",
      "epoch: 460 loss:0.216261 auc:0.6897\n",
      "epoch: 480 loss:0.215415 auc:0.5407\n",
      "epoch: 440 loss:0.218233 auc:0.5672\n",
      "epoch: 500 loss:0.216923 auc:0.7995\n",
      "epoch: 480 loss:0.223516 auc:0.6594\n",
      "epoch: 500 loss:0.217968 auc:0.3647\n",
      "epoch: 500 loss:0.220013 auc:0.5359\n",
      "epoch: 460 loss:0.217478 auc:0.5721\n",
      "epoch: 520 loss:0.215464 auc:0.3859\n",
      "epoch: 500 loss:0.216171 auc:0.6971\n",
      "epoch: 520 loss:0.217008 auc:0.7920\n",
      "epoch: 520 loss:0.215127 auc:0.5335\n",
      "epoch: 480 loss:0.216524 auc:0.5718\n",
      "epoch: 540 loss:0.220015 auc:0.8049\n",
      "epoch: 520 loss:0.215170 auc:0.6926\n",
      "epoch: 540 loss:0.218243 auc:0.3977\n",
      "epoch: 540 loss:0.215324 auc:0.5291\n",
      "epoch: 500 loss:0.217913 auc:0.5866\n",
      "epoch: 560 loss:0.215820 auc:0.8196\n",
      "epoch: 540 loss:0.218007 auc:0.7016\n",
      "epoch: 560 loss:0.215186 auc:0.4007\n",
      "epoch: 560 loss:0.215027 auc:0.5394\n",
      "epoch: 520 loss:0.215815 auc:0.5708\n",
      "epoch: 580 loss:0.214995 auc:0.8075\n",
      "epoch: 560 loss:0.215012 auc:0.6970\n",
      "epoch: 580 loss:0.214950 auc:0.3990\n",
      "epoch: 580 loss:0.217985 auc:0.5162\n",
      "epoch: 540 loss:0.215224 auc:0.5789\n",
      "epoch: 580 loss:0.217464 auc:0.6920\n",
      "epoch: 600 loss:0.214729 auc:0.8051\n",
      "epoch: 600 loss:0.215911 auc:0.3909\n",
      "epoch: 600 loss:0.215539 auc:0.5295\n",
      "epoch: 560 loss:0.222838 auc:0.5977\n",
      "epoch: 600 loss:0.214838 auc:0.6914\n",
      "epoch: 620 loss:0.216168 auc:0.8203\n",
      "epoch: 620 loss:0.215397 auc:0.3867\n",
      "epoch: 580 loss:0.215902 auc:0.5840\n",
      "epoch: 620 loss:0.213646 auc:0.5314\n",
      "epoch: 620 loss:0.214009 auc:0.6961\n",
      "epoch: 640 loss:0.214072 auc:0.3971\n",
      "epoch: 640 loss:0.214275 auc:0.8113\n",
      "epoch: 600 loss:0.214787 auc:0.5738\n",
      "epoch: 640 loss:0.215241 auc:0.5290\n",
      "epoch: 660 loss:0.427321 auc:0.5125\n",
      "epoch: 640 loss:0.217808 auc:0.6947\n",
      "epoch: 660 loss:0.409667 auc:0.4371\n",
      "epoch: 620 loss:0.215637 auc:0.5599\n",
      "epoch: 660 loss:0.214125 auc:0.6941\n",
      "epoch: 660 loss:0.213583 auc:0.5307\n",
      "epoch: 680 loss:0.367227 auc:0.3380\n",
      "epoch: 680 loss:0.355581 auc:0.3681\n",
      "epoch: 640 loss:0.214521 auc:0.5776\n",
      "epoch: 680 loss:0.213532 auc:0.6941\n",
      "epoch: 680 loss:0.213339 auc:0.5278\n",
      "epoch: 700 loss:0.354970 auc:0.3175\n",
      "epoch: 700 loss:0.344651 auc:0.4178\n",
      "epoch: 660 loss:0.214820 auc:0.5740\n",
      "epoch: 700 loss:0.214321 auc:0.6991\n",
      "epoch: 700 loss:0.214803 auc:0.5377\n",
      "epoch: 720 loss:0.347997 auc:0.3021\n",
      "epoch: 680 loss:0.214367 auc:0.5753\n",
      "epoch: 720 loss:0.335976 auc:0.4436\n",
      "epoch: 720 loss:0.213699 auc:0.6926\n",
      "epoch: 740 loss:0.341149 auc:0.3208\n",
      "epoch: 720 loss:0.212931 auc:0.5286\n",
      "epoch: 740 loss:0.326113 auc:0.4606\n",
      "epoch: 700 loss:0.216675 auc:0.5679\n",
      "epoch: 740 loss:0.213649 auc:0.6962\n",
      "epoch: 760 loss:0.332784 auc:0.3427\n",
      "epoch: 740 loss:0.214470 auc:0.5318\n",
      "epoch: 780 loss:0.323721 auc:0.3472\n",
      "epoch: 760 loss:0.314343 auc:0.4760\n",
      "epoch: 720 loss:0.214376 auc:0.5847\n",
      "epoch: 760 loss:0.215661 auc:0.6930\n",
      "epoch: 800 loss:0.313953 auc:0.3378\n",
      "epoch: 760 loss:0.212740 auc:0.5314\n",
      "epoch: 780 loss:0.301279 auc:0.5385\n",
      "epoch: 740 loss:0.213710 auc:0.5692\n",
      "epoch: 780 loss:0.213326 auc:0.6921\n",
      "epoch: 780 loss:0.217340 auc:0.5483\n",
      "epoch: 820 loss:0.303390 auc:0.3058\n",
      "epoch: 800 loss:0.288647 auc:0.6149\n",
      "epoch: 800 loss:0.212942 auc:0.6939\n",
      "epoch: 760 loss:0.216364 auc:0.5689\n",
      "epoch: 840 loss:0.292936 auc:0.2990\n",
      "epoch: 800 loss:0.212985 auc:0.5278\n",
      "epoch: 820 loss:0.278383 auc:0.7010\n",
      "epoch: 820 loss:0.215298 auc:0.6865\n",
      "epoch: 780 loss:0.213762 auc:0.5724\n",
      "epoch: 860 loss:0.283837 auc:0.3240\n",
      "epoch: 820 loss:0.212305 auc:0.5308\n",
      "epoch: 840 loss:0.264881 auc:0.7457\n",
      "epoch: 840 loss:0.213022 auc:0.6938\n",
      "epoch: 880 loss:0.273667 auc:0.3107\n",
      "epoch: 800 loss:0.220651 auc:0.5777\n",
      "epoch: 840 loss:0.222734 auc:0.5302\n",
      "epoch: 860 loss:0.255425 auc:0.7577\n",
      "epoch: 860 loss:0.214133 auc:0.6956\n",
      "epoch: 900 loss:0.265436 auc:0.2985\n",
      "epoch: 820 loss:0.214024 auc:0.5665\n",
      "epoch: 860 loss:0.213935 auc:0.5334\n",
      "epoch: 880 loss:0.248180 auc:0.7566\n",
      "epoch: 880 loss:0.212721 auc:0.6865\n",
      "epoch: 920 loss:0.258764 auc:0.2925\n",
      "epoch: 840 loss:0.213239 auc:0.5732\n",
      "epoch: 880 loss:0.212325 auc:0.5277\n",
      "epoch: 900 loss:0.242882 auc:0.7570\n",
      "epoch: 900 loss:0.218879 auc:0.6875\n",
      "epoch: 940 loss:0.252714 auc:0.2648\n",
      "epoch: 900 loss:0.214028 auc:0.5272\n",
      "epoch: 920 loss:0.237771 auc:0.7694\n",
      "epoch: 860 loss:0.215590 auc:0.5744\n",
      "epoch: 960 loss:0.248343 auc:0.2542\n",
      "epoch: 920 loss:0.213246 auc:0.6981\n",
      "epoch: 920 loss:0.212165 auc:0.5270\n",
      "epoch: 940 loss:0.234566 auc:0.7733\n",
      "epoch: 880 loss:0.213241 auc:0.5694\n",
      "epoch: 980 loss:0.245472 auc:0.2603\n",
      "epoch: 940 loss:0.212520 auc:0.6885\n",
      "epoch: 940 loss:0.213115 auc:0.5255\n",
      "epoch: 960 loss:0.231569 auc:0.7688\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.698572 auc:0.4751\n",
      "epoch: 900 loss:0.223794 auc:0.6150\n",
      "epoch: 960 loss:0.213198 auc:0.6926\n",
      "epoch: 960 loss:0.212559 auc:0.5306\n",
      "epoch: 980 loss:0.229179 auc:0.7802\n",
      "epoch:  20 loss:0.352273 auc:0.7025\n",
      "epoch: 920 loss:0.216296 auc:0.5751\n",
      "epoch: 980 loss:0.212626 auc:0.6970\n",
      "epoch: 980 loss:0.211819 auc:0.5273\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.699437 auc:0.5106\n",
      "epoch: 940 loss:0.213401 auc:0.5670\n",
      "epoch:  40 loss:0.329082 auc:0.6798\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.698277 auc:0.4917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dim 1:   7%|██▌                                    | 30/460 [15:18:33<346:35:30, 2901.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit finished.\n",
      "epoch:   0 loss:0.699739 auc:0.3625\n",
      "epoch:  20 loss:0.352869 auc:0.6303\n",
      "epoch: 960 loss:0.212866 auc:0.5657\n",
      "epoch:  60 loss:0.306526 auc:0.6224\n",
      "epoch:  20 loss:0.354727 auc:0.5909\n",
      "epoch:  20 loss:0.354638 auc:0.7475\n",
      "epoch: 980 loss:0.216063 auc:0.5573\n",
      "epoch:  40 loss:0.328757 auc:0.6646\n",
      "epoch:  80 loss:0.282363 auc:0.6272\n",
      "epoch:  40 loss:0.330350 auc:0.6715\n",
      "epoch:  40 loss:0.329587 auc:0.7000\n",
      "Fit finished.\n",
      "epoch:   0 loss:0.700788 auc:0.5484\n",
      "epoch:  60 loss:0.306403 auc:0.6822\n",
      "epoch: 100 loss:0.262733 auc:0.6330\n",
      "epoch:  60 loss:0.307566 auc:0.7851\n",
      "epoch:  60 loss:0.308039 auc:0.7350\n",
      "epoch:  20 loss:0.353832 auc:0.4134\n",
      "epoch:  80 loss:0.283601 auc:0.7519\n",
      "epoch: 120 loss:0.250151 auc:0.6384\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 47\u001b[0m\n\u001b[1;32m     41\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     42\u001b[0m     (dim, target_index, seed, args)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m seed, target_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(np\u001b[38;5;241m.\u001b[39marange(res\u001b[38;5;241m.\u001b[39mshape[dim]))\n\u001b[1;32m     44\u001b[0m ]\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# 並列実行（プログレスバー付き）\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessing dim \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdim\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# 結果の結合\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold_results \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_kfold = 1\n",
    "n_jobs = 5  # 並列数\n",
    "\n",
    "\n",
    "def process_iteration(dim, target_index, seed, args):\n",
    "    \"\"\"各反復処理をカプセル化した関数\"\"\"\n",
    "    if dim:\n",
    "        if drug_sum[target_index] < 10:\n",
    "            return None, None\n",
    "    else:\n",
    "        if cell_sum[target_index] < 10:\n",
    "            return None, None\n",
    "\n",
    "    fold_results = []\n",
    "    for fold in range(n_kfold):\n",
    "        true_data, predict_data = nihgcn_new(\n",
    "            cell_exprs=exprs,\n",
    "            drug_finger=drug_finger,\n",
    "            res_mat=res,\n",
    "            null_mask=null_mask,\n",
    "            target_dim=dim,\n",
    "            target_index=target_index,\n",
    "            evaluate_fun=roc_auc,\n",
    "            args=args,\n",
    "            seed=seed,\n",
    "        )\n",
    "        fold_results.append((true_data, predict_data))\n",
    "\n",
    "    return fold_results\n",
    "\n",
    "\n",
    "# 並列処理の実行\n",
    "true_data_s = pd.DataFrame()\n",
    "predict_data_s = pd.DataFrame()\n",
    "\n",
    "for dim in target_dim:\n",
    "    # 全タスクを事前に生成\n",
    "    tasks = [\n",
    "        (dim, target_index, seed, args)\n",
    "        for seed, target_index in enumerate(np.arange(res.shape[dim]))\n",
    "    ]\n",
    "\n",
    "    # 並列実行（プログレスバー付き）\n",
    "    results = Parallel(n_jobs=n_jobs, verbose=0, prefer=\"threads\")(\n",
    "        delayed(process_iteration)(*task)\n",
    "        for task in tqdm(tasks, desc=f\"Processing dim {dim}\")\n",
    "    )\n",
    "\n",
    "    # 結果の結合\n",
    "    for fold_results in results:\n",
    "        if fold_results is None:\n",
    "            continue\n",
    "        for true_data, predict_data in fold_results:\n",
    "            true_data_s = pd.concat(\n",
    "                [true_data_s, translate_result(true_data)],\n",
    "                ignore_index=True,\n",
    "                copy=False,  # メモリ節約のため\n",
    "            )\n",
    "            predict_data_s = pd.concat(\n",
    "                [predict_data_s, translate_result(predict_data)],\n",
    "                ignore_index=True,\n",
    "                copy=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87fb88-253c-46b5-a367-df7ea05cbf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data_s.to_csv(f\"new_drug_true_{args.data}.csv\")\n",
    "predict_data_s.to_csv(f\"new_drug_pred_{args.data}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b507b-cec7-41ad-8b8e-b7fc574e3eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940db47e-7ca3-46e1-b156-7735a576081a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ec736-f5a9-4fa0-b134-103cd1f4aba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaa3395-dd1a-4c16-b171-182e45ce78ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec217d32-2481-4556-a7bb-74c347e5fffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf9fea-cfe6-48f9-bbeb-94502fd6bb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f62bcf-5963-4c3e-83a9-6fbf9868c315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b46af-bd2d-44fa-8752-b7a9d8f8d513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
