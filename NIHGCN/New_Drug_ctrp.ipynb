{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modified-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "numerical-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from load_data import load_data\n",
    "from model import Optimizer, nihgcn\n",
    "from myutils import *\n",
    "from sampler import NewSampler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "global-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )  # cuda:number or cpu\n",
    "        self.data = \"ctrp\"  # Dataset{gdsc or ccle}\n",
    "        self.lr = 0.001  # the learning rate\n",
    "        self.wd = 1e-5  # the weight decay for l2 normalizaton\n",
    "        self.layer_size = [1024, 1024]  # Output sizes of every layer\n",
    "        self.alpha = 0.25  # the scale for balance gcn and ni\n",
    "        self.gamma = 8  # the scale for sigmod\n",
    "        self.epochs = 1000  # the epochs for model\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "excessive-receiver",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res, drug_finger, exprs, null_mask, pos_num = load_data(args)\n",
    "cell_sum = np.sum(res, axis=1)\n",
    "drug_sum = np.sum(res, axis=0)\n",
    "\n",
    "target_dim = [\n",
    "    # 0,  # Cell\n",
    "    1  # Drug\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alpine-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nihgcn_new(\n",
    "    cell_exprs,\n",
    "    drug_finger,\n",
    "    res_mat,\n",
    "    null_mask,\n",
    "    target_dim,\n",
    "    target_index,\n",
    "    evaluate_fun,\n",
    "    args,\n",
    "    seed,\n",
    "):\n",
    "\n",
    "    sampler = NewSampler(res_mat, null_mask, target_dim, target_index, seed)\n",
    "\n",
    "    val_labels = sampler.test_data[sampler.test_mask]\n",
    "\n",
    "    if len(np.unique(val_labels)) < 2:\n",
    "        print(f\"Target {target_index} skipped: Validation set has only one class.\")\n",
    "        return None, None\n",
    "\n",
    "    model = nihgcn(\n",
    "        sampler.train_data,\n",
    "        cell_exprs=cell_exprs,\n",
    "        drug_finger=drug_finger,\n",
    "        layer_size=args.layer_size,\n",
    "        alpha=args.alpha,\n",
    "        gamma=args.gamma,\n",
    "        device=args.device,\n",
    "    )\n",
    "    opt = Optimizer(\n",
    "        model,\n",
    "        sampler.train_data,\n",
    "        sampler.test_data,\n",
    "        sampler.test_mask,\n",
    "        sampler.train_mask,\n",
    "        evaluate_fun,\n",
    "        lr=args.lr,\n",
    "        wd=args.wd,\n",
    "        epochs=args.epochs,\n",
    "        device=args.device,\n",
    "    )\n",
    "    true_data, predict_data = opt()\n",
    "    return true_data, predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "equal-telescope",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing dim 1:   0%|          | 0/460 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss:0.697310 auc:0.5137\n",
      "epoch:   0 loss:0.700717 auc:0.6475\n",
      "epoch:   0 loss:0.695436 auc:0.4598\n",
      "epoch:   0 loss:0.705157 auc:0.5000\n",
      "epoch:   0 loss:0.699093 auc:0.4590\n",
      "epoch:   0 loss:0.701050 auc:0.5790\n",
      "epoch:   0 loss:0.696832 auc:0.4725\n",
      "epoch:   0 loss:0.699978 auc:0.4839\n",
      "epoch:   0 loss:0.700585 auc:0.4544\n",
      "epoch:   0 loss:0.702219 auc:0.4307\n",
      "epoch:   0 loss:0.700091 auc:0.5405\n",
      "epoch:   0 loss:0.702225 auc:0.5345\n",
      "epoch:   0 loss:0.699388 auc:0.4475\n",
      "epoch:   0 loss:0.702984 auc:0.2778\n",
      "epoch:   0 loss:0.696174 auc:0.5763\n",
      "epoch:   0 loss:0.698586 auc:0.6300\n",
      "epoch:   0 loss:0.701285 auc:0.4486\n",
      "epoch:   0 loss:0.704084 auc:0.5500\n",
      "epoch:   0 loss:0.702291 auc:0.5686\n",
      "epoch:   0 loss:0.698783 auc:0.6019\n",
      "epoch:   0 loss:0.700363 auc:0.4234\n",
      "epoch:   0 loss:0.703336 auc:0.4421\n",
      "epoch:   0 loss:0.703573 auc:0.4583\n",
      "epoch:   0 loss:0.700141 auc:0.4880\n",
      "epoch:   0 loss:0.698600 auc:0.4150\n",
      "epoch:   0 loss:0.699424 auc:0.5979\n",
      "epoch:   0 loss:0.702226 auc:0.6094\n",
      "epoch:   0 loss:0.700616 auc:0.3678\n",
      "epoch:   0 loss:0.704218 auc:0.3946\n",
      "epoch:   0 loss:0.698920 auc:0.4728\n",
      "epoch:   0 loss:0.696751 auc:0.3956\n",
      "epoch:   0 loss:0.698453 auc:0.5218\n",
      "epoch:   0 loss:0.699720 auc:0.5301\n",
      "epoch:   0 loss:0.701061 auc:0.5183\n",
      "epoch:   0 loss:0.696606 auc:0.6562\n",
      "epoch:   0 loss:0.703483 auc:0.5262\n",
      "epoch:   0 loss:0.705253 auc:0.5571\n",
      "epoch:   0 loss:0.699905 auc:0.5389\n",
      "epoch:   0 loss:0.699538 auc:0.3784\n",
      "epoch:   0 loss:0.705241 auc:0.4953\n",
      "epoch:   0 loss:0.701459 auc:0.4853\n",
      "epoch:   0 loss:0.703946 auc:0.4700\n",
      "epoch:   0 loss:0.703064 auc:0.4913\n",
      "epoch:   0 loss:0.703205 auc:0.4421\n",
      "epoch:   0 loss:0.702851 auc:0.4913\n",
      "epoch:   0 loss:0.699352 auc:0.5217\n",
      "epoch:   0 loss:0.700928 auc:0.5393\n",
      "epoch:   0 loss:0.699357 auc:0.5012\n",
      "epoch:   0 loss:0.698940 auc:0.5693\n",
      "epoch:   0 loss:0.702737 auc:0.4699\n",
      "epoch:  20 loss:0.351944 auc:0.7551\n",
      "epoch:  20 loss:0.354189 auc:0.6855\n",
      "epoch:  20 loss:0.353827 auc:0.7172\n",
      "epoch:  20 loss:0.353346 auc:0.7206\n",
      "epoch:  20 loss:0.352143 auc:0.6799\n",
      "epoch:  20 loss:0.351474 auc:0.6320\n",
      "epoch:  20 loss:0.353202 auc:0.7094\n",
      "epoch:  20 loss:0.350960 auc:0.8013\n",
      "epoch:  20 loss:0.353650 auc:0.6859\n",
      "epoch:  20 loss:0.352155 auc:0.7186\n",
      "epoch:  20 loss:0.350669 auc:0.9100\n",
      "epoch:  20 loss:0.355877 auc:0.6451\n",
      "epoch:  20 loss:0.350804 auc:0.7689\n",
      "epoch:  20 loss:0.352636 auc:0.6786\n",
      "epoch:  20 loss:0.355098 auc:0.8075\n",
      "epoch:  20 loss:0.354422 auc:0.6000\n",
      "epoch:  20 loss:0.354059 auc:0.8125\n",
      "epoch:  20 loss:0.355989 auc:0.7150\n",
      "epoch:  20 loss:0.351849 auc:0.8061\n",
      "epoch:  20 loss:0.352679 auc:0.6580\n",
      "epoch:  20 loss:0.349571 auc:0.7356\n",
      "epoch:  20 loss:0.351609 auc:0.6236\n",
      "epoch:  20 loss:0.348641 auc:0.6425\n",
      "epoch:  20 loss:0.357212 auc:0.5644\n",
      "epoch:  20 loss:0.354854 auc:0.5476\n",
      "epoch:  20 loss:0.356003 auc:0.6653\n",
      "epoch:  40 loss:0.329912 auc:0.7456\n",
      "epoch:  20 loss:0.350143 auc:0.5135\n",
      "epoch:  20 loss:0.355374 auc:0.7755\n",
      "epoch:  20 loss:0.353726 auc:0.7344\n",
      "epoch:  20 loss:0.349686 auc:0.6043\n",
      "epoch:  20 loss:0.353972 auc:0.5235\n",
      "epoch:  20 loss:0.352750 auc:0.4633\n",
      "epoch:  20 loss:0.348938 auc:0.5966\n",
      "epoch:  20 loss:0.355565 auc:0.6000\n",
      "epoch:  20 loss:0.351231 auc:0.4773\n",
      "epoch:  20 loss:0.352099 auc:0.6311\n",
      "epoch:  20 loss:0.355501 auc:0.2428\n",
      "epoch:  20 loss:0.351815 auc:0.5077\n",
      "epoch:  20 loss:0.354227 auc:0.4197\n",
      "epoch:  20 loss:0.352899 auc:0.4709\n",
      "epoch:  20 loss:0.351831 auc:0.6214\n",
      "epoch:  20 loss:0.353847 auc:0.4357\n",
      "epoch:  20 loss:0.349509 auc:0.4724\n",
      "epoch:  20 loss:0.354620 auc:0.4760\n",
      "epoch:  20 loss:0.353583 auc:0.4314\n",
      "epoch:  20 loss:0.353995 auc:0.7425\n",
      "epoch:  20 loss:0.351663 auc:0.5212\n",
      "epoch:  20 loss:0.351530 auc:0.6300\n",
      "epoch:  20 loss:0.352826 auc:0.4772\n",
      "epoch:  20 loss:0.351618 auc:0.4510\n",
      "epoch:  40 loss:0.326879 auc:0.7020\n",
      "epoch:  40 loss:0.329359 auc:0.7222\n",
      "epoch:  40 loss:0.326463 auc:0.8163\n",
      "epoch:  60 loss:0.306958 auc:0.7319\n",
      "epoch:  40 loss:0.330111 auc:0.6910\n",
      "epoch:  40 loss:0.331774 auc:0.7607\n",
      "epoch:  40 loss:0.323482 auc:0.9067\n",
      "epoch:  40 loss:0.330634 auc:0.6876\n",
      "epoch:  40 loss:0.327218 auc:0.6514\n",
      "epoch:  40 loss:0.327720 auc:0.7732\n",
      "epoch:  40 loss:0.330165 auc:0.7447\n",
      "epoch:  40 loss:0.326702 auc:0.6962\n",
      "epoch:  40 loss:0.331068 auc:0.8000\n",
      "epoch:  40 loss:0.326637 auc:0.7258\n",
      "epoch:  40 loss:0.323453 auc:0.7441\n",
      "epoch:  40 loss:0.325136 auc:0.8338\n",
      "epoch:  40 loss:0.331366 auc:0.9236\n",
      "epoch:  40 loss:0.330770 auc:0.6374\n",
      "epoch:  60 loss:0.303042 auc:0.7778\n",
      "epoch:  60 loss:0.303057 auc:0.6651\n",
      "epoch:  60 loss:0.307065 auc:0.7026\n",
      "epoch:  80 loss:0.283633 auc:0.7412\n",
      "epoch:  60 loss:0.308847 auc:0.7441\n",
      "epoch:  60 loss:0.307578 auc:0.6838\n",
      "epoch:  80 loss:0.278677 auc:0.8095\n",
      "epoch:  60 loss:0.303722 auc:0.6576\n",
      "epoch:  80 loss:0.278611 auc:0.6916\n",
      "epoch:  80 loss:0.282270 auc:0.7231\n",
      "epoch:  60 loss:0.297263 auc:0.8533\n",
      "epoch: 100 loss:0.265376 auc:0.7575\n",
      "epoch:  80 loss:0.285312 auc:0.7617\n",
      "epoch:  80 loss:0.283945 auc:0.6995\n",
      "epoch: 100 loss:0.260879 auc:0.7982\n",
      "epoch: 100 loss:0.259556 auc:0.6892\n",
      "epoch: 100 loss:0.265064 auc:0.7134\n",
      "epoch: 120 loss:0.251141 auc:0.7544\n",
      "epoch:  80 loss:0.279800 auc:0.7033\n",
      "epoch:  80 loss:0.273992 auc:0.8978\n",
      "epoch:  60 loss:0.302389 auc:0.7590\n",
      "epoch:  60 loss:0.308326 auc:0.7137\n",
      "epoch:  60 loss:0.309024 auc:0.9444\n",
      "epoch:  60 loss:0.309070 auc:0.7704\n",
      "epoch:  60 loss:0.297602 auc:0.7390\n",
      "epoch: 120 loss:0.252017 auc:0.7891\n",
      "epoch: 120 loss:0.249783 auc:0.7137\n",
      "epoch: 140 loss:0.242232 auc:0.7681\n",
      "epoch: 120 loss:0.250297 auc:0.6982\n",
      "epoch: 100epoch: 100 loss:0.264208 auc:0.7291\n",
      " loss:0.264754 auc:0.7656\n",
      "epoch: 100 loss:0.263611 auc:0.7579\n",
      "epoch: 100 loss:0.256342 auc:0.9022\n",
      "epoch:  60 loss:0.304323 auc:0.8185\n",
      "epoch: 140 loss:0.242300 auc:0.7914\n",
      "epoch:  80 loss:0.284401 auc:0.7449\n",
      "epoch:  80 loss:0.279427 auc:0.7577\n",
      "epoch: 160 loss:0.237312 auc:0.7619\n",
      "epoch: 140 loss:0.240320 auc:0.7100\n",
      "epoch: 140 loss:0.243961 auc:0.6772\n",
      "epoch:  80 loss:0.285702 auc:0.7511\n",
      "epoch:  80 loss:0.285450 auc:0.9236\n",
      "epoch:  60 loss:0.303164 auc:0.6500\n",
      "epoch:  60 loss:0.299505 auc:0.8560\n",
      "epoch: 120 loss:0.258749 auc:0.7416\n",
      "epoch: 120 loss:0.252755 auc:0.7539\n",
      "epoch:  80 loss:0.273398 auc:0.7564\n",
      "epoch: 120 loss:0.249270 auc:0.7545\n",
      "epoch: 160 loss:0.240023 auc:0.8005\n",
      "epoch: 180 loss:0.232601 auc:0.7612\n",
      "epoch: 120 loss:0.246795 auc:0.9022\n",
      "epoch: 160 loss:0.236367 auc:0.7218\n",
      "epoch: 160 loss:0.236849 auc:0.6857\n",
      "epoch: 140 loss:0.243046 auc:0.7295\n",
      "epoch: 140 loss:0.243364 auc:0.7732\n",
      "epoch: 100 loss:0.277776 auc:0.7687\n",
      "epoch: 100 loss:0.260735 auc:0.7433\n",
      "epoch: 200 loss:0.231339 auc:0.7750\n",
      "epoch: 180 loss:0.232779 auc:0.7800\n",
      "epoch: 140 loss:0.241705 auc:0.7304\n",
      "epoch: 180 loss:0.231701 auc:0.7243\n",
      "epoch: 180 loss:0.233540 auc:0.6555\n",
      "epoch: 140 loss:0.239125 auc:0.9022\n",
      "epoch: 100 loss:0.265190 auc:0.7456\n",
      "epoch: 220 loss:0.227449 auc:0.7650\n",
      "epoch: 160 loss:0.237099 auc:0.7580\n",
      "epoch: 200 loss:0.230399 auc:0.7710\n",
      "epoch: 160 loss:0.237494 auc:0.7178\n",
      "epoch: 120 loss:0.252374 auc:0.7698\n",
      "epoch: 100 loss:0.265840 auc:0.9375\n",
      "epoch: 200 loss:0.235552 auc:0.6845\n",
      "epoch: 160 loss:0.235485 auc:0.7214\n",
      "epoch: 200 loss:0.233790 auc:0.6263\n",
      "epoch: 240 loss:0.229673 auc:0.7694\n",
      "epoch: 220 loss:0.228875 auc:0.7438\n",
      "epoch: 160 loss:0.234761 auc:0.9022\n",
      "epoch: 120 loss:0.248175 auc:0.7529\n",
      "epoch: 180 loss:0.235676 auc:0.7400\n",
      "epoch: 180 loss:0.234424 auc:0.7002\n",
      "epoch: 220 loss:0.227520 auc:0.7314\n",
      "epoch: 100 loss:0.261503 auc:0.7733\n",
      "epoch: 220 loss:0.227345 auc:0.6102\n",
      "epoch: 140 loss:0.243393 auc:0.7800\n",
      "epoch: 260 loss:0.224307 auc:0.7581\n",
      "epoch: 180 loss:0.244988 auc:0.6911\n",
      "epoch: 240 loss:0.226178 auc:0.7710\n",
      "epoch:  80 loss:0.279970 auc:0.8166\n",
      "epoch: 200 loss:0.229320 auc:0.7416\n",
      "epoch: 120 loss:0.251649 auc:0.7539\n",
      "epoch: 200 loss:0.230947 auc:0.7041\n",
      "epoch: 180 loss:0.232952 auc:0.8978\n",
      "epoch: 240 loss:0.225011 auc:0.7331\n",
      "epoch: 140 loss:0.241247 auc:0.7511\n",
      "epoch: 280 loss:0.224710 auc:0.7581\n",
      "epoch: 240 loss:0.229151 auc:0.5865\n",
      "epoch: 120 loss:0.251232 auc:0.9444\n",
      "epoch: 260epoch: 200 loss:0.229925 auc:0.7368\n",
      " loss:0.224152 auc:0.7528\n",
      "epoch: 160 loss:0.240667 auc:0.7783\n",
      "epoch: 220 loss:0.228965 auc:0.7394\n",
      "epoch: 260 loss:0.225517 auc:0.7306\n",
      "epoch: 220 loss:0.227884 auc:0.6738\n",
      "epoch: 200 loss:0.229008 auc:0.8889\n",
      "epoch: 300 loss:0.221718 auc:0.7556\n",
      "epoch: 260 loss:0.224136 auc:0.6142\n",
      "epoch: 140 loss:0.247064 auc:0.7456\n",
      "epoch: 280 loss:0.224872 auc:0.7370\n",
      "epoch: 160 loss:0.235628 auc:0.7465\n",
      "epoch: 220 loss:0.226665 auc:0.7077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 240 loss:0.225055 auc:0.7268\n",
      "epoch: 280 loss:0.222799 auc:0.7294\n",
      "epoch: 180 loss:0.233903 auc:0.7704\n",
      "epoch: 240 loss:0.231603 auc:0.6650\n",
      "epoch:  60 loss:0.309749 auc:0.7400\n",
      "epoch: 120 loss:0.245704 auc:0.7793\n",
      "epoch:  60 loss:0.307562 auc:0.6253\n",
      "epoch: 320 loss:0.224103 auc:0.7438\n",
      "epoch: 280 loss:0.223097 auc:0.6187\n",
      "epoch: 300 loss:0.221925 auc:0.7460\n",
      "epoch: 220 loss:0.227815 auc:0.9022\n",
      "epoch: 140 loss:0.244512 auc:0.9514\n",
      "epoch: 240 loss:0.227754 auc:0.6821\n",
      "epoch: 100 loss:0.261579 auc:0.8166\n",
      "epoch: 300 loss:0.221497 auc:0.7394\n",
      "epoch: 260 loss:0.224231 auc:0.7223\n",
      "epoch: 180 loss:0.232645 auc:0.7403\n",
      "epoch:  80 loss:0.279769 auc:0.8643\n",
      "epoch: 340 loss:0.220244 auc:0.7512\n",
      "epoch: 160 loss:0.237772 auc:0.7576\n",
      "epoch: 260 loss:0.224921 auc:0.6855\n",
      "epoch: 200 loss:0.231538 auc:0.7738\n",
      "epoch: 300 loss:0.221380 auc:0.6014\n",
      "epoch: 320 loss:0.223794 auc:0.7188\n",
      "epoch: 240 loss:0.224752 auc:0.8978\n",
      "epoch:  80 loss:0.279208 auc:0.7295\n",
      "epoch: 320 loss:0.221211 auc:0.7371\n",
      "epoch: 360 loss:0.223971 auc:0.7000\n",
      "epoch: 260 loss:0.223517 auc:0.6884\n",
      "epoch: 280 loss:0.228142 auc:0.7423\n",
      "epoch: 340 loss:0.220234 auc:0.7256\n",
      "epoch: 280 loss:0.225037 auc:0.6621\n",
      "epoch: 320 loss:0.221508 auc:0.5981\n",
      "epoch: 220 loss:0.230293 auc:0.7596\n",
      "epoch: 200 loss:0.229747 auc:0.7407\n",
      "epoch: 380 loss:0.219167 auc:0.7456\n",
      "epoch: 340 loss:0.223491 auc:0.7418\n",
      "epoch: 260 loss:0.223886 auc:0.9067\n",
      "epoch: 180 loss:0.234057 auc:0.7649\n",
      "epoch: 160 loss:0.237558 auc:0.9514\n",
      "epoch: 300 loss:0.221558 auc:0.7305\n",
      "epoch: 360 loss:0.224124 auc:0.7279\n",
      "epoch: 280 loss:0.228974 auc:0.7212\n",
      "epoch: 340 loss:0.221271 auc:0.5856\n",
      "epoch: 300 loss:0.222214 auc:0.6846\n",
      "epoch: 140 loss:0.238993 auc:0.7801\n",
      "epoch: 400 loss:0.217985 auc:0.7481\n",
      "epoch: 360 loss:0.219182 auc:0.7449\n",
      "epoch: 240 loss:0.226235 auc:0.7528\n",
      "epoch: 380 loss:0.219321 auc:0.7211\n",
      "epoch: 280 loss:0.226513 auc:0.8800\n",
      "epoch: 360 loss:0.220560 auc:0.5747\n",
      "epoch: 320 loss:0.225318 auc:0.6861\n",
      "epoch: 220 loss:0.227129 auc:0.7339\n",
      "epoch: 300 loss:0.221832 auc:0.6922\n",
      "epoch: 320 loss:0.224969 auc:0.6865\n",
      "epoch: 420 loss:0.219607 auc:0.7625\n",
      "epoch: 380 loss:0.220057 auc:0.7469\n",
      "epoch: 400 loss:0.217945 auc:0.7120\n",
      "epoch: 200 loss:0.231214 auc:0.7704\n",
      "epoch: 380 loss:0.218392 auc:0.5716\n",
      "epoch: 340 loss:0.219843 auc:0.7174\n",
      "epoch: 260 loss:0.233479 auc:0.7426\n",
      "epoch: 180 loss:0.233095 auc:0.9444\n",
      "epoch: 440 loss:0.217178 auc:0.7431\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 47\u001b[0m\n\u001b[1;32m     41\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     42\u001b[0m     (dim, target_index, seed, args)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m seed, target_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(np\u001b[38;5;241m.\u001b[39marange(res\u001b[38;5;241m.\u001b[39mshape[dim]))\n\u001b[1;32m     44\u001b[0m ]\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# 並列実行（プログレスバー付き）\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessing dim \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdim\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# 結果の結合\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold_results \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[0;32m/scratch.global/inoue019/conda-envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch.global/inoue019/conda-envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/scratch.global/inoue019/conda-envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 300 loss:0.221835 auc:0.8711\n",
      "epoch: 340 loss:0.220391 auc:0.6621\n",
      "epoch: 400 loss:0.217863 auc:0.7433\n",
      "epoch: 320 loss:0.220234 auc:0.6833\n",
      "epoch: 120 loss:0.248842 auc:0.8223\n",
      "epoch: 420 loss:0.219251 auc:0.7279\n",
      "epoch: 240 loss:0.226776 auc:0.7351\n",
      "epoch: 160 loss:0.233928 auc:0.7786\n",
      "epoch: 400 loss:0.219931 auc:0.5817\n",
      "epoch: 460 loss:0.220270 auc:0.7256\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_kfold = 1\n",
    "n_jobs = 50  # 並列数\n",
    "\n",
    "\n",
    "def process_iteration(dim, target_index, seed, args):\n",
    "    \"\"\"各反復処理をカプセル化した関数\"\"\"\n",
    "    if dim:\n",
    "        if drug_sum[target_index] < 10:\n",
    "            return None, None\n",
    "    else:\n",
    "        if cell_sum[target_index] < 10:\n",
    "            return None, None\n",
    "\n",
    "    fold_results = []\n",
    "    for fold in range(n_kfold):\n",
    "        true_data, predict_data = nihgcn_new(\n",
    "            cell_exprs=exprs,\n",
    "            drug_finger=drug_finger,\n",
    "            res_mat=res,\n",
    "            null_mask=null_mask,\n",
    "            target_dim=dim,\n",
    "            target_index=target_index,\n",
    "            evaluate_fun=roc_auc,\n",
    "            args=args,\n",
    "            seed=seed,\n",
    "        )\n",
    "        fold_results.append((true_data, predict_data))\n",
    "\n",
    "    return fold_results\n",
    "\n",
    "\n",
    "# 並列処理の実行\n",
    "true_data_s = pd.DataFrame()\n",
    "predict_data_s = pd.DataFrame()\n",
    "\n",
    "for dim in target_dim:\n",
    "    # 全タスクを事前に生成\n",
    "    tasks = [\n",
    "        (dim, target_index, seed, args)\n",
    "        for seed, target_index in enumerate(np.arange(res.shape[dim]))\n",
    "    ]\n",
    "\n",
    "    # 並列実行（プログレスバー付き）\n",
    "    results = Parallel(n_jobs=n_jobs, verbose=0, prefer=\"threads\")(\n",
    "        delayed(process_iteration)(*task)\n",
    "        for task in tqdm(tasks, desc=f\"Processing dim {dim}\")\n",
    "    )\n",
    "\n",
    "    # 結果の結合\n",
    "    for fold_results in results:\n",
    "        if fold_results is None:\n",
    "            continue\n",
    "        for true_data, predict_data in fold_results:\n",
    "            true_data_s = pd.concat(\n",
    "                [true_data_s, translate_result(true_data)],\n",
    "                ignore_index=True,\n",
    "                copy=False,  # メモリ節約のため\n",
    "            )\n",
    "            predict_data_s = pd.concat(\n",
    "                [predict_data_s, translate_result(predict_data)],\n",
    "                ignore_index=True,\n",
    "                copy=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data_s.to_csv(f\"new_drug_true_{args.data}.csv\")\n",
    "predict_data_s.to_csv(f\"new_drug_pred_{args.data}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-bidder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-essex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-currency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-malaysia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-philippines",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-importance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-candidate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-maria",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genex",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
