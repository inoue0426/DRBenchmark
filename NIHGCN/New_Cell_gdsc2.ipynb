{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "precious-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "separate-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from load_data import load_data\n",
    "from model import Optimizer, nihgcn\n",
    "from myutils import *\n",
    "from sampler import NewSampler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "simple-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )  # cuda:number or cpu\n",
    "        self.data = \"gdsc2\"  # Dataset{gdsc or ccle}\n",
    "        self.lr = 0.001  # the learning rate\n",
    "        self.wd = 1e-5  # the weight decay for l2 normalizaton\n",
    "        self.layer_size = [1024, 1024]  # Output sizes of every layer\n",
    "        self.alpha = 0.25  # the scale for balance gcn and ni\n",
    "        self.gamma = 8  # the scale for sigmod\n",
    "        self.epochs = 1000  # the epochs for model\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "another-sensitivity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load gdsc2\n"
     ]
    }
   ],
   "source": [
    "res, drug_finger, exprs, null_mask, pos_num = load_data(args)\n",
    "cell_sum = np.sum(res, axis=1)\n",
    "drug_sum = np.sum(res, axis=0)\n",
    "\n",
    "target_dim = [\n",
    "    0,  # Cell\n",
    "    # 1  # Drug\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "grateful-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nihgcn_new(\n",
    "    cell_exprs,\n",
    "    drug_finger,\n",
    "    res_mat,\n",
    "    null_mask,\n",
    "    target_dim,\n",
    "    target_index,\n",
    "    evaluate_fun,\n",
    "    args,\n",
    "    seed,\n",
    "):\n",
    "\n",
    "    sampler = NewSampler(res_mat, null_mask, target_dim, target_index, seed)\n",
    "    model = nihgcn(\n",
    "        sampler.train_data,\n",
    "        cell_exprs=cell_exprs,\n",
    "        drug_finger=drug_finger,\n",
    "        layer_size=args.layer_size,\n",
    "        alpha=args.alpha,\n",
    "        gamma=args.gamma,\n",
    "        device=args.device,\n",
    "    )\n",
    "    opt = Optimizer(\n",
    "        model,\n",
    "        sampler.train_data,\n",
    "        sampler.test_data,\n",
    "        sampler.test_mask,\n",
    "        sampler.train_mask,\n",
    "        evaluate_fun,\n",
    "        lr=args.lr,\n",
    "        wd=args.wd,\n",
    "        epochs=args.epochs,\n",
    "        device=args.device,\n",
    "    )\n",
    "    true_data, predict_data = opt()\n",
    "    return true_data, predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spectacular-blank",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing dim 0:   0%|          | 0/910 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss:0.704774 auc:0.4911\n",
      "epoch:   0 loss:0.702121 auc:0.5513\n",
      "epoch:   0 loss:0.704717 auc:0.6457\n",
      "epoch:   0 loss:0.707030 auc:0.4475\n",
      "epoch:   0 loss:0.710614 auc:0.3345\n",
      "epoch:   0 loss:0.698764 auc:0.4452\n",
      "epoch:   0 loss:0.702891 auc:0.3217\n",
      "epoch:   0 loss:0.695418 auc:0.5845\n",
      "epoch:   0 loss:0.690566 auc:0.4977\n",
      "epoch:   0 loss:0.706130 auc:0.5718\n",
      "epoch:   0 loss:0.701533 auc:0.5511\n",
      "epoch:   0 loss:0.694574 auc:0.5224\n",
      "epoch:   0 loss:0.704751 auc:0.4405\n",
      "epoch:   0 loss:0.709357 auc:0.3952\n",
      "epoch:   0 loss:0.705153 auc:0.6278\n",
      "epoch:   0 loss:0.696670 auc:0.3563\n",
      "epoch:   0 loss:0.696496 auc:0.3984\n",
      "epoch:   0 loss:0.701929 auc:0.4916\n",
      "epoch:   0 loss:0.687916 auc:0.6497\n",
      "epoch:   0 loss:0.695700 auc:0.4949\n",
      "epoch:   0 loss:0.692385 auc:0.4559\n",
      "epoch:   0 loss:0.701390 auc:0.6195\n",
      "epoch:   0 loss:0.711387 auc:0.6597\n",
      "epoch:   0 loss:0.707878 auc:0.5918\n",
      "epoch:   0 loss:0.695575 auc:0.4716\n",
      "epoch:   0 loss:0.705569 auc:0.4757\n",
      "epoch:   0 loss:0.693635 auc:0.7031\n",
      "epoch:   0 loss:0.694222 auc:0.5130\n",
      "epoch:   0 loss:0.689969 auc:0.3573\n",
      "epoch:   0 loss:0.691578 auc:0.4803\n",
      "epoch:   0 loss:0.701522 auc:0.4427\n",
      "epoch:   0 loss:0.704358 auc:0.2600\n",
      "epoch:   0 loss:0.706249 auc:0.4947\n",
      "epoch:   0 loss:0.697333 auc:0.4525\n",
      "epoch:   0 loss:0.696507 auc:0.4861\n",
      "epoch:   0 loss:0.709471 auc:0.4912\n",
      "epoch:   0 loss:0.708777 auc:0.3857\n",
      "epoch:   0 loss:0.709411 auc:0.5208\n",
      "epoch:   0 loss:0.691615 auc:0.4931\n",
      "epoch:   0 loss:0.698105 auc:0.4709\n",
      "epoch:   0 loss:0.701769 auc:0.4729\n",
      "epoch:   0 loss:0.706370 auc:0.4571\n",
      "epoch:   0 loss:0.702478 auc:0.5243\n",
      "epoch:   0 loss:0.698268 auc:0.6590\n",
      "epoch:   0 loss:0.688365 auc:0.5603\n",
      "epoch:   0 loss:0.691314 auc:0.3960\n",
      "epoch:   0 loss:0.699122 auc:0.4426\n",
      "epoch:   0 loss:0.700268 auc:0.4887\n",
      "epoch:   0 loss:0.706085 auc:0.4528\n",
      "epoch:   0 loss:0.716172 auc:0.5391\n",
      "epoch:  20 loss:0.153940 auc:0.9810\n",
      "epoch:  20 loss:0.153561 auc:0.9519\n",
      "epoch:  20 loss:0.152852 auc:0.9723\n",
      "epoch:  20 loss:0.154558 auc:0.9865\n",
      "epoch:  20 loss:0.153290 auc:0.9751\n",
      "epoch:  20 loss:0.153508 auc:0.9954\n",
      "epoch:  20 loss:0.154354 auc:0.9584\n",
      "epoch:  20 loss:0.154037 auc:0.9920\n",
      "epoch:  20 loss:0.152853 auc:0.9952\n",
      "epoch:  20 loss:0.155167 auc:0.9595\n",
      "epoch:  20 loss:0.153322 auc:0.9586\n",
      "epoch:  20 loss:0.153086 auc:0.9845\n",
      "epoch:  20 loss:0.153328 auc:0.9822\n",
      "epoch:  20 loss:0.152973 auc:0.9886\n",
      "epoch:  20 loss:0.154558 auc:0.9624\n",
      "epoch:  20 loss:0.153600 auc:0.9823\n",
      "epoch:  20 loss:0.153226 auc:1.0000\n",
      "epoch:  20 loss:0.154878 auc:0.9976\n",
      "epoch:  20 loss:0.153260 auc:0.9579\n",
      "epoch:  20 loss:0.153151 auc:0.9731\n",
      "epoch:  20 loss:0.155644 auc:0.9432\n",
      "epoch:  20 loss:0.153932 auc:0.9931\n",
      "epoch:  20 loss:0.154226 auc:0.9972\n",
      "epoch:  20 loss:0.153453 auc:0.9732\n",
      "epoch:  20 loss:0.153329 auc:0.9477\n",
      "epoch:  20 loss:0.153790 auc:0.9972\n",
      "epoch:  20 loss:0.154683 auc:0.9612\n",
      "epoch:  20 loss:0.154458 auc:0.9751\n",
      "epoch:  20 loss:0.154021 auc:0.9719\n",
      "epoch:  20 loss:0.154230 auc:0.9979\n",
      "epoch:  20 loss:0.153160 auc:0.9732\n",
      "epoch:  20 loss:0.153806 auc:0.9401\n",
      "epoch:  20 loss:0.153544 auc:0.9853\n",
      "epoch:  20 loss:0.152729 auc:0.9796\n",
      "epoch:  20 loss:0.153406 auc:0.9724\n",
      "epoch:  20 loss:0.152957 auc:0.9828\n",
      "epoch:  20 loss:0.152935 auc:0.9754\n",
      "epoch:  20 loss:0.152317 auc:0.8980\n",
      "epoch:  20 loss:0.155540 auc:0.9759\n",
      "epoch:  20 loss:0.154408 auc:0.9444\n",
      "epoch:  20 loss:0.155105 auc:0.9844\n",
      "epoch:  20 loss:0.153193 auc:0.9687\n",
      "epoch:  20 loss:0.153101 auc:0.9993\n",
      "epoch:  20 loss:0.154632 auc:0.9545\n",
      "epoch:  20 loss:0.153129 auc:0.9521\n",
      "epoch:  20 loss:0.153589 auc:0.8834\n",
      "epoch:  20 loss:0.153313 auc:0.9184\n",
      "epoch:  20 loss:0.154942 auc:0.9753\n",
      "epoch:  20 loss:0.154168 auc:0.9493\n",
      "epoch:  20 loss:0.154936 auc:1.0000\n",
      "epoch:  40 loss:0.138139 auc:0.9844\n",
      "epoch:  40 loss:0.136812 auc:0.9554\n",
      "epoch:  40 loss:0.137469 auc:0.9869\n",
      "epoch:  40 loss:0.136835 auc:0.9770\n",
      "epoch:  40 loss:0.138717 auc:0.9692\n",
      "epoch:  40 loss:0.135673 auc:0.9976\n",
      "epoch:  40 loss:0.137509 auc:0.9662\n",
      "epoch:  40 loss:0.136597 auc:0.9730\n",
      "epoch:  40 loss:0.136777 auc:0.9627\n",
      "epoch:  60 loss:0.123809 auc:0.9865\n",
      "epoch:  40 loss:0.138469 auc:0.9983\n",
      "epoch:  60 loss:0.122909 auc:0.9572\n",
      "epoch:  80 loss:0.114695 auc:0.9875\n",
      "epoch:  60 loss:0.124794 auc:0.9744\n",
      "epoch:  60 loss:0.123638 auc:0.9694\n",
      "epoch:  60 loss:0.123023 auc:0.9767\n",
      "epoch:  60 loss:0.123464 auc:0.9934\n",
      "epoch:  60 loss:0.123183 auc:0.9678\n",
      "epoch:  80 loss:0.114270 auc:0.9561\n",
      "epoch:  60 loss:0.122670 auc:0.9988\n",
      "epoch:  60 loss:0.123125 auc:0.9792\n",
      "epoch:  40 loss:0.137175 auc:0.9525\n",
      "epoch:  40 loss:0.138732 auc:0.9733\n",
      "epoch:  40 loss:0.137479 auc:0.9719\n",
      "epoch:  40 loss:0.137060 auc:0.9762\n",
      "epoch:  40 loss:0.136894 auc:0.9783\n",
      "epoch:  40 loss:0.138145 auc:0.9673\n",
      "epoch:  60 loss:0.124656 auc:0.9977\n",
      "epoch: 100 loss:0.108422 auc:0.9875\n",
      "epoch:  80 loss:0.115666 auc:0.9744\n",
      "epoch:  40 loss:0.137423 auc:0.9727\n",
      "epoch:  40 loss:0.136298 auc:0.9917\n",
      "epoch:  40 loss:0.138974 auc:0.9976\n",
      "epoch:  40 loss:0.136442 auc:0.9761\n",
      "epoch: 100 loss:0.108200 auc:0.9567\n",
      "epoch:  80 loss:0.114829 auc:0.9912\n",
      "epoch:  80 loss:0.114504 auc:0.9805\n",
      "epoch:  80 loss:0.114872 auc:0.9706\n",
      "epoch:  80 loss:0.114684 auc:0.9718\n",
      "epoch:  80 loss:0.114654 auc:0.9976\n",
      "epoch:  80 loss:0.114657 auc:0.9792\n",
      "epoch: 120 loss:0.102423 auc:0.9854\n",
      "epoch:  80 loss:0.115530 auc:0.9960\n",
      "epoch: 100 loss:0.109524 auc:0.9688\n",
      "epoch:  60 loss:0.124847 auc:0.9886\n",
      "epoch: 120 loss:0.102321 auc:0.9578\n",
      "epoch:  60 loss:0.123431 auc:0.9834\n",
      "epoch:  60 loss:0.123593 auc:0.9547\n",
      "epoch: 100 loss:0.108897 auc:0.9706\n",
      "epoch:  60 loss:0.123114 auc:0.9783\n",
      "epoch: 100 loss:0.108527 auc:0.9727\n",
      "epoch: 100 loss:0.108847 auc:0.9927\n",
      "epoch: 100 loss:0.108410 auc:0.9818\n",
      "epoch: 140 loss:0.096971 auc:0.9823\n",
      "epoch: 100 loss:0.108730 auc:0.9952\n",
      "epoch: 100 loss:0.108737 auc:0.9799\n",
      "epoch: 120 loss:0.103738 auc:0.9640\n",
      "epoch:  60 loss:0.124050 auc:0.9673\n",
      "epoch:  60 loss:0.123834 auc:0.9712\n",
      "epoch: 100 loss:0.109324 auc:0.9955\n",
      "epoch: 140 loss:0.098625 auc:0.9550\n",
      "epoch:  80 loss:0.115945 auc:0.9916\n",
      "epoch: 120 loss:0.103132 auc:0.9731\n",
      "epoch: 160 loss:0.092580 auc:0.9834\n",
      "epoch: 120 loss:0.102548 auc:0.9693\n",
      "epoch: 140 loss:0.098186 auc:0.9580\n",
      "epoch: 120 loss:0.102416 auc:0.9821\n",
      "epoch: 120 loss:0.102949 auc:0.9920\n",
      "epoch: 120 loss:0.102901 auc:0.9952\n",
      "epoch: 120 loss:0.102967 auc:0.9813\n",
      "epoch: 160 loss:0.092419 auc:0.9602\n",
      "epoch:  80 loss:0.115181 auc:0.9489\n",
      "epoch:  80 loss:0.114814 auc:0.9845\n",
      "epoch: 180 loss:0.088436 auc:0.9854\n",
      "epoch: 140 loss:0.098174 auc:0.9725\n",
      "epoch: 120 loss:0.103342 auc:0.9983\n",
      "epoch: 140 loss:0.098218 auc:0.9687\n",
      "epoch: 160 loss:0.094295 auc:0.9576\n",
      "epoch:  80 loss:0.114502 auc:0.9795\n",
      "epoch: 140 loss:0.098640 auc:0.9905\n",
      "epoch: 140 loss:0.097409 auc:0.9834\n",
      "epoch: 100 loss:0.109696 auc:0.9911\n",
      "epoch: 180 loss:0.088813 auc:0.9615\n",
      "epoch: 140 loss:0.098643 auc:0.9827\n",
      "epoch: 140 loss:0.100789 auc:0.9952\n",
      "epoch: 200 loss:0.085767 auc:0.9844\n",
      "epoch:  60 loss:0.122294 auc:0.9941\n",
      "epoch: 160 loss:0.093074 auc:0.9744\n",
      "epoch: 180 loss:0.089780 auc:0.9572\n",
      "epoch: 100 loss:0.108754 auc:0.9816\n",
      "epoch: 140 loss:0.098451 auc:0.9977\n",
      "epoch: 100 loss:0.109252 auc:0.9481\n",
      "epoch:  80 loss:0.115247 auc:0.9739\n",
      "epoch: 160 loss:0.092914 auc:0.9684\n",
      "epoch: 200 loss:0.085789 auc:0.9591\n",
      "epoch: 160 loss:0.092033 auc:0.9860\n",
      "epoch: 160 loss:0.092898 auc:0.9912\n",
      "epoch: 220 loss:0.083194 auc:0.9854\n",
      "epoch: 120 loss:0.103708 auc:0.9911\n",
      "epoch: 160 loss:0.092934 auc:0.9813\n",
      "epoch: 180 loss:0.088880 auc:0.9756\n",
      "epoch: 160 loss:0.092966 auc:0.9976\n",
      "epoch: 200 loss:0.088034 auc:0.9580\n",
      "epoch: 220 loss:0.083074 auc:0.9596\n",
      "epoch: 180 loss:0.088891 auc:0.9678\n",
      "epoch: 100 loss:0.108393 auc:0.9804\n",
      "epoch:  80 loss:0.115079 auc:0.9726\n",
      "epoch: 240 loss:0.082910 auc:0.9875\n",
      "epoch: 180 loss:0.088314 auc:0.9863\n",
      "epoch: 160 loss:0.093574 auc:0.9977\n",
      "epoch: 180 loss:0.089198 auc:0.9912\n",
      "epoch: 200 loss:0.086377 auc:0.9750\n",
      "epoch: 120 loss:0.102886 auc:0.9780\n",
      "epoch: 140 loss:0.097943 auc:0.9916\n",
      "epoch: 120 loss:0.103363 auc:0.9474\n",
      "epoch: 180 loss:0.089067 auc:0.9799\n",
      "epoch: 220epoch: 180 loss:0.088993 auc:0.9976\n",
      " loss:0.084102 auc:0.9540\n",
      "epoch: 240 loss:0.083114 auc:0.9554\n",
      "epoch: 200 loss:0.086596 auc:0.9658\n",
      "epoch: 260 loss:0.080047 auc:0.9875\n",
      "epoch: 100 loss:0.109067 auc:0.9771\n",
      "epoch: 200 loss:0.085558 auc:0.9863\n",
      "epoch: 200 loss:0.085842 auc:0.9905\n",
      "epoch: 180 loss:0.089469 auc:0.9983\n",
      "epoch: 220 loss:0.083574 auc:0.9712\n",
      "epoch: 240 loss:0.081949 auc:0.9532\n",
      "epoch: 260 loss:0.079687 auc:0.9585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 280 loss:0.078694 auc:0.9896\n",
      "epoch: 200 loss:0.086570 auc:0.9799\n",
      "epoch: 220 loss:0.083498 auc:0.9629\n",
      "epoch: 120 loss:0.102425 auc:0.9813\n",
      "epoch: 160 loss:0.093737 auc:0.9911\n",
      "epoch: 200 loss:0.086702 auc:0.9964\n",
      "epoch: 220 loss:0.083626 auc:0.9876\n",
      "epoch: 220 loss:0.085104 auc:0.9905\n",
      "epoch: 240 loss:0.085299 auc:0.9719\n",
      "epoch: 140epoch: 140 loss:0.097802 auc:0.9394\n",
      " loss:0.097320 auc:0.9792\n",
      "epoch: 260 loss:0.080682 auc:0.9412\n",
      "epoch: 280 loss:0.078408 auc:0.9576\n",
      "epoch: 300 loss:0.078179 auc:0.9896\n",
      "epoch: 240 loss:0.081820 auc:0.9632\n",
      "epoch: 200 loss:0.087935 auc:0.9972\n",
      "epoch: 220 loss:0.084290 auc:0.9792\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 47\u001b[0m\n\u001b[1;32m     41\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     42\u001b[0m     (dim, target_index, seed, args)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m seed, target_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(np\u001b[38;5;241m.\u001b[39marange(res\u001b[38;5;241m.\u001b[39mshape[dim]))\n\u001b[1;32m     44\u001b[0m ]\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# 並列実行（プログレスバー付き）\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessing dim \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdim\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# 結果の結合\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold_results \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[0;32m/scratch.global/inoue019/conda-envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch.global/inoue019/conda-envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/scratch.global/inoue019/conda-envs/myenv/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 220 loss:0.083585 auc:0.9964\n",
      "epoch: 240 loss:0.081239 auc:0.9901\n",
      "epoch: 260 loss:0.080234 auc:0.9731\n",
      "epoch: 280 loss:0.079066 auc:0.9448\n",
      "epoch: 180 loss:0.089340 auc:0.9916\n",
      "epoch: 300 loss:0.078317 auc:0.9580\n",
      "epoch: 320 loss:0.077068 auc:0.9896\n",
      "epoch: 240 loss:0.081684 auc:0.9898\n",
      "epoch:  60 loss:0.122851 auc:0.9764\n",
      "epoch: 260 loss:0.080931 auc:0.9615\n",
      "epoch: 240 loss:0.081558 auc:0.9785\n",
      "epoch: 160 loss:0.092621 auc:0.9792\n",
      "epoch:  80 loss:0.113934 auc:0.9905\n",
      "epoch:  60 loss:0.124052 auc:0.9648\n",
      "epoch:  60 loss:0.124936 auc:0.9984\n",
      "epoch: 220 loss:0.083971 auc:0.9972\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_kfold = 1\n",
    "n_jobs = 50  # 並列数\n",
    "\n",
    "\n",
    "def process_iteration(dim, target_index, seed, args):\n",
    "    \"\"\"各反復処理をカプセル化した関数\"\"\"\n",
    "    if dim:\n",
    "        if drug_sum[target_index] < 10:\n",
    "            return None, None\n",
    "    else:\n",
    "        if cell_sum[target_index] < 10:\n",
    "            return None, None\n",
    "\n",
    "    fold_results = []\n",
    "    for fold in range(n_kfold):\n",
    "        true_data, predict_data = nihgcn_new(\n",
    "            cell_exprs=exprs,\n",
    "            drug_finger=drug_finger,\n",
    "            res_mat=res,\n",
    "            null_mask=null_mask,\n",
    "            target_dim=dim,\n",
    "            target_index=target_index,\n",
    "            evaluate_fun=roc_auc,\n",
    "            args=args,\n",
    "            seed=seed,\n",
    "        )\n",
    "        fold_results.append((true_data, predict_data))\n",
    "\n",
    "    return fold_results\n",
    "\n",
    "\n",
    "# 並列処理の実行\n",
    "true_data_s = pd.DataFrame()\n",
    "predict_data_s = pd.DataFrame()\n",
    "\n",
    "for dim in target_dim:\n",
    "    # 全タスクを事前に生成\n",
    "    tasks = [\n",
    "        (dim, target_index, seed, args)\n",
    "        for seed, target_index in enumerate(np.arange(res.shape[dim]))\n",
    "    ]\n",
    "\n",
    "    # 並列実行（プログレスバー付き）\n",
    "    results = Parallel(n_jobs=n_jobs, verbose=0, prefer=\"threads\")(\n",
    "        delayed(process_iteration)(*task)\n",
    "        for task in tqdm(tasks, desc=f\"Processing dim {dim}\")\n",
    "    )\n",
    "\n",
    "    # 結果の結合\n",
    "    for fold_results in results:\n",
    "        if fold_results is None:\n",
    "            continue\n",
    "        for true_data, predict_data in fold_results:\n",
    "            true_data_s = pd.concat(\n",
    "                [true_data_s, translate_result(true_data)],\n",
    "                ignore_index=True,\n",
    "                copy=False,  # メモリ節約のため\n",
    "            )\n",
    "            predict_data_s = pd.concat(\n",
    "                [predict_data_s, translate_result(predict_data)],\n",
    "                ignore_index=True,\n",
    "                copy=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data_s.to_csv(f\"new_cell_true_{args.data}.csv\")\n",
    "predict_data_s.to_csv(f\"new_cell_pred_{args.data}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-september",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-domestic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-remains",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-knock",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-sword",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-twist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-geometry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genex",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
