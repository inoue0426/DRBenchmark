{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "874334de-4e40-4786-82f8-a6abfd5939f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
"cell_type": "code",
"execution_count": 2,
"id": "c8044c5c-f48a-490a-829f-e3eef1878c70",
"metadata": {},
"outputs": [],
"source": [
"%load_ext autoreload\n",
"%autoreload 2\n",
"\n",
"from load_data import load_data\n",
"from sampler import NewSampler\n",
"from DeepDSC.DeepDSC import (\n",
"    AE,\n",
"    DF,\n",
"    GeneExpressionDataset,\n",
"    calculate_morgan_fingerprints,\n",
"    prepare_data,\n",
"    prepare_drug_data,\n",
"    prepare_train_val_test_data,\n",
"    train_autoencoder,\n",
"    train_df_model\n",
")\n"
]
},
{
"cell_type": "code",
"execution_count": 3,
"id": "fbcf3b16-9be3-4bd4-82ee-b9495131eb87",
"metadata": {},
"outputs": [],
"source": [
"data = \"ctrp\"\n",
"PATH = \"../ctrp_data/\"\n",
"\n",
"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
]
},
{
"cell_type": "code",
"execution_count": 5,
"id": "f525656d-e3d7-49b8-9ea9-7f8741a77f1d",
"metadata": {},
"outputs": [],
"source": [
"class Args:\n",
"    def __init__(self):\n",
"        self.device = device  # cuda:number or cpu\n",
    "        self.data = \"gdsc2\"  # Dataset{gdsc or ccle}\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "args = Args()\n",
    "res, drug_feature, exprs, mut, cna, null_mask, pos_num = load_data(args)\n",
    "cells = {i: j for i, j in enumerate(res.index)}\n",
    "drugs = {i: j for i, j in enumerate(res.columns)}\n",
    "\n",
    "cell_sum = np.sum(res, axis=1)\n",
    "drug_sum = np.sum(res, axis=0)\n",
    "\n",
    "target_dim = [\n",
    "    # 0,  # Drug\n",
    "    1  # Cell\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8485f0-121b-4163-9154-35440784d414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "153895c8-aa54-4707-9f00-2e5e84372e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(PATH, train, val):\n",
    "    print(\"Loading gene expression data...\")\n",
    "    normalized_gene_exp_tensor, gene_exp = prepare_data(\n",
    "        data1=PATH + \"/gene_exp_part1.csv.gz\", data2=PATH + \"gene_exp_part2.csv.gz\"\n",
    "    )\n",
    "    normalized_gene_exp_dataset = GeneExpressionDataset(normalized_gene_exp_tensor)\n",
    "    normalized_gene_exp_dataloader = DataLoader(\n",
    "        normalized_gene_exp_dataset, batch_size=10000, shuffle=True\n",
    "    )\n",
    "\n",
    "    print(\"Training autoencoder...\")\n",
    "    autoencoder = AE(normalized_gene_exp_tensor.shape[1]).to(device)\n",
    "    train_autoencoder(autoencoder, normalized_gene_exp_dataloader)\n",
    "    print(\"Autoencoder training completed.\")\n",
    "\n",
    "    print(\"Extracting compressed features...\")\n",
    "    compressed_features_tensor = autoencoder.encoder(normalized_gene_exp_tensor)\n",
    "    compressed_features = pd.DataFrame(\n",
    "        compressed_features_tensor.cpu().detach().numpy(), index=gene_exp.columns\n",
    "    )\n",
    "    print(f\"Compressed features shape: {compressed_features.shape}\")\n",
    "    drug_response, nsc_sm = prepare_drug_data(is_nsc=False, is_gdsc=False, is_1=False)\n",
    "    mfp = calculate_morgan_fingerprints(drug_response, nsc_sm)\n",
    "    print(f\"Morgan fingerprints shape: {mfp.shape}\")\n",
    "\n",
    "    train_labels = train[2]\n",
    "    val_labels = val[2]\n",
    "    train_data = train[[0, 1]]\n",
    "    val_data = val[[0, 1]]\n",
    "    \n",
    "    print(\n",
    "        f\"Training data size: {len(train_data)}, Validation data size: {len(val_data)}\"\n",
    "    )\n",
    "    train_data, val_data = prepare_train_val_test_data(\n",
    "        train_data, val_data, compressed_features, mfp\n",
    "    )\n",
    "    df_model = DF().to(device)\n",
    "    val_labels, best_val_out = train_df_model(\n",
    "        df_model,\n",
    "        train_data,\n",
    "        val_data,\n",
    "        torch.tensor(train_labels).double().to(device),\n",
    "        torch.tensor(val_labels).double().to(device),\n",
    "    )\n",
    "    print(\"DF model training completed.\")\n",
    "    return val_labels, best_val_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b29a457-3b31-4052-85d3-9ae0c530b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepDSC(res_mat, null_mask, target_dim, target_index, seed):\n",
    "    sampler = NewSampler(res_mat, null_mask, target_dim, target_index, seed)\n",
    "\n",
    "    train_data = pd.DataFrame(sampler.train_data, index=res.index, columns=res.columns)\n",
    "    test_data = pd.DataFrame(sampler.test_data, index=res.index, columns=res.columns)\n",
    "\n",
    "    train_mask = pd.DataFrame(sampler.train_mask, index=res.index, columns=res.columns)\n",
    "    test_mask = pd.DataFrame(sampler.test_mask, index=res.index, columns=res.columns)\n",
    "\n",
    "    train = pd.DataFrame(train_mask.values.nonzero()).T\n",
    "    train[2] = train_data.values[train_mask.values.nonzero()].astype(int)\n",
    "\n",
    "    test = pd.DataFrame(test_mask.values.nonzero()).T\n",
    "    test[2] = test_data.values[test_mask.values.nonzero()].astype(int)\n",
    "\n",
    "    train[0] = [cells[i] for i in train[0]]\n",
    "    train[1] = [drugs[i] for i in train[1]]\n",
    "    test[0] = [cells[i] for i in test[0]]\n",
    "    test[1] = [drugs[i] for i in test[1]]\n",
    "\n",
    "    val_labels, best_val_out = main(PATH, train, test)\n",
    "    return val_labels, best_val_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f4626-f8db-43c8-8c8a-5e6008c44e84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/756 [00:00<?, ?it/s]/tmp/ipykernel_3353839/1143185186.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if drug_sum[target_index] < 10:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gene expression data...\n",
      "Training autoencoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/800 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/800 [00:01<20:26,  1.53s/it]\u001b[A\n",
      "  1%|▏         | 10/800 [00:01<01:38,  8.00it/s]\u001b[A\n",
      "  2%|▏         | 14/800 [00:01<01:14, 10.60it/s]\u001b[A\n",
      "  2%|▏         | 18/800 [00:02<00:59, 13.18it/s]\u001b[A\n",
      "  3%|▎         | 21/800 [00:02<00:51, 15.06it/s]\u001b[A\n",
      "  3%|▎         | 24/800 [00:02<00:46, 16.86it/s]\u001b[A\n",
      "  3%|▎         | 27/800 [00:02<00:41, 18.49it/s]\u001b[A\n",
      "  4%|▍         | 30/800 [00:02<00:38, 19.88it/s]\u001b[A\n",
      "  4%|▍         | 33/800 [00:02<00:36, 21.03it/s]\u001b[A\n",
      "  4%|▍         | 36/800 [00:02<00:34, 21.94it/s]\u001b[A\n",
      "  5%|▍         | 39/800 [00:02<00:33, 22.64it/s]\u001b[A\n",
      "  5%|▌         | 42/800 [00:02<00:32, 23.19it/s]\u001b[A\n",
      "  6%|▌         | 45/800 [00:03<00:31, 23.61it/s]\u001b[A\n",
      "  6%|▌         | 48/800 [00:03<00:31, 23.88it/s]\u001b[A\n",
      "  6%|▋         | 51/800 [00:03<00:31, 24.09it/s]\u001b[A\n",
      "  7%|▋         | 54/800 [00:03<00:30, 24.25it/s]\u001b[A\n",
      "  7%|▋         | 57/800 [00:03<00:30, 24.37it/s]\u001b[A\n",
      "  8%|▊         | 60/800 [00:03<00:30, 24.42it/s]\u001b[A\n",
      "  8%|▊         | 63/800 [00:03<00:30, 24.42it/s]\u001b[A\n",
      "  8%|▊         | 66/800 [00:03<00:30, 24.38it/s]\u001b[A\n",
      "  9%|▊         | 69/800 [00:04<00:30, 24.36it/s]\u001b[A\n",
      "  9%|▉         | 72/800 [00:04<00:29, 24.37it/s]\u001b[A\n",
      "  9%|▉         | 75/800 [00:04<00:29, 24.38it/s]\u001b[A\n",
      " 10%|▉         | 78/800 [00:04<00:29, 24.39it/s]\u001b[A\n",
      " 10%|█         | 81/800 [00:04<00:29, 24.40it/s]\u001b[A\n",
      " 10%|█         | 84/800 [00:04<00:29, 24.41it/s]\u001b[A\n",
      " 11%|█         | 87/800 [00:04<00:29, 24.41it/s]\u001b[A\n",
      " 11%|█▏        | 90/800 [00:04<00:29, 24.42it/s]\u001b[A\n",
      " 12%|█▏        | 93/800 [00:05<00:28, 24.43it/s]\u001b[A\n",
      " 12%|█▏        | 96/800 [00:05<00:28, 24.44it/s]\u001b[A\n",
      " 12%|█▏        | 99/800 [00:05<00:28, 24.47it/s]\u001b[A\n",
      " 13%|█▎        | 102/800 [00:05<00:28, 24.51it/s]\u001b[A\n",
      " 13%|█▎        | 105/800 [00:05<00:28, 24.53it/s]\u001b[A\n",
      " 14%|█▎        | 108/800 [00:05<00:28, 24.52it/s]\u001b[A\n",
      " 14%|█▍        | 111/800 [00:05<00:28, 24.47it/s]\u001b[A\n",
      " 14%|█▍        | 114/800 [00:05<00:28, 24.41it/s]\u001b[A\n",
      " 15%|█▍        | 117/800 [00:06<00:28, 24.38it/s]\u001b[A\n",
      " 15%|█▌        | 120/800 [00:06<00:27, 24.39it/s]\u001b[A\n",
      " 15%|█▌        | 123/800 [00:06<00:27, 24.37it/s]\u001b[A\n",
      " 16%|█▌        | 126/800 [00:06<00:27, 24.38it/s]\u001b[A\n",
      " 16%|█▌        | 129/800 [00:06<00:27, 24.39it/s]\u001b[A\n",
      " 16%|█▋        | 132/800 [00:06<00:27, 24.40it/s]\u001b[A\n",
      " 17%|█▋        | 135/800 [00:06<00:27, 24.41it/s]\u001b[A\n",
      " 17%|█▋        | 138/800 [00:06<00:27, 24.43it/s]\u001b[A\n",
      " 18%|█▊        | 141/800 [00:07<00:26, 24.46it/s]\u001b[A\n",
      " 18%|█▊        | 144/800 [00:07<00:26, 24.51it/s]\u001b[A\n",
      " 18%|█▊        | 147/800 [00:07<00:26, 24.53it/s]\u001b[A\n",
      " 19%|█▉        | 150/800 [00:07<00:26, 24.51it/s]\u001b[A\n",
      " 19%|█▉        | 153/800 [00:07<00:26, 24.46it/s]\u001b[A\n",
      " 20%|█▉        | 156/800 [00:07<00:26, 24.42it/s]\u001b[A\n",
      " 20%|█▉        | 159/800 [00:07<00:26, 24.38it/s]\u001b[A\n",
      " 20%|██        | 162/800 [00:07<00:26, 24.35it/s]\u001b[A\n",
      " 21%|██        | 165/800 [00:08<00:26, 24.35it/s]\u001b[A\n",
      " 21%|██        | 168/800 [00:08<00:25, 24.37it/s]\u001b[A\n",
      " 21%|██▏       | 171/800 [00:08<00:25, 24.39it/s]\u001b[A\n",
      " 22%|██▏       | 174/800 [00:08<00:25, 24.42it/s]\u001b[A\n",
      " 22%|██▏       | 177/800 [00:08<00:25, 24.43it/s]\u001b[A\n",
      " 22%|██▎       | 180/800 [00:08<00:25, 24.47it/s]\u001b[A\n",
      " 23%|██▎       | 183/800 [00:08<00:25, 24.52it/s]\u001b[A\n",
      " 23%|██▎       | 186/800 [00:08<00:25, 24.52it/s]\u001b[A\n",
      " 24%|██▎       | 189/800 [00:08<00:24, 24.47it/s]\u001b[A\n",
      " 24%|██▍       | 192/800 [00:09<00:24, 24.40it/s]\u001b[A\n",
      " 24%|██▍       | 195/800 [00:09<00:24, 24.37it/s]\u001b[A\n",
      " 25%|██▍       | 198/800 [00:09<00:24, 24.37it/s]\u001b[A\n",
      " 25%|██▌       | 201/800 [00:09<00:24, 24.34it/s]\u001b[A\n",
      " 26%|██▌       | 204/800 [00:09<00:24, 24.36it/s]\u001b[A\n",
      " 26%|██▌       | 207/800 [00:09<00:24, 24.38it/s]\u001b[A\n",
      " 26%|██▋       | 210/800 [00:09<00:24, 24.40it/s]\u001b[A\n",
      " 27%|██▋       | 213/800 [00:09<00:24, 24.42it/s]\u001b[A\n",
      " 27%|██▋       | 216/800 [00:10<00:23, 24.44it/s]\u001b[A\n",
      " 27%|██▋       | 219/800 [00:10<00:23, 24.49it/s]\u001b[A\n",
      " 28%|██▊       | 222/800 [00:10<00:23, 24.49it/s]\u001b[A\n",
      " 28%|██▊       | 225/800 [00:10<00:23, 24.50it/s]\u001b[A\n",
      " 28%|██▊       | 228/800 [00:10<00:23, 24.49it/s]\u001b[A\n",
      " 29%|██▉       | 231/800 [00:10<00:23, 24.49it/s]\u001b[A\n",
      " 29%|██▉       | 234/800 [00:10<00:23, 24.39it/s]\u001b[A\n",
      " 30%|██▉       | 237/800 [00:10<00:23, 24.31it/s]\u001b[A\n",
      " 30%|███       | 240/800 [00:11<00:23, 24.25it/s]\u001b[A\n",
      " 30%|███       | 243/800 [00:11<00:22, 24.27it/s]\u001b[A\n",
      " 31%|███       | 246/800 [00:11<00:22, 24.30it/s]\u001b[A\n",
      " 31%|███       | 249/800 [00:11<00:22, 24.33it/s]\u001b[A\n",
      " 32%|███▏      | 252/800 [00:11<00:22, 24.37it/s]\u001b[A\n",
      " 32%|███▏      | 255/800 [00:11<00:22, 24.41it/s]\u001b[A\n",
      " 32%|███▏      | 258/800 [00:11<00:22, 24.45it/s]\u001b[A\n",
      " 33%|███▎      | 261/800 [00:11<00:22, 24.44it/s]\u001b[A\n",
      " 33%|███▎      | 264/800 [00:12<00:21, 24.38it/s]\u001b[A\n",
      " 33%|███▎      | 267/800 [00:12<00:21, 24.32it/s]\u001b[A\n",
      " 34%|███▍      | 270/800 [00:12<00:21, 24.29it/s]\u001b[A\n",
      " 34%|███▍      | 273/800 [00:12<00:21, 24.25it/s]\u001b[A\n",
      " 34%|███▍      | 276/800 [00:12<00:21, 24.23it/s]\u001b[A\n",
      " 35%|███▍      | 279/800 [00:12<00:21, 24.26it/s]\u001b[A\n",
      " 35%|███▌      | 282/800 [00:12<00:21, 24.31it/s]\u001b[A\n",
      " 36%|███▌      | 285/800 [00:12<00:21, 24.37it/s]\u001b[A\n",
      " 36%|███▌      | 288/800 [00:13<00:20, 24.42it/s]\u001b[A\n",
      " 36%|███▋      | 291/800 [00:13<00:20, 24.42it/s]\u001b[A\n",
      " 37%|███▋      | 294/800 [00:13<00:20, 24.40it/s]\u001b[A\n",
      " 37%|███▋      | 297/800 [00:13<00:20, 24.36it/s]\u001b[A\n",
      " 38%|███▊      | 300/800 [00:13<00:20, 24.31it/s]\u001b[A\n",
      " 38%|███▊      | 303/800 [00:13<00:20, 24.27it/s]\u001b[A\n",
      " 38%|███▊      | 306/800 [00:13<00:20, 24.26it/s]\u001b[A\n",
      " 39%|███▊      | 309/800 [00:13<00:20, 24.27it/s]\u001b[A\n",
      " 39%|███▉      | 312/800 [00:14<00:20, 24.32it/s]\u001b[A\n",
      " 39%|███▉      | 315/800 [00:14<00:19, 24.35it/s]\u001b[A\n",
      " 40%|███▉      | 318/800 [00:14<00:19, 24.39it/s]\u001b[A\n",
      " 40%|████      | 321/800 [00:14<00:19, 24.44it/s]\u001b[A\n",
      " 40%|████      | 324/800 [00:14<00:19, 24.45it/s]\u001b[A\n",
      " 41%|████      | 327/800 [00:14<00:19, 24.42it/s]\u001b[A\n",
      " 41%|████▏     | 330/800 [00:14<00:19, 24.37it/s]\u001b[A\n",
      " 42%|████▏     | 333/800 [00:14<00:19, 24.31it/s]\u001b[A\n",
      " 42%|████▏     | 336/800 [00:15<00:19, 24.27it/s]\u001b[A\n",
      " 42%|████▏     | 339/800 [00:15<00:19, 24.25it/s]\u001b[A\n",
      " 43%|████▎     | 342/800 [00:15<00:18, 24.26it/s]\u001b[A\n",
      " 43%|████▎     | 345/800 [00:15<00:18, 24.30it/s]\u001b[A\n",
      " 44%|████▎     | 348/800 [00:15<00:18, 24.34it/s]\u001b[A\n",
      " 44%|████▍     | 351/800 [00:15<00:18, 24.38it/s]\u001b[A\n",
      " 44%|████▍     | 354/800 [00:15<00:18, 24.40it/s]\u001b[A\n",
      " 45%|████▍     | 357/800 [00:15<00:18, 24.39it/s]\u001b[A\n",
      " 45%|████▌     | 360/800 [00:16<00:18, 24.33it/s]\u001b[A\n",
      " 45%|████▌     | 363/800 [00:16<00:17, 24.30it/s]\u001b[A\n",
      " 46%|████▌     | 366/800 [00:16<00:17, 24.28it/s]\u001b[A\n",
      " 46%|████▌     | 369/800 [00:16<00:17, 24.26it/s]\u001b[A\n",
      " 46%|████▋     | 372/800 [00:16<00:17, 24.25it/s]\u001b[A\n",
      " 47%|████▋     | 375/800 [00:16<00:17, 24.30it/s]\u001b[A\n",
      " 47%|████▋     | 378/800 [00:16<00:17, 24.34it/s]\u001b[A\n",
      " 48%|████▊     | 381/800 [00:16<00:17, 24.39it/s]\u001b[A\n",
      " 48%|████▊     | 384/800 [00:17<00:17, 24.41it/s]\u001b[A\n",
      " 48%|████▊     | 387/800 [00:17<00:16, 24.41it/s]\u001b[A\n",
      " 49%|████▉     | 390/800 [00:17<00:16, 24.35it/s]\u001b[A\n",
      " 49%|████▉     | 393/800 [00:17<00:16, 24.30it/s]\u001b[A\n",
      " 50%|████▉     | 396/800 [00:17<00:16, 24.28it/s]\u001b[A\n",
      " 50%|████▉     | 399/800 [00:17<00:16, 24.26it/s]\u001b[A\n",
      " 50%|█████     | 402/800 [00:17<00:16, 24.25it/s]\u001b[A\n",
      " 51%|█████     | 405/800 [00:17<00:16, 24.26it/s]\u001b[A\n",
      " 51%|█████     | 408/800 [00:17<00:16, 24.30it/s]\u001b[A\n",
      " 51%|█████▏    | 411/800 [00:18<00:15, 24.35it/s]\u001b[A\n",
      " 52%|█████▏    | 414/800 [00:18<00:15, 24.39it/s]\u001b[A\n",
      " 52%|█████▏    | 417/800 [00:18<00:15, 24.41it/s]\u001b[A\n",
      " 52%|█████▎    | 420/800 [00:18<00:15, 24.38it/s]\u001b[A\n",
      " 53%|█████▎    | 423/800 [00:18<00:15, 24.30it/s]\u001b[A\n",
      " 53%|█████▎    | 426/800 [00:18<00:15, 24.27it/s]\u001b[A\n",
      " 54%|█████▎    | 429/800 [00:18<00:15, 24.26it/s]\u001b[A\n",
      " 54%|█████▍    | 432/800 [00:18<00:15, 24.25it/s]\u001b[A\n",
      " 54%|█████▍    | 435/800 [00:19<00:15, 24.24it/s]\u001b[A\n",
      " 55%|█████▍    | 438/800 [00:19<00:14, 24.27it/s]\u001b[A\n",
      " 55%|█████▌    | 441/800 [00:19<00:14, 24.32it/s]\u001b[A\n",
      " 56%|█████▌    | 444/800 [00:19<00:14, 24.37it/s]\u001b[A\n",
      " 56%|█████▌    | 447/800 [00:19<00:14, 24.41it/s]\u001b[A\n",
      " 56%|█████▋    | 450/800 [00:19<00:14, 24.41it/s]\u001b[A\n",
      " 57%|█████▋    | 453/800 [00:19<00:14, 24.35it/s]\u001b[A\n",
      " 57%|█████▋    | 456/800 [00:19<00:14, 24.30it/s]\u001b[A\n",
      " 57%|█████▋    | 459/800 [00:20<00:14, 24.27it/s]\u001b[A\n",
      " 58%|█████▊    | 462/800 [00:20<00:13, 24.26it/s]\u001b[A\n",
      " 58%|█████▊    | 465/800 [00:20<00:13, 24.25it/s]\u001b[A\n",
      " 58%|█████▊    | 468/800 [00:20<00:13, 24.24it/s]\u001b[A\n",
      " 59%|█████▉    | 471/800 [00:20<00:13, 24.29it/s]\u001b[A\n",
      " 59%|█████▉    | 474/800 [00:20<00:13, 24.34it/s]\u001b[A\n",
      " 60%|█████▉    | 477/800 [00:20<00:13, 24.38it/s]\u001b[A\n",
      " 60%|██████    | 480/800 [00:20<00:13, 24.43it/s]\u001b[A\n",
      " 60%|██████    | 483/800 [00:21<00:12, 24.42it/s]\u001b[A\n",
      " 61%|██████    | 486/800 [00:21<00:12, 24.36it/s]\u001b[A\n",
      " 61%|██████    | 489/800 [00:21<00:12, 24.30it/s]\u001b[A\n",
      " 62%|██████▏   | 492/800 [00:21<00:12, 24.27it/s]\u001b[A\n",
      " 62%|██████▏   | 495/800 [00:21<00:12, 24.23it/s]\u001b[A\n",
      " 62%|██████▏   | 498/800 [00:21<00:12, 24.23it/s]\u001b[A\n",
      " 63%|██████▎   | 501/800 [00:21<00:12, 24.29it/s]\u001b[A\n",
      " 63%|██████▎   | 504/800 [00:21<00:12, 24.33it/s]\u001b[A\n",
      " 63%|██████▎   | 507/800 [00:22<00:12, 24.37it/s]\u001b[A\n",
      " 64%|██████▍   | 510/800 [00:22<00:11, 24.40it/s]\u001b[A\n",
      " 64%|██████▍   | 513/800 [00:22<00:11, 24.43it/s]\u001b[A\n",
      " 64%|██████▍   | 516/800 [00:22<00:11, 24.41it/s]\u001b[A\n",
      " 65%|██████▍   | 519/800 [00:22<00:11, 24.34it/s]\u001b[A\n",
      " 65%|██████▌   | 522/800 [00:22<00:11, 24.30it/s]\u001b[A\n",
      " 66%|██████▌   | 525/800 [00:22<00:11, 24.27it/s]\u001b[A\n",
      " 66%|██████▌   | 528/800 [00:22<00:11, 24.25it/s]\u001b[A\n",
      " 66%|██████▋   | 531/800 [00:23<00:11, 24.24it/s]\u001b[A\n",
      " 67%|██████▋   | 534/800 [00:23<00:10, 24.29it/s]\u001b[A\n",
      " 67%|██████▋   | 537/800 [00:23<00:10, 24.33it/s]\u001b[A\n",
      " 68%|██████▊   | 540/800 [00:23<00:10, 24.38it/s]\u001b[A\n",
      " 68%|██████▊   | 543/800 [00:23<00:10, 24.41it/s]\u001b[A\n",
      " 68%|██████▊   | 546/800 [00:23<00:10, 24.43it/s]\u001b[A\n",
      " 69%|██████▊   | 549/800 [00:23<00:10, 24.37it/s]\u001b[A\n",
      " 69%|██████▉   | 552/800 [00:23<00:10, 24.32it/s]\u001b[A\n",
      " 69%|██████▉   | 555/800 [00:24<00:10, 24.29it/s]\u001b[A\n",
      " 70%|██████▉   | 558/800 [00:24<00:09, 24.25it/s]\u001b[A\n",
      " 70%|███████   | 561/800 [00:24<00:09, 24.24it/s]\u001b[A\n",
      " 70%|███████   | 564/800 [00:24<00:09, 24.26it/s]\u001b[A\n",
      " 71%|███████   | 567/800 [00:24<00:09, 24.30it/s]\u001b[A\n",
      " 71%|███████▏  | 570/800 [00:24<00:09, 24.34it/s]\u001b[A\n",
      " 72%|███████▏  | 573/800 [00:24<00:09, 24.38it/s]\u001b[A\n",
      " 72%|███████▏  | 576/800 [00:24<00:09, 24.41it/s]\u001b[A\n",
      " 72%|███████▏  | 579/800 [00:25<00:09, 24.40it/s]\u001b[A\n",
      " 73%|███████▎  | 582/800 [00:25<00:08, 24.33it/s]\u001b[A\n",
      " 73%|███████▎  | 585/800 [00:25<00:08, 24.29it/s]\u001b[A\n",
      " 74%|███████▎  | 588/800 [00:25<00:08, 24.26it/s]\u001b[A\n",
      " 74%|███████▍  | 591/800 [00:25<00:08, 24.23it/s]\u001b[A\n",
      " 74%|███████▍  | 594/800 [00:25<00:08, 24.25it/s]\u001b[A\n",
      " 75%|███████▍  | 597/800 [00:25<00:08, 24.29it/s]\u001b[A\n",
      " 75%|███████▌  | 600/800 [00:25<00:08, 24.34it/s]\u001b[A\n",
      " 75%|███████▌  | 603/800 [00:26<00:08, 24.39it/s]\u001b[A\n",
      " 76%|███████▌  | 606/800 [00:26<00:07, 24.41it/s]\u001b[A\n",
      " 76%|███████▌  | 609/800 [00:26<00:07, 24.39it/s]\u001b[A\n",
      " 76%|███████▋  | 612/800 [00:26<00:07, 24.32it/s]\u001b[A\n",
      " 77%|███████▋  | 615/800 [00:26<00:07, 24.28it/s]\u001b[A\n",
      " 77%|███████▋  | 618/800 [00:26<00:07, 24.25it/s]\u001b[A\n",
      " 78%|███████▊  | 621/800 [00:26<00:07, 24.24it/s]\u001b[A\n",
      " 78%|███████▊  | 624/800 [00:26<00:07, 24.26it/s]\u001b[A\n",
      " 78%|███████▊  | 627/800 [00:27<00:07, 24.30it/s]\u001b[A\n",
      " 79%|███████▉  | 630/800 [00:27<00:06, 24.36it/s]\u001b[A\n",
      " 79%|███████▉  | 633/800 [00:27<00:06, 24.39it/s]\u001b[A\n",
      " 80%|███████▉  | 636/800 [00:27<00:06, 24.42it/s]\u001b[A\n",
      " 80%|███████▉  | 639/800 [00:27<00:06, 24.36it/s]\u001b[A\n",
      " 80%|████████  | 642/800 [00:27<00:06, 24.30it/s]\u001b[A\n",
      " 81%|████████  | 645/800 [00:27<00:06, 24.28it/s]\u001b[A\n",
      " 81%|████████  | 648/800 [00:27<00:06, 24.23it/s]\u001b[A\n",
      " 81%|████████▏ | 651/800 [00:27<00:06, 24.23it/s]\u001b[A\n",
      " 82%|████████▏ | 654/800 [00:28<00:06, 24.25it/s]\u001b[A\n",
      " 82%|████████▏ | 657/800 [00:28<00:05, 24.30it/s]\u001b[A\n",
      " 82%|████████▎ | 660/800 [00:28<00:05, 24.34it/s]\u001b[A\n",
      " 83%|████████▎ | 663/800 [00:28<00:05, 24.38it/s]\u001b[A\n",
      " 83%|████████▎ | 666/800 [00:28<00:05, 24.41it/s]\u001b[A\n",
      " 84%|████████▎ | 669/800 [00:28<00:05, 24.39it/s]\u001b[A\n",
      " 84%|████████▍ | 672/800 [00:28<00:05, 24.34it/s]\u001b[A\n",
      " 84%|████████▍ | 675/800 [00:28<00:05, 24.29it/s]\u001b[A\n",
      " 85%|████████▍ | 678/800 [00:29<00:05, 24.25it/s]\u001b[A\n",
      " 85%|████████▌ | 681/800 [00:29<00:04, 24.24it/s]\u001b[A\n",
      " 86%|████████▌ | 684/800 [00:29<00:04, 24.24it/s]\u001b[A\n",
      " 86%|████████▌ | 687/800 [00:29<00:04, 24.29it/s]\u001b[A\n",
      " 86%|████████▋ | 690/800 [00:29<00:04, 24.34it/s]\u001b[A\n",
      " 87%|████████▋ | 693/800 [00:29<00:04, 24.38it/s]\u001b[A\n",
      " 87%|████████▋ | 696/800 [00:29<00:04, 24.38it/s]\u001b[A\n",
      " 87%|████████▋ | 699/800 [00:29<00:04, 24.33it/s]\u001b[A\n",
      " 88%|████████▊ | 702/800 [00:30<00:04, 24.28it/s]\u001b[A\n",
      " 88%|████████▊ | 705/800 [00:30<00:03, 24.27it/s]\u001b[A\n",
      " 88%|████████▊ | 708/800 [00:30<00:03, 24.25it/s]\u001b[A\n",
      " 89%|████████▉ | 711/800 [00:30<00:03, 24.24it/s]\u001b[A\n",
      " 89%|████████▉ | 714/800 [00:30<00:03, 24.26it/s]\u001b[A\n",
      " 90%|████████▉ | 717/800 [00:30<00:03, 24.31it/s]\u001b[A\n",
      " 90%|█████████ | 720/800 [00:30<00:03, 24.36it/s]\u001b[A\n",
      " 90%|█████████ | 723/800 [00:30<00:03, 24.40it/s]\u001b[A\n",
      " 91%|█████████ | 726/800 [00:31<00:03, 24.39it/s]\u001b[A\n",
      " 91%|█████████ | 729/800 [00:31<00:02, 24.31it/s]\u001b[A\n",
      " 92%|█████████▏| 732/800 [00:31<00:02, 24.29it/s]\u001b[A\n",
      " 92%|█████████▏| 735/800 [00:31<00:02, 24.25it/s]\u001b[A\n",
      " 92%|█████████▏| 738/800 [00:31<00:02, 24.24it/s]\u001b[A\n",
      " 93%|█████████▎| 741/800 [00:31<00:02, 24.24it/s]\u001b[A\n",
      " 93%|█████████▎| 744/800 [00:31<00:02, 24.28it/s]\u001b[A\n",
      " 93%|█████████▎| 747/800 [00:31<00:02, 24.33it/s]\u001b[A\n",
      " 94%|█████████▍| 750/800 [00:32<00:02, 24.36it/s]\u001b[A\n",
      " 94%|█████████▍| 753/800 [00:32<00:01, 24.40it/s]\u001b[A\n",
      " 94%|█████████▍| 756/800 [00:32<00:01, 24.37it/s]\u001b[A\n",
      " 95%|█████████▍| 759/800 [00:32<00:01, 24.30it/s]\u001b[A\n",
      " 95%|█████████▌| 762/800 [00:32<00:01, 24.27it/s]\u001b[A\n",
      " 96%|█████████▌| 765/800 [00:32<00:01, 24.23it/s]\u001b[A\n",
      " 96%|█████████▌| 768/800 [00:32<00:01, 24.21it/s]\u001b[A\n",
      " 96%|█████████▋| 771/800 [00:32<00:01, 24.25it/s]\u001b[A\n",
      " 97%|█████████▋| 774/800 [00:33<00:01, 24.30it/s]\u001b[A\n",
      " 97%|█████████▋| 777/800 [00:33<00:00, 24.35it/s]\u001b[A\n",
      " 98%|█████████▊| 780/800 [00:33<00:00, 24.39it/s]\u001b[A\n",
      " 98%|█████████▊| 783/800 [00:33<00:00, 24.39it/s]\u001b[A\n",
      " 98%|█████████▊| 786/800 [00:33<00:00, 24.37it/s]\u001b[A\n",
      " 99%|█████████▊| 789/800 [00:33<00:00, 24.32it/s]\u001b[A\n",
      " 99%|█████████▉| 792/800 [00:33<00:00, 24.29it/s]\u001b[A\n",
      " 99%|█████████▉| 795/800 [00:33<00:00, 24.22it/s]\u001b[A\n",
      "100%|██████████| 800/800 [00:34<00:00, 23.45it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder training completed.\n",
      "Extracting compressed features...\n",
      "Compressed features shape: (1089, 500)\n",
      "Morgan fingerprints shape: (460, 256)\n",
      "Training data size: 275467, Validation data size: 282\n",
      "Epoch 1 Loss: 0.816 Val Loss: 2.074\n",
      "Accuracy: 0.500\n",
      "Epoch 2 Loss: 1.638 Val Loss: 1.560\n",
      "Accuracy: 0.500\n",
      "Epoch 3 Loss: 1.245 Val Loss: 0.808\n",
      "Accuracy: 0.500\n",
      "Epoch 4 Loss: 0.704 Val Loss: 0.639\n",
      "Accuracy: 0.624\n",
      "Epoch 5 Loss: 0.700 Val Loss: 0.723\n",
      "Accuracy: 0.521\n",
      "Epoch 6 Loss: 0.846 Val Loss: 0.698\n",
      "Accuracy: 0.525\n",
      "Epoch 7 Loss: 0.810 Val Loss: 0.625\n",
      "Accuracy: 0.617\n",
      "Epoch 8 Loss: 0.688 Val Loss: 0.606\n",
      "Accuracy: 0.709\n",
      "Epoch 9 Loss: 0.609 Val Loss: 0.657\n",
      "Accuracy: 0.567\n",
      "Epoch 10 Loss: 0.608 Val Loss: 0.727\n",
      "Accuracy: 0.514\n",
      "Epoch 11 Loss: 0.642 Val Loss: 0.764\n",
      "Accuracy: 0.504\n",
      "Epoch 12 Loss: 0.663 Val Loss: 0.755\n",
      "Accuracy: 0.504\n",
      "Epoch 13 Loss: 0.657 Val Loss: 0.712\n",
      "Accuracy: 0.518\n",
      "Epoch 14 Loss: 0.628 Val Loss: 0.655\n",
      "Accuracy: 0.571\n",
      "Epoch 15 Loss: 0.595 Val Loss: 0.604\n",
      "Accuracy: 0.642\n",
      "Epoch 16 Loss: 0.570 Val Loss: 0.570\n",
      "Accuracy: 0.709\n",
      "Epoch 17 Loss: 0.560 Val Loss: 0.551\n",
      "Accuracy: 0.755\n",
      "Epoch 18 Loss: 0.561 Val Loss: 0.542\n",
      "Accuracy: 0.780\n",
      "Epoch 19 Loss: 0.566 Val Loss: 0.537\n",
      "Accuracy: 0.798\n",
      "Epoch 20 Loss: 0.569 Val Loss: 0.531\n",
      "Accuracy: 0.801\n",
      "Epoch 21 Loss: 0.565 Val Loss: 0.526\n",
      "Accuracy: 0.794\n",
      "Epoch 22 Loss: 0.555 Val Loss: 0.522\n",
      "Accuracy: 0.780\n",
      "Epoch 23 Loss: 0.543 Val Loss: 0.522\n",
      "Accuracy: 0.787\n",
      "Epoch 24 Loss: 0.533 Val Loss: 0.527\n",
      "Accuracy: 0.738\n",
      "Epoch 25 Loss: 0.526 Val Loss: 0.534\n",
      "Accuracy: 0.723\n",
      "Epoch 26 Loss: 0.523 Val Loss: 0.542\n",
      "Accuracy: 0.716\n",
      "Epoch 27 Loss: 0.523 Val Loss: 0.546\n",
      "Accuracy: 0.730\n",
      "Epoch 28 Loss: 0.522 Val Loss: 0.545\n",
      "Accuracy: 0.730\n",
      "Epoch 29 Loss: 0.520 Val Loss: 0.538\n",
      "Accuracy: 0.730\n",
      "Epoch 30 Loss: 0.516 Val Loss: 0.526\n",
      "Accuracy: 0.741\n",
      "Epoch 31 Loss: 0.509 Val Loss: 0.511\n",
      "Accuracy: 0.752\n",
      "Epoch 32 Loss: 0.503 Val Loss: 0.496\n",
      "Accuracy: 0.766\n",
      "Epoch 33 Loss: 0.497 Val Loss: 0.484\n",
      "Accuracy: 0.787\n",
      "Epoch 34 Loss: 0.493 Val Loss: 0.474\n",
      "Accuracy: 0.794\n",
      "Epoch 35 Loss: 0.491 Val Loss: 0.467\n",
      "Accuracy: 0.798\n",
      "Epoch 36 Loss: 0.490 Val Loss: 0.461\n",
      "Accuracy: 0.801\n",
      "Epoch 37 Loss: 0.488 Val Loss: 0.457\n",
      "Accuracy: 0.801\n",
      "Epoch 38 Loss: 0.485 Val Loss: 0.455\n",
      "Accuracy: 0.801\n",
      "Epoch 39 Loss: 0.482 Val Loss: 0.453\n",
      "Accuracy: 0.798\n",
      "Epoch 40 Loss: 0.478 Val Loss: 0.454\n",
      "Accuracy: 0.805\n",
      "Epoch 41 Loss: 0.474 Val Loss: 0.455\n",
      "Accuracy: 0.809\n",
      "Epoch 42 Loss: 0.471 Val Loss: 0.457\n",
      "Accuracy: 0.805\n",
      "Epoch 43 Loss: 0.469 Val Loss: 0.458\n",
      "Accuracy: 0.805\n",
      "Epoch 44 Loss: 0.467 Val Loss: 0.458\n",
      "Accuracy: 0.812\n",
      "Epoch 45 Loss: 0.466 Val Loss: 0.456\n",
      "Accuracy: 0.812\n",
      "Epoch 46 Loss: 0.464 Val Loss: 0.452\n",
      "Accuracy: 0.816\n",
      "Epoch 47 Loss: 0.461 Val Loss: 0.447\n",
      "Accuracy: 0.826\n",
      "Epoch 48 Loss: 0.459 Val Loss: 0.441\n",
      "Accuracy: 0.830\n",
      "Epoch 49 Loss: 0.456 Val Loss: 0.434\n",
      "Accuracy: 0.823\n",
      "Epoch 50 Loss: 0.454 Val Loss: 0.429\n",
      "Accuracy: 0.840\n",
      "Epoch 51 Loss: 0.452 Val Loss: 0.424\n",
      "Accuracy: 0.844\n",
      "Epoch 52 Loss: 0.450 Val Loss: 0.421\n",
      "Accuracy: 0.837\n",
      "Epoch 53 Loss: 0.449 Val Loss: 0.418\n",
      "Accuracy: 0.837\n",
      "Epoch 54 Loss: 0.447 Val Loss: 0.416\n",
      "Accuracy: 0.840\n",
      "Epoch 55 Loss: 0.445 Val Loss: 0.415\n",
      "Accuracy: 0.851\n",
      "Epoch 56 Loss: 0.443 Val Loss: 0.415\n",
      "Accuracy: 0.858\n",
      "Epoch 57 Loss: 0.441 Val Loss: 0.415\n",
      "Accuracy: 0.848\n",
      "Epoch 58 Loss: 0.439 Val Loss: 0.416\n",
      "Accuracy: 0.848\n",
      "Epoch 59 Loss: 0.438 Val Loss: 0.416\n",
      "Accuracy: 0.848\n",
      "Epoch 60 Loss: 0.437 Val Loss: 0.415\n",
      "Accuracy: 0.851\n",
      "Epoch 61 Loss: 0.435 Val Loss: 0.413\n",
      "Accuracy: 0.855\n",
      "Epoch 62 Loss: 0.434 Val Loss: 0.411\n",
      "Accuracy: 0.855\n",
      "Epoch 63 Loss: 0.432 Val Loss: 0.408\n",
      "Accuracy: 0.858\n",
      "Epoch 64 Loss: 0.431 Val Loss: 0.404\n",
      "Accuracy: 0.855\n",
      "Epoch 65 Loss: 0.429 Val Loss: 0.401\n",
      "Accuracy: 0.855\n",
      "Epoch 66 Loss: 0.428 Val Loss: 0.398\n",
      "Accuracy: 0.855\n",
      "Epoch 67 Loss: 0.427 Val Loss: 0.396\n",
      "Accuracy: 0.862\n",
      "Epoch 68 Loss: 0.426 Val Loss: 0.394\n",
      "Accuracy: 0.862\n",
      "Epoch 69 Loss: 0.424 Val Loss: 0.393\n",
      "Accuracy: 0.862\n",
      "Epoch 70 Loss: 0.423 Val Loss: 0.392\n",
      "Accuracy: 0.855\n",
      "Epoch 71 Loss: 0.422 Val Loss: 0.391\n",
      "Accuracy: 0.855\n",
      "Epoch 72 Loss: 0.421 Val Loss: 0.391\n",
      "Accuracy: 0.858\n",
      "Epoch 73 Loss: 0.420 Val Loss: 0.391\n",
      "Accuracy: 0.855\n",
      "Epoch 74 Loss: 0.419 Val Loss: 0.390\n",
      "Accuracy: 0.855\n",
      "Epoch 75 Loss: 0.418 Val Loss: 0.390\n",
      "Accuracy: 0.855\n",
      "Epoch 76 Loss: 0.417 Val Loss: 0.389\n",
      "Accuracy: 0.855\n",
      "Epoch 77 Loss: 0.416 Val Loss: 0.387\n",
      "Accuracy: 0.858\n",
      "Epoch 78 Loss: 0.415 Val Loss: 0.385\n",
      "Accuracy: 0.858\n",
      "Epoch 79 Loss: 0.414 Val Loss: 0.383\n",
      "Accuracy: 0.858\n",
      "Epoch 80 Loss: 0.413 Val Loss: 0.381\n",
      "Accuracy: 0.855\n",
      "Epoch 81 Loss: 0.412 Val Loss: 0.380\n",
      "Accuracy: 0.855\n",
      "Epoch 82 Loss: 0.411 Val Loss: 0.378\n",
      "Accuracy: 0.851\n",
      "Epoch 83 Loss: 0.410 Val Loss: 0.377\n",
      "Accuracy: 0.851\n",
      "Epoch 84 Loss: 0.410 Val Loss: 0.376\n",
      "Accuracy: 0.851\n",
      "Epoch 85 Loss: 0.409 Val Loss: 0.376\n",
      "Accuracy: 0.851\n",
      "Epoch 86 Loss: 0.408 Val Loss: 0.375\n",
      "Accuracy: 0.851\n",
      "Epoch 87 Loss: 0.407 Val Loss: 0.375\n",
      "Accuracy: 0.851\n",
      "Epoch 88 Loss: 0.407 Val Loss: 0.374\n",
      "Accuracy: 0.851\n",
      "Epoch 89 Loss: 0.406 Val Loss: 0.374\n",
      "Accuracy: 0.851\n",
      "Epoch 90 Loss: 0.405 Val Loss: 0.373\n",
      "Accuracy: 0.855\n",
      "Epoch 91 Loss: 0.404 Val Loss: 0.372\n",
      "Accuracy: 0.851\n",
      "Epoch 92 Loss: 0.404 Val Loss: 0.371\n",
      "Accuracy: 0.851\n"
     ]
    }
   ],
   "source": [
    "n_kfold = 1\n",
    "true_data_s = pd.DataFrame()\n",
    "predict_data_s = pd.DataFrame()\n",
    "for dim in target_dim:\n",
<<<<<<< HEAD
    "    for seed, target_index in tqdm(enumerate(np.arange(res.shape[dim]))):\n",
    "        p = res.iloc[:, target_index].dropna() > 0\n",
    "        tmp = sum(p) * 100 / len(p)\n",
    "        if 0 < tmp < 100:\n",
    "            if dim:\n",
    "                if drug_sum[target_index] < 10:\n",
    "                    continue\n",
    "            else:\n",
    "                if cell_sum[target_index] < 10:\n",
    "                    continue\n",
    "            epochs = []\n",
    "            for fold in range(n_kfold):\n",
    "                val_labels, best_val_out = DeepDSC(\n",
    "                    res.values, null_mask.T.values, dim, target_index, seed\n",
    "                )\n",
    "\n",
    "            true_data_s = pd.concat(\n",
    "                [true_data_s, pd.DataFrame(val_labels.cpu().numpy())], axis=1\n",
    "            )\n",
    "            predict_data_s = pd.concat(\n",
    "                [predict_data_s, pd.DataFrame(best_val_out.cpu().numpy())], axis=1\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            print(\n",
    "                f\"Target {target_index} skipped: All labels are {'0' if tmp == 0 else '1'}.\"\n",
    "            )"
=======
    "    for seed, target_index in enumerate(tqdm(np.arange(res.shape[dim]))):\n",
    "        if dim:\n",
    "            if drug_sum[target_index] < 10:\n",
    "                continue\n",
    "        else:\n",
    "            if cell_sum[target_index] < 10:\n",
    "                continue\n",
    "        epochs = []\n",
    "        for fold in range(n_kfold):\n",
    "            val_labels, best_val_out = DeepDSC(\n",
    "                res.values, null_mask.T.values, dim, target_index, seed\n",
    "            )\n",
    "\n",
    "        true_data_s = pd.concat(\n",
    "            [true_data_s, pd.DataFrame(val_labels.cpu().numpy())], axis=1\n",
    "        )\n",
    "        predict_data_s = pd.concat(\n",
    "            [predict_data_s, pd.DataFrame(best_val_out.cpu().numpy())], axis=1\n",
    "        )"
>>>>>>> 0ed566d (add DeepDSC results)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d64b3ec-4dc8-44a2-8a00-33264652bae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b609460-8eab-4f83-bac0-9b655b4290d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec400d-4112-4a47-b6e0-1bae975cee93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de4624-5b82-458d-8ec6-a28ca4108a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca21ea-156c-4cdf-bfce-c41f8aa1107a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f1600-6a1b-49cc-8b10-d9e73a71b5da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genex",
   "language": "python",
   "name": "genex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
