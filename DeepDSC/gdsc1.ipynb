{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "874334de-4e40-4786-82f8-a6abfd5939f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8044c5c-f48a-490a-829f-e3eef1878c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from load_data import load_data\n",
    "from sampler import Sampler\n",
    "\n",
    "from DeepDSC.DeepDSC import (AE, DF, GeneExpressionDataset,\n",
    "                             calculate_morgan_fingerprints, prepare_data,\n",
    "                             prepare_drug_data, prepare_train_val_test_data,\n",
    "                             train_autoencoder, train_df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbcf3b16-9be3-4bd4-82ee-b9495131eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9288ba5-744f-43f4-b872-a06f8577cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"gdsc1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f525656d-e3d7-49b8-9ea9-7f8741a77f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load gdsc1\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.device = \"cpu\"  # cuda:number or cpu\n",
    "        self.data = data  # Dataset{gdsc or ccle}\n",
    "\n",
    "\n",
    "args = Args()\n",
    "res, drug_feature, exprs, mut, cna, null_mask, pos_num = load_data(args)\n",
    "cells = {i: j for i, j in enumerate(res.index)}\n",
    "drugs = {i: j for i, j in enumerate(res.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea98472-4653-4130-b581-c55469df9f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(PATH, train, val):\n",
    "    normalized_gene_exp_tensor, gene_exp = prepare_data(\n",
    "        data1=PATH + \"/gene_exp_part1.csv.gz\", data2=PATH + \"gene_exp_part2.csv.gz\"\n",
    "    )\n",
    "    normalized_gene_exp_dataset = GeneExpressionDataset(normalized_gene_exp_tensor)\n",
    "    normalized_gene_exp_dataloader = DataLoader(\n",
    "        normalized_gene_exp_dataset, batch_size=10000, shuffle=True\n",
    "    )\n",
    "\n",
    "    # オートエンコーダーのトレーニング\n",
    "    autoencoder = AE(normalized_gene_exp_tensor.shape[1]).to(device)\n",
    "    train_autoencoder(autoencoder, normalized_gene_exp_dataloader)\n",
    "\n",
    "    # 圧縮特徴の抽出\n",
    "    compressed_features_tensor = autoencoder.encoder(normalized_gene_exp_tensor)\n",
    "    compressed_features = pd.DataFrame(\n",
    "        compressed_features_tensor.cpu().detach().numpy(), index=gene_exp.columns\n",
    "    )\n",
    "\n",
    "    # 薬物応答データの準備\n",
    "    drug_response, nsc_sm = prepare_drug_data(is_nsc=False, is_gdsc=True, is_1=True)\n",
    "    mfp = calculate_morgan_fingerprints(drug_response, nsc_sm)\n",
    "    print(f\"Morgan fingerprints shape: {mfp.shape}\")\n",
    "\n",
    "    train_labels = train[2]\n",
    "    val_labels = test[2]\n",
    "    train_data = train[[0, 1]]\n",
    "    val_data = test[[0, 1]]\n",
    "    print(\n",
    "        f\"Training data size: {len(train_data)}, Validation data size: {len(val_data)}\"\n",
    "    )\n",
    "    train_data, val_data = prepare_train_val_test_data(\n",
    "        train_data, val_data, compressed_features, mfp\n",
    "    )\n",
    "    df_model = DF().to(device)\n",
    "    val_labels, best_val_out = train_df_model(\n",
    "        df_model,\n",
    "        train_data,\n",
    "        val_data,\n",
    "        torch.tensor(train_labels).double(),\n",
    "        torch.tensor(val_labels).double(),\n",
    "    )\n",
    "    print(\"DF model training completed.\")\n",
    "    return val_labels, best_val_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b72e12-7cab-41f8-af92-3a899170fcb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▋                                                        | 282/800 [10:40<19:37,  2.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m test[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m [cells[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m     30\u001b[0m test[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m [drugs[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m---> 32\u001b[0m val_labels, best_val_out \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m true_datas \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([true_datas, pd\u001b[38;5;241m.\u001b[39mDataFrame(val_labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m predict_datas \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m     35\u001b[0m     [predict_datas, pd\u001b[38;5;241m.\u001b[39mDataFrame(best_val_out\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     36\u001b[0m )\n",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(PATH, train, val)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# オートエンコーダーのトレーニング\u001b[39;00m\n\u001b[1;32m     11\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m AE(normalized_gene_exp_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautoencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_gene_exp_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 圧縮特徴の抽出\u001b[39;00m\n\u001b[1;32m     15\u001b[0m compressed_features_tensor \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mencoder(normalized_gene_exp_tensor)\n",
      "File \u001b[0;32m~/code/Benchmark/DeepDSC/DeepDSC/DeepDSC.py:224\u001b[0m, in \u001b[0;36mtrain_autoencoder\u001b[0;34m(autoencoder, dataloader, num_epochs)\u001b[0m\n\u001b[1;32m    222\u001b[0m l1_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m autoencoder\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m    223\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m+\u001b[39m l1_lambda \u001b[38;5;241m*\u001b[39m l1_norm\n\u001b[0;32m--> 224\u001b[0m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(autoencoder\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    226\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = []\n",
    "true_datas = pd.DataFrame()\n",
    "predict_datas = pd.DataFrame()\n",
    "k = 5\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "device = \"cpu\"\n",
    "PATH = f\"../{data}_data/\"\n",
    "\n",
    "true_datas = pd.DataFrame()\n",
    "predict_datas = pd.DataFrame()\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(np.arange(pos_num))):\n",
    "    sampler = Sampler(res, train_index, test_index, null_mask.T, i)\n",
    "\n",
    "    train_data = pd.DataFrame(sampler.train_data, index=res.index, columns=res.columns)\n",
    "    test_data = pd.DataFrame(sampler.test_data, index=res.index, columns=res.columns)\n",
    "\n",
    "    train_mask = pd.DataFrame(sampler.train_mask, index=res.index, columns=res.columns)\n",
    "    test_mask = pd.DataFrame(sampler.test_mask, index=res.index, columns=res.columns)\n",
    "\n",
    "    train = pd.DataFrame(train_mask.values.nonzero()).T\n",
    "    train[2] = train_data.values[train_mask.values.nonzero()].astype(int)\n",
    "\n",
    "    test = pd.DataFrame(test_mask.values.nonzero()).T\n",
    "    test[2] = test_data.values[test_mask.values.nonzero()].astype(int)\n",
    "\n",
    "    train[0] = [cells[i] for i in train[0]]\n",
    "    train[1] = [drugs[i] for i in train[1]]\n",
    "    test[0] = [cells[i] for i in test[0]]\n",
    "    test[1] = [drugs[i] for i in test[1]]\n",
    "\n",
    "    val_labels, best_val_out = main(PATH, train, test)\n",
    "    true_datas = pd.concat([true_datas, pd.DataFrame(val_labels.cpu().numpy())], axis=1)\n",
    "    predict_datas = pd.concat(\n",
    "        [predict_datas, pd.DataFrame(best_val_out.cpu().numpy())], axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39826a76-a8b0-4322-aa68-d77d0f9977ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_datas.T.reset_index(drop=True).to_csv(\"true_gdsc1.csv\")\n",
    "predict_datas.T.reset_index(drop=True).to_csv(\"pred_gdsc1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16693c57-0e4d-4542-bfa2-cacc8c273fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9015f9f-1954-4456-a518-08c5447bdf04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00295d-5ca3-4f46-8d1f-91a36272050c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95542e-46f4-43c8-a12d-82532ce6db2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01632ad3-a869-4b53-97ad-7887bcedef51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e502655-3a6b-4ead-aaf5-10b11701ef55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc5024-f26f-4aa4-995b-21f37662b0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
