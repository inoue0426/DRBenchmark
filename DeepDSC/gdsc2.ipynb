{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "874334de-4e40-4786-82f8-a6abfd5939f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8044c5c-f48a-490a-829f-e3eef1878c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from load_data import load_data\n",
    "from sampler import Sampler\n",
    "\n",
    "from DeepDSC.DeepDSC import (AE, DF, GeneExpressionDataset,\n",
    "                             calculate_morgan_fingerprints, prepare_data,\n",
    "                             prepare_drug_data, prepare_train_val_test_data,\n",
    "                             train_autoencoder, train_df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbcf3b16-9be3-4bd4-82ee-b9495131eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9288ba5-744f-43f4-b872-a06f8577cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"gdsc2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f525656d-e3d7-49b8-9ea9-7f8741a77f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load gdsc2\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.device = \"cpu\"  # cuda:number or cpu\n",
    "        self.data = data  # Dataset{gdsc or ccle}\n",
    "\n",
    "\n",
    "args = Args()\n",
    "res, drug_feature, exprs, mut, cna, null_mask, pos_num = load_data(args)\n",
    "cells = {i: j for i, j in enumerate(res.index)}\n",
    "drugs = {i: j for i, j in enumerate(res.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9c0537-df6e-43d8-a2ba-6b9bf7f79820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea98472-4653-4130-b581-c55469df9f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(PATH, train, val):\n",
    "    normalized_gene_exp_tensor, gene_exp = prepare_data(\n",
    "        data1=PATH + \"/gene_exp_part1.csv.gz\", data2=PATH + \"gene_exp_part2.csv.gz\"\n",
    "    )\n",
    "    normalized_gene_exp_dataset = GeneExpressionDataset(normalized_gene_exp_tensor)\n",
    "    normalized_gene_exp_dataloader = DataLoader(\n",
    "        normalized_gene_exp_dataset, batch_size=10000, shuffle=True\n",
    "    )\n",
    "\n",
    "    # オートエンコーダーのトレーニング\n",
    "    autoencoder = AE(normalized_gene_exp_tensor.shape[1]).to(device)\n",
    "    train_autoencoder(autoencoder, normalized_gene_exp_dataloader)\n",
    "\n",
    "    # 圧縮特徴の抽出\n",
    "    compressed_features_tensor = autoencoder.encoder(normalized_gene_exp_tensor)\n",
    "    compressed_features = pd.DataFrame(\n",
    "        compressed_features_tensor.cpu().detach().numpy(), index=gene_exp.columns\n",
    "    )\n",
    "\n",
    "    # 薬物応答データの準備\n",
    "    drug_response, nsc_sm = prepare_drug_data(is_nsc=False, is_gdsc=True, is_1=False)\n",
    "    mfp = calculate_morgan_fingerprints(drug_response, nsc_sm)\n",
    "    print(f\"Morgan fingerprints shape: {mfp.shape}\")\n",
    "\n",
    "    train_labels = train[2]\n",
    "    val_labels = test[2]\n",
    "    train_data = train[[0, 1]]\n",
    "    val_data = test[[0, 1]]\n",
    "    print(\n",
    "        f\"Training data size: {len(train_data)}, Validation data size: {len(val_data)}\"\n",
    "    )\n",
    "    train_data, val_data = prepare_train_val_test_data(\n",
    "        train_data, val_data, compressed_features, mfp\n",
    "    )\n",
    "    df_model = DF().to(device)\n",
    "    val_labels, best_val_out = train_df_model(\n",
    "        df_model,\n",
    "        train_data,\n",
    "        val_data,\n",
    "        torch.tensor(train_labels).double(),\n",
    "        torch.tensor(val_labels).double(),\n",
    "    )\n",
    "    print(\"DF model training completed.\")\n",
    "    return val_labels, best_val_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b72e12-7cab-41f8-af92-3a899170fcb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                     | 25/800 [01:08<35:38,  2.76s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m test[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m [cells[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m     30\u001b[0m test[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m [drugs[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m---> 32\u001b[0m val_labels, best_val_out \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m true_datas \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([true_datas, pd\u001b[38;5;241m.\u001b[39mDataFrame(val_labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m predict_datas \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m     35\u001b[0m     [predict_datas, pd\u001b[38;5;241m.\u001b[39mDataFrame(best_val_out\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     36\u001b[0m )\n",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(PATH, train, val)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# オートエンコーダーのトレーニング\u001b[39;00m\n\u001b[1;32m     11\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m AE(normalized_gene_exp_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautoencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_gene_exp_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 圧縮特徴の抽出\u001b[39;00m\n\u001b[1;32m     15\u001b[0m compressed_features_tensor \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mencoder(normalized_gene_exp_tensor)\n",
      "File \u001b[0;32m~/code/Benchmark/DeepDSC/DeepDSC/DeepDSC.py:220\u001b[0m, in \u001b[0;36mtrain_autoencoder\u001b[0;34m(autoencoder, dataloader, num_epochs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m    219\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 220\u001b[0m     train_out \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m criterion(train_out, data)\n\u001b[1;32m    222\u001b[0m     l1_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m autoencoder\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mparameters())\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/code/Benchmark/DeepDSC/DeepDSC/DeepDSC.py:179\u001b[0m, in \u001b[0;36mAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    178\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m--> 179\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoded\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = []\n",
    "true_datas = pd.DataFrame()\n",
    "predict_datas = pd.DataFrame()\n",
    "k = 5\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "device = \"cpu\"\n",
    "PATH = f\"../{data}_data/\"\n",
    "\n",
    "true_datas = pd.DataFrame()\n",
    "predict_datas = pd.DataFrame()\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(np.arange(pos_num))):\n",
    "    sampler = Sampler(res, train_index, test_index, null_mask.T, i)\n",
    "\n",
    "    train_data = pd.DataFrame(sampler.train_data, index=res.index, columns=res.columns)\n",
    "    test_data = pd.DataFrame(sampler.test_data, index=res.index, columns=res.columns)\n",
    "\n",
    "    train_mask = pd.DataFrame(sampler.train_mask, index=res.index, columns=res.columns)\n",
    "    test_mask = pd.DataFrame(sampler.test_mask, index=res.index, columns=res.columns)\n",
    "\n",
    "    train = pd.DataFrame(train_mask.values.nonzero()).T\n",
    "    train[2] = train_data.values[train_mask.values.nonzero()].astype(int)\n",
    "\n",
    "    test = pd.DataFrame(test_mask.values.nonzero()).T\n",
    "    test[2] = test_data.values[test_mask.values.nonzero()].astype(int)\n",
    "\n",
    "    train[0] = [cells[i] for i in train[0]]\n",
    "    train[1] = [drugs[i] for i in train[1]]\n",
    "    test[0] = [cells[i] for i in test[0]]\n",
    "    test[1] = [drugs[i] for i in test[1]]\n",
    "\n",
    "    val_labels, best_val_out = main(PATH, train, test)\n",
    "    true_datas = pd.concat([true_datas, pd.DataFrame(val_labels.cpu().numpy())], axis=1)\n",
    "    predict_datas = pd.concat(\n",
    "        [predict_datas, pd.DataFrame(best_val_out.cpu().numpy())], axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39826a76-a8b0-4322-aa68-d77d0f9977ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_datas.T.reset_index(drop=True).to_csv(\"true_gdsc2.csv\")\n",
    "predict_datas.T.reset_index(drop=True).to_csv(\"pred_gdsc2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16693c57-0e4d-4542-bfa2-cacc8c273fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9015f9f-1954-4456-a518-08c5447bdf04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00295d-5ca3-4f46-8d1f-91a36272050c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95542e-46f4-43c8-a12d-82532ce6db2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01632ad3-a869-4b53-97ad-7887bcedef51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825d00e-f802-4274-bf8c-8d904b2ceebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3562d-932b-4886-bb42-c181a62fb078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
