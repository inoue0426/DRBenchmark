{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "874334de-4e40-4786-82f8-a6abfd5939f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8044c5c-f48a-490a-829f-e3eef1878c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from load_data import load_data\n",
    "from sampler import NewSampler\n",
    "\n",
    "from DeepDSC.DeepDSC import (AE, DF, GeneExpressionDataset,\n",
    "                             calculate_morgan_fingerprints, prepare_data,\n",
    "                             prepare_drug_data, prepare_train_val_test_data,\n",
    "                             train_autoencoder, train_df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25cc69ef-c29e-4c90-a347-cef3ebf18ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"gdsc2\"\n",
    "PATH = \"../gdsc2_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbcf3b16-9be3-4bd4-82ee-b9495131eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f525656d-e3d7-49b8-9ea9-7f8741a77f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load gdsc2\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.device = device  # cuda:number or cpu\n",
    "        self.data = \"gdsc2\"  # Dataset{gdsc or ccle}\n",
    "\n",
    "\n",
    "args = Args()\n",
    "res, drug_feature, exprs, mut, cna, null_mask, pos_num = load_data(args)\n",
    "cells = {i: j for i, j in enumerate(res.index)}\n",
    "drugs = {i: j for i, j in enumerate(res.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c8485f0-121b-4163-9154-35440784d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_sum = np.sum(res, axis=1)\n",
    "drug_sum = np.sum(res, axis=0)\n",
    "\n",
    "target_dim = [\n",
    "    0,  # Drug\n",
    "    # 1  # Cell\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aea98472-4653-4130-b581-c55469df9f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(PATH, train, val):\n",
    "    normalized_gene_exp_tensor, gene_exp = prepare_data(\n",
    "        data1=PATH + \"/gene_exp_part1.csv.gz\", data2=PATH + \"gene_exp_part2.csv.gz\"\n",
    "    )\n",
    "    normalized_gene_exp_dataset = GeneExpressionDataset(normalized_gene_exp_tensor)\n",
    "    normalized_gene_exp_dataloader = DataLoader(\n",
    "        normalized_gene_exp_dataset, batch_size=10000, shuffle=True\n",
    "    )\n",
    "\n",
    "    # オートエンコーダーのトレーニング\n",
    "    autoencoder = AE(normalized_gene_exp_tensor.shape[1]).to(device)\n",
    "    train_autoencoder(autoencoder, normalized_gene_exp_dataloader)\n",
    "\n",
    "    # 圧縮特徴の抽出\n",
    "    compressed_features_tensor = autoencoder.encoder(normalized_gene_exp_tensor)\n",
    "    compressed_features = pd.DataFrame(\n",
    "        compressed_features_tensor.cpu().detach().numpy(), index=gene_exp.columns\n",
    "    )\n",
    "\n",
    "    # 薬物応答データの準備\n",
    "    drug_response, nsc_sm = prepare_drug_data(is_nsc=False, is_gdsc=True, is_1=False)\n",
    "    mfp = calculate_morgan_fingerprints(drug_response, nsc_sm)\n",
    "    print(f\"Morgan fingerprints shape: {mfp.shape}\")\n",
    "\n",
    "    train_labels = train[2]\n",
    "    val_labels = val[2]\n",
    "    train_data = train[[0, 1]]\n",
    "    val_data = val[[0, 1]]\n",
    "    print(\n",
    "        f\"Training data size: {len(train_data)}, Validation data size: {len(val_data)}\"\n",
    "    )\n",
    "    train_data, val_data = prepare_train_val_test_data(\n",
    "        train_data, val_data, compressed_features, mfp\n",
    "    )\n",
    "    df_model = DF().to(device)\n",
    "    val_labels, best_val_out = train_df_model(\n",
    "        df_model,\n",
    "        train_data,\n",
    "        val_data,\n",
    "        torch.tensor(train_labels).double().to(device),\n",
    "        torch.tensor(val_labels).double().to(device),\n",
    "    )\n",
    "    print(\"DF model training completed.\")\n",
    "    return val_labels, best_val_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85f6219d-3df5-4bb4-92e3-c54b6eae9fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepDSC(res_mat, null_mask, target_dim, target_index, seed):\n",
    "    sampler = NewSampler(res_mat, null_mask, target_dim, target_index, seed)\n",
    "\n",
    "    train_data = pd.DataFrame(sampler.train_data, index=res.index, columns=res.columns)\n",
    "    test_data = pd.DataFrame(sampler.test_data, index=res.index, columns=res.columns)\n",
    "\n",
    "    train_mask = pd.DataFrame(sampler.train_mask, index=res.index, columns=res.columns)\n",
    "    test_mask = pd.DataFrame(sampler.test_mask, index=res.index, columns=res.columns)\n",
    "\n",
    "    train = pd.DataFrame(train_mask.values.nonzero()).T\n",
    "    train[2] = train_data.values[train_mask.values.nonzero()].astype(int)\n",
    "\n",
    "    test = pd.DataFrame(test_mask.values.nonzero()).T\n",
    "    test[2] = test_data.values[test_mask.values.nonzero()].astype(int)\n",
    "\n",
    "    train[0] = [cells[i] for i in train[0]]\n",
    "    train[1] = [drugs[i] for i in train[1]]\n",
    "    test[0] = [cells[i] for i in test[0]]\n",
    "    test[1] = [drugs[i] for i in test[1]]\n",
    "\n",
    "    val_labels, best_val_out = main(PATH, train, test)\n",
    "    return val_labels, best_val_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34b72e12-7cab-41f8-af92-3a899170fcb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/240 [00:00<?, ?it/s]/tmp/ipykernel_264052/3433340645.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if cell_sum[target_index] < 10:\n",
      "\n",
      "  0%|          | 0/800 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/800 [00:00<12:34,  1.06it/s]\u001b[A\n",
      "  1%|▏         | 11/800 [00:01<00:58, 13.42it/s]\u001b[A\n",
      "  2%|▏         | 16/800 [00:01<00:47, 16.49it/s]\u001b[A\n",
      "  2%|▎         | 20/800 [00:01<00:42, 18.52it/s]\u001b[A\n",
      "  3%|▎         | 24/800 [00:01<00:38, 20.19it/s]\u001b[A\n",
      "  3%|▎         | 27/800 [00:01<00:36, 21.26it/s]\u001b[A\n",
      "  4%|▍         | 30/800 [00:01<00:34, 22.19it/s]\u001b[A\n",
      "  4%|▍         | 33/800 [00:01<00:33, 22.96it/s]\u001b[A\n",
      "  4%|▍         | 36/800 [00:02<00:32, 23.57it/s]\u001b[A\n",
      "  5%|▍         | 39/800 [00:02<00:31, 24.02it/s]\u001b[A\n",
      "  5%|▌         | 42/800 [00:02<00:31, 24.33it/s]\u001b[A\n",
      "  6%|▌         | 45/800 [00:02<00:30, 24.59it/s]\u001b[A\n",
      "  6%|▌         | 48/800 [00:02<00:30, 24.80it/s]\u001b[A\n",
      "  6%|▋         | 51/800 [00:02<00:30, 24.95it/s]\u001b[A\n",
      "  7%|▋         | 54/800 [00:02<00:29, 25.05it/s]\u001b[A\n",
      "  7%|▋         | 57/800 [00:02<00:29, 25.12it/s]\u001b[A\n",
      "  8%|▊         | 60/800 [00:03<00:29, 25.13it/s]\u001b[A\n",
      "  8%|▊         | 63/800 [00:03<00:29, 25.13it/s]\u001b[A\n",
      "  8%|▊         | 66/800 [00:03<00:29, 25.12it/s]\u001b[A\n",
      "  9%|▊         | 69/800 [00:03<00:29, 25.12it/s]\u001b[A\n",
      "  9%|▉         | 72/800 [00:03<00:28, 25.12it/s]\u001b[A\n",
      "  9%|▉         | 75/800 [00:03<00:28, 25.14it/s]\u001b[A\n",
      " 10%|▉         | 78/800 [00:03<00:28, 25.19it/s]\u001b[A\n",
      " 10%|█         | 81/800 [00:03<00:28, 25.22it/s]\u001b[A\n",
      " 10%|█         | 84/800 [00:03<00:28, 25.24it/s]\u001b[A\n",
      " 11%|█         | 87/800 [00:04<00:28, 25.25it/s]\u001b[A\n",
      " 11%|█▏        | 90/800 [00:04<00:28, 25.24it/s]\u001b[A\n",
      " 12%|█▏        | 93/800 [00:04<00:33, 21.42it/s]\u001b[A\n",
      "  1%|▏         | 3/240 [00:22<29:35,  7.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     epochs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_kfold):\n\u001b[0;32m---> 14\u001b[0m         val_labels, best_val_out \u001b[38;5;241m=\u001b[39m \u001b[43mDeepDSC\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnull_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m true_datas \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([true_datas, pd\u001b[38;5;241m.\u001b[39mDataFrame(val_labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m predict_datas \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m     20\u001b[0m     [predict_datas, pd\u001b[38;5;241m.\u001b[39mDataFrame(best_val_out\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     21\u001b[0m )\n",
      "Cell \u001b[0;32mIn[18], line 21\u001b[0m, in \u001b[0;36mDeepDSC\u001b[0;34m(res_mat, null_mask, target_dim, target_index, seed)\u001b[0m\n\u001b[1;32m     18\u001b[0m test[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m [cells[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m     19\u001b[0m test[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m [drugs[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m---> 21\u001b[0m val_labels, best_val_out \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_labels, best_val_out\n",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(PATH, train, val)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# オートエンコーダーのトレーニング\u001b[39;00m\n\u001b[1;32m     11\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m AE(normalized_gene_exp_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautoencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_gene_exp_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 圧縮特徴の抽出\u001b[39;00m\n\u001b[1;32m     15\u001b[0m compressed_features_tensor \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mencoder(normalized_gene_exp_tensor)\n",
      "File \u001b[0;32m/spin1/home/linux/inouey2/DRBenchmark/DeepDSC/DeepDSC/DeepDSC.py:218\u001b[0m, in \u001b[0;36mtrain_autoencoder\u001b[0;34m(autoencoder, dataloader, num_epochs)\u001b[0m\n\u001b[1;32m    216\u001b[0m l1_lambda \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs)):\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m    219\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    220\u001b[0m         train_out \u001b[38;5;241m=\u001b[39m autoencoder(data)\n",
      "File \u001b[0;32m/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:317\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    257\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m/data/inouey2/conda/envs/genex/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:214\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    212\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    213\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_kfold = 1\n",
    "true_data_s = pd.DataFrame()\n",
    "predict_data_s = pd.DataFrame()\n",
    "for dim in target_dim:\n",
    "    for seed, target_index in enumerate(tqdm(np.arange(res.shape[dim]))):\n",
    "        if dim:\n",
    "            if drug_sum[target_index] < 10:\n",
    "                continue\n",
    "        else:\n",
    "            if cell_sum[target_index] < 10:\n",
    "                continue\n",
    "        epochs = []\n",
    "        for fold in range(n_kfold):\n",
    "            val_labels, best_val_out = DeepDSC(\n",
    "                res.values, null_mask.T.values, dim, target_index, seed\n",
    "            )\n",
    "\n",
    "    true_datas = pd.concat([true_datas, pd.DataFrame(val_labels.cpu().numpy())], axis=1)\n",
    "    predict_datas = pd.concat(\n",
    "        [predict_datas, pd.DataFrame(best_val_out.cpu().numpy())], axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d3c23e-46b4-4336-bf2f-abb938e0556d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39826a76-a8b0-4322-aa68-d77d0f9977ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_data_s.to_csv(f\"new_drug_true_{args.data}.csv\")\n",
    "predict_data_s.to_csv(f\"new_drug_pred_{args.data}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f4626-f8db-43c8-8c8a-5e6008c44e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d64b3ec-4dc8-44a2-8a00-33264652bae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b609460-8eab-4f83-bac0-9b655b4290d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec400d-4112-4a47-b6e0-1bae975cee93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de4624-5b82-458d-8ec6-a28ca4108a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genex",
   "language": "python",
   "name": "genex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
